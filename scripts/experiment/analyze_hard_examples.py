"""
Hard Examples Analysis Script
=============================
ç›®çš„:
1. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ãŒå¤§ããäºˆæ¸¬ã‚’å¤–ã—ãŸã€Œäºˆæ¸¬å›°é›£äº‹ä¾‹ (Hard Examples)ã€ã‚’ç‰¹å®šã™ã‚‹ã€‚
   - è¦‹é€ƒã— (Hard FN): æ­»äº¡äº‹æ•…ãªã®ã«äºˆæ¸¬ç¢ºç‡ãŒæ¥µç«¯ã«ä½ã„ã‚±ãƒ¼ã‚¹ã€‚
   - éå‰°æ¤œçŸ¥ (Hard FP): éæ­»äº¡äº‹æ•…ãªã®ã«äºˆæ¸¬ç¢ºç‡ãŒæ¥µç«¯ã«é«˜ã„ã‚±ãƒ¼ã‚¹ã€‚
2. Hard Examples ã¨æ­£è§£ä¾‹ (Easy TP/TN) ã®ç‰¹å¾´é‡åˆ†å¸ƒã‚’æ¯”è¼ƒã—ã€ãƒ¢ãƒ‡ãƒ«ã®å¼±ç‚¹ã‚’ç‰¹å®šã™ã‚‹ã€‚
3. æœ€ã‚‚ãƒŸã‚¹ãŒã²ã©ã„ãƒˆãƒƒãƒ—äº‹ä¾‹ã‚’æŠ½å‡ºã—ã€SHAPã‚’ç”¨ã„ã¦è¦å› ã‚’è§£æ˜ã™ã‚‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/experiment/analyze_hard_examples.py
"""

import os
import json
import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import lightgbm as lgb
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve
from scipy.stats import ks_2samp

import warnings
warnings.filterwarnings('ignore')

# --- è¨­å®š ---
DATA_PATH = Path("data/processed/honhyo_for_analysis_with_traffic_hospital_no_leakage.csv")
STAGE1_OOF_PATH = Path("data/processed/stage1_oof_predictions.csv")
ENSEMBLE_OOF_PATH = Path("results/tabnet_optimized/oof_predictions.csv")
OUTPUT_DIR = Path("results/error_analysis_hard")
os.makedirs(OUTPUT_DIR, exist_ok=True)

RANDOM_STATE = 42
TEST_SIZE = 0.2
STAGE1_RECALL_TARGET = 0.98

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'MS Gothic'
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

# åˆ†æå¯¾è±¡ã‚«ãƒ©ãƒ 
ANALYSIS_COLS = [
    'éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰', 'æ˜¼å¤œ', 'å¤©å€™', 'åœ°å½¢', 'è·¯é¢çŠ¶æ…‹',
    'é“è·¯å½¢çŠ¶', 'ä¿¡å·æ©Ÿ', 'road_type', 'æ­©è»Šé“åŒºåˆ†', 'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰',
    'å¹´é½¢ï¼ˆå½“äº‹è€…Aï¼‰', 'å½“äº‹è€…ç¨®åˆ¥ï¼ˆå½“äº‹è€…Aï¼‰'
]

# ã‚³ãƒ¼ãƒ‰è¾æ›¸ (ä»£è¡¨çš„ãªã‚‚ã®)
CODE_DICT = {
    'æ˜¼å¤œ': {11: 'æ˜¼-æ˜', 12: 'æ˜¼-æ˜¼', 13: 'æ˜¼-æš®', 21: 'å¤œ-æš—', 22: 'å¤œ-é“è·¯ç…§æ˜ã‚ã‚Š', 23: 'å¤œ-é“è·¯ç…§æ˜ãªã—'},
    'å¤©å€™': {1: 'æ™´', 2: 'æ›‡', 3: 'é›¨', 4: 'éœ§', 5: 'é›ª', 6: 'ãã®ä»–'},
    'åœ°å½¢': {1: 'å¸‚è¡—åœ°', 2: 'éå¸‚è¡—åœ°-DIDå¤–', 3: 'ãã®ä»–'},
    'é“è·¯å½¢çŠ¶': {1: 'äº¤å·®ç‚¹', 11: 'å˜è·¯-ãƒˆãƒ³ãƒãƒ«', 21: 'è¸åˆ‡', 31: 'äº¤å·®ç‚¹-ç’°çŠ¶'},
}


def load_and_align_data():
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨ç´ä»˜ã‘"""
    print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»ç´ä»˜ã‘ä¸­...")
    df_full = pd.read_csv(DATA_PATH)
    df_full['fatal'] = df_full['fatal'].astype(int)
    
    stage1_oof = pd.read_csv(STAGE1_OOF_PATH)
    ensemble_oof = pd.read_csv(ENSEMBLE_OOF_PATH)
    
    all_indices = np.arange(len(df_full))
    train_indices, _ = train_test_split(
        all_indices, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=df_full['fatal']
    )
    
    y_train = df_full.iloc[train_indices]['fatal'].values
    stage1_prob = 0.85 * stage1_oof['prob_catboost'].values + 0.15 * stage1_oof['prob_lgbm'].values
    
    precision, recall, thresholds = precision_recall_curve(y_train, stage1_prob)
    valid_idx = np.where(recall[:-1] >= STAGE1_RECALL_TARGET)[0]
    stage1_threshold = thresholds[valid_idx[-1]] if len(valid_idx) > 0 else 0.0
    
    filter_mask = stage1_prob >= stage1_threshold
    filtered_train_indices = train_indices[filter_mask]
    
    if len(filtered_train_indices) != len(ensemble_oof):
        print(f"   âš ï¸ è¡Œæ•°ä¸ä¸€è‡´: train indices = {len(filtered_train_indices)}, oof = {len(ensemble_oof)}")
        # æœ€å°å€¤ã«åˆã‚ã›ã‚‹ï¼ˆç¶™ç¶šã®ãŸã‚ï¼‰
        min_len = min(len(filtered_train_indices), len(ensemble_oof))
        filtered_train_indices = filtered_train_indices[:min_len]
        ensemble_oof = ensemble_oof.iloc[:min_len]
        
    df_aligned = df_full.iloc[filtered_train_indices].reset_index(drop=True).copy()
    for col in ensemble_oof.columns:
        df_aligned[f'pred_{col}'] = ensemble_oof[col].values
        
    return df_aligned, stage1_threshold


def identify_hard_examples(df, threshold):
    """Hard Examples (è¦‹é€ƒã—/éå‰°æ¤œçŸ¥) ã‚’ç‰¹å®šã™ã‚‹"""
    print("\nğŸ¯ Hard Examples ç‰¹å®šä¸­...")
    
    y_true = df['fatal'].values
    y_prob = df['pred_ensemble'].values
    y_pred = (y_prob >= threshold).astype(int)
    
    # åŸºæœ¬ãƒã‚¹ã‚¯
    tp_mask = (y_true == 1) & (y_pred == 1)  # True Positive
    tn_mask = (y_true == 0) & (y_pred == 0)  # True Negative
    fp_mask = (y_true == 0) & (y_pred == 1)  # False Positive
    fn_mask = (y_true == 1) & (y_pred == 0)  # False Negative (è¦‹é€ƒã—)
    
    # Hard Examples ã®æŠ½å‡º
    # Hard FN: æ­»äº¡äº‹æ•…ã®ä¸­ã§äºˆæ¸¬ç¢ºç‡ãŒç‰¹ã«ä½ã„ã‚‚ã® (ä¸‹ä½10%)
    fatal_probs = y_prob[y_true == 1]
    fn_threshold = np.percentile(fatal_probs, 10)  # ä¸‹ä½10%
    hard_fn_mask = fn_mask & (y_prob < fn_threshold)
    
    # Hard FP: éæ­»äº¡äº‹æ•…ã®ä¸­ã§äºˆæ¸¬ç¢ºç‡ãŒç‰¹ã«é«˜ã„ã‚‚ã® (ä¸Šä½1%)
    non_fatal_probs = y_prob[y_true == 0]
    fp_threshold = np.percentile(non_fatal_probs, 99)  # ä¸Šä½1%
    hard_fp_mask = fp_mask & (y_prob > fp_threshold)
    
    # Easy Examples (æ¯”è¼ƒç”¨)
    # Easy TP: æ­»äº¡äº‹æ•…ã§äºˆæ¸¬ç¢ºç‡ãŒé«˜ã„ã‚‚ã® (ä¸Šä½50%)
    tp_threshold = np.percentile(fatal_probs, 50)
    easy_tp_mask = tp_mask & (y_prob > tp_threshold)
    
    # Easy TN: éæ­»äº¡äº‹æ•…ã§äºˆæ¸¬ç¢ºç‡ãŒä½ã„ã‚‚ã® (ä¸‹ä½50%)
    tn_threshold = np.percentile(non_fatal_probs, 50)
    easy_tn_mask = tn_mask & (y_prob < tn_threshold)
    
    summary = {
        'Hard FN (è¦‹é€ƒã—)': hard_fn_mask.sum(),
        'Hard FP (éå‰°æ¤œçŸ¥)': hard_fp_mask.sum(),
        'Easy TP (æ­£è§£)': easy_tp_mask.sum(),
        'Easy TN (æ­£è§£)': easy_tn_mask.sum(),
        'fn_threshold': fn_threshold,
        'fp_threshold': fp_threshold,
    }
    
    print(f"   Hard FN (è¦‹é€ƒã—): {hard_fn_mask.sum()} ä»¶ (prob < {fn_threshold:.4f})")
    print(f"   Hard FP (éå‰°æ¤œçŸ¥): {hard_fp_mask.sum()} ä»¶ (prob > {fp_threshold:.4f})")
    print(f"   Easy TP (æ¯”è¼ƒç”¨): {easy_tp_mask.sum()} ä»¶")
    print(f"   Easy TN (æ¯”è¼ƒç”¨): {easy_tn_mask.sum()} ä»¶")
    
    return {
        'hard_fn': hard_fn_mask,
        'hard_fp': hard_fp_mask,
        'easy_tp': easy_tp_mask,
        'easy_tn': easy_tn_mask,
        'fn': fn_mask,
        'fp': fp_mask,
        'summary': summary
    }


def compare_distributions(df, mask1, mask2, label1, label2, output_dir):
    """2ç¾¤é–“ã®ç‰¹å¾´é‡åˆ†å¸ƒã‚’KSæ¤œå®šã§æ¯”è¼ƒã™ã‚‹"""
    print(f"\nğŸ“Š åˆ†å¸ƒæ¯”è¼ƒ: {label1} vs {label2}")
    
    available_cols = [c for c in ANALYSIS_COLS if c in df.columns]
    
    results = []
    for col in available_cols:
        data1 = df.loc[mask1, col].dropna()
        data2 = df.loc[mask2, col].dropna()
        
        if len(data1) < 10 or len(data2) < 10:
            continue
            
        # KSæ¤œå®š
        stat, p_value = ks_2samp(data1, data2)
        
        # ä»£è¡¨å€¤ã®å·®
        mean_diff = data1.mean() - data2.mean()
        
        results.append({
            'feature': col,
            'ks_stat': stat,
            'ks_pvalue': p_value,
            'mean_diff': mean_diff,
            'n1': len(data1),
            'n2': len(data2)
        })
    
    df_results = pd.DataFrame(results).sort_values('ks_stat', ascending=False)
    
    # ä¸Šä½5ä»¶ã‚’è¡¨ç¤º
    print(f"   åˆ†å¸ƒä¹–é›¢ãŒå¤§ãã„ç‰¹å¾´é‡ (Top 5):")
    for i, row in df_results.head(5).iterrows():
        print(f"      - {row['feature']}: KS={row['ks_stat']:.4f}, p={row['ks_pvalue']:.4e}")
    
    # CSVã«ä¿å­˜
    output_path = output_dir / f"distribution_comparison_{label1}_vs_{label2}.csv"
    df_results.to_csv(output_path, index=False)
    
    return df_results


def visualize_hard_examples_distributions(df, masks, output_dir):
    """Hard Examples ã®ä»£è¡¨çš„ãªç‰¹å¾´é‡åˆ†å¸ƒã‚’å¯è¦–åŒ–"""
    print("\nğŸ“ˆ Hard Examples ã®åˆ†å¸ƒå¯è¦–åŒ–...")
    
    # å¯è¦–åŒ–å¯¾è±¡ã®ç‰¹å¾´é‡
    target_cols = ['æ˜¼å¤œ', 'åœ°å½¢', 'é“è·¯å½¢çŠ¶', 'å¤©å€™']
    target_cols = [c for c in target_cols if c in df.columns]
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    axes = axes.flatten()
    
    for idx, col in enumerate(target_cols):
        ax = axes[idx]
        
        # å„ã‚«ãƒ†ã‚´ãƒªã®å‰²åˆã‚’è¨ˆç®—
        categories = []
        for mask_name, mask in [('Hard FN', masks['hard_fn']), 
                                 ('Easy TP', masks['easy_tp']),
                                 ('Hard FP', masks['hard_fp']),
                                 ('Easy TN', masks['easy_tn'])]:
            counts = df.loc[mask, col].value_counts(normalize=True).head(10)
            for val, pct in counts.items():
                # ã‚³ãƒ¼ãƒ‰è¾æ›¸ãŒã‚ã‚Œã°å¤‰æ›
                val_label = CODE_DICT.get(col, {}).get(val, str(val))
                categories.append({'group': mask_name, 'value': val_label, 'percentage': pct})
        
        df_cat = pd.DataFrame(categories)
        
        # Grouped bar chart
        if not df_cat.empty:
            pivot = df_cat.pivot_table(index='value', columns='group', values='percentage', aggfunc='first')
            pivot.plot(kind='bar', ax=ax, width=0.8)
            ax.set_title(f'{col} åˆ†å¸ƒæ¯”è¼ƒ')
            ax.set_ylabel('å‰²åˆ')
            ax.legend(title='', fontsize=8)
            ax.tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.savefig(output_dir / "hard_examples_distributions.png", dpi=150)
    plt.close()
    print(f"   ä¿å­˜: hard_examples_distributions.png")


def deep_dive_top_cases(df, masks, output_dir, n_cases=3):
    """Top N ã®æ¥µç«¯ãªèª¤åˆ†é¡äº‹ä¾‹ã‚’æ·±æ˜ã‚Š (SHAPåˆ†æ)"""
    print(f"\nğŸ”¬ Top {n_cases} æ¥µç«¯äº‹ä¾‹ã®æ·±æ˜ã‚Š (SHAPåˆ†æ)...")
    
    y_prob = df['pred_ensemble'].values
    
    # LightGBMãƒ—ãƒ­ã‚­ã‚·ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ (SHAPè¨ˆç®—ç”¨)
    print("   LightGBMãƒ—ãƒ­ã‚­ã‚·ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
    
    excluded_cols = ['fatal', 'pred_lgbm', 'pred_catboost', 'pred_mlp', 
                     'pred_tabnet_optimized', 'pred_ensemble', 'target', 'accident_id',
                     'åœ°ç‚¹ã€€ç·¯åº¦ï¼ˆåŒ—ç·¯ï¼‰', 'åœ°ç‚¹ã€€çµŒåº¦ï¼ˆæ±çµŒï¼‰']
    feature_cols = [c for c in df.columns if c not in excluded_cols and not c.startswith('pred_')]
    
    # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°
    cat_cols = [c for c in ANALYSIS_COLS if c in feature_cols]
    
    X = df[feature_cols].copy()
    y = df['fatal']
    
    for c in cat_cols:
        if c in X.columns:
            X[c] = X[c].astype('category')
    
    lgb_train = lgb.Dataset(X, y)
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'verbosity': -1,
        'boosting_type': 'gbdt',
        'seed': 42,
        'num_leaves': 31,
        'learning_rate': 0.1
    }
    model = lgb.train(params, lgb_train, num_boost_round=100)
    
    explainer = shap.TreeExplainer(model)
    
    # --- Hard FN Top Cases ---
    hard_fn_indices = np.where(masks['hard_fn'])[0]
    if len(hard_fn_indices) > 0:
        # äºˆæ¸¬ç¢ºç‡ãŒæœ€ã‚‚ä½ã„ã‚‚ã®ã‚’é¸æŠ
        fn_probs = y_prob[hard_fn_indices]
        sorted_idx = np.argsort(fn_probs)[:n_cases]
        top_fn_indices = hard_fn_indices[sorted_idx]
        
        print(f"\n   === Hard FN Top {n_cases} Cases (æœ€ã‚‚ã²ã©ã„è¦‹é€ƒã—) ===")
        
        for rank, idx in enumerate(top_fn_indices, 1):
            prob = y_prob[idx]
            print(f"\n   Case #{rank}: Index={idx}, Prob={prob:.4f} (æ­»äº¡äº‹æ•…ãªã®ã«ä½ç¢ºç‡)")
            
            # ç‰¹å¾´é‡ã‚µãƒãƒªãƒ¼
            for col in ['éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰', 'é“è·¯å½¢çŠ¶', 'æ˜¼å¤œ', 'åœ°å½¢']:
                if col in df.columns:
                    val = df.loc[idx, col]
                    val_label = CODE_DICT.get(col, {}).get(val, val)
                    print(f"      - {col}: {val_label}")
            
            # SHAP Waterfall
            shap_values = explainer.shap_values(X.iloc[[idx]])
            if isinstance(shap_values, list):
                shap_values = shap_values[1]
            
            base_value = explainer.expected_value
            if isinstance(base_value, list):
                base_value = base_value[1]
            
            plt.figure(figsize=(10, 6))
            try:
                shap.plots.waterfall(
                    shap.Explanation(
                        values=shap_values[0],
                        base_values=base_value,
                        data=X.iloc[idx],
                        feature_names=X.columns
                    ),
                    show=False, max_display=10
                )
                plt.title(f"Hard FN Case #{rank}: è¦‹é€ƒã—è¦å› åˆ†è§£ (Prob={prob:.4f})")
                plt.tight_layout()
                plt.savefig(output_dir / f"shap_waterfall_hard_fn_{rank}.png", dpi=150)
                plt.close()
            except Exception as e:
                print(f"      âš ï¸ SHAP Waterfallç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # --- Hard FP Top Cases ---
    hard_fp_indices = np.where(masks['hard_fp'])[0]
    if len(hard_fp_indices) > 0:
        fp_probs = y_prob[hard_fp_indices]
        sorted_idx = np.argsort(-fp_probs)[:n_cases]  # é™é †
        top_fp_indices = hard_fp_indices[sorted_idx]
        
        print(f"\n   === Hard FP Top {n_cases} Cases (æœ€ã‚‚ã²ã©ã„éå‰°æ¤œçŸ¥) ===")
        
        for rank, idx in enumerate(top_fp_indices, 1):
            prob = y_prob[idx]
            print(f"\n   Case #{rank}: Index={idx}, Prob={prob:.4f} (éæ­»äº¡ãªã®ã«é«˜ç¢ºç‡)")
            
            for col in ['éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰', 'é“è·¯å½¢çŠ¶', 'æ˜¼å¤œ', 'åœ°å½¢']:
                if col in df.columns:
                    val = df.loc[idx, col]
                    val_label = CODE_DICT.get(col, {}).get(val, val)
                    print(f"      - {col}: {val_label}")
            
            shap_values = explainer.shap_values(X.iloc[[idx]])
            if isinstance(shap_values, list):
                shap_values = shap_values[1]
            
            base_value = explainer.expected_value
            if isinstance(base_value, list):
                base_value = base_value[1]
            
            plt.figure(figsize=(10, 6))
            try:
                shap.plots.waterfall(
                    shap.Explanation(
                        values=shap_values[0],
                        base_values=base_value,
                        data=X.iloc[idx],
                        feature_names=X.columns
                    ),
                    show=False, max_display=10
                )
                plt.title(f"Hard FP Case #{rank}: éå‰°æ¤œçŸ¥è¦å› åˆ†è§£ (Prob={prob:.4f})")
                plt.tight_layout()
                plt.savefig(output_dir / f"shap_waterfall_hard_fp_{rank}.png", dpi=150)
                plt.close()
            except Exception as e:
                print(f"      âš ï¸ SHAP Waterfallç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\n   SHAP Waterfallãƒ—ãƒ­ãƒƒãƒˆä¿å­˜å®Œäº†")


def generate_summary_report(df, masks, dist_fn, dist_fp, output_dir):
    """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ (Markdown) ã‚’ç”Ÿæˆ"""
    print("\nğŸ“ ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
    
    summary = masks['summary']
    
    report = f"""# Hard Examples åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## æ¦‚è¦

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã‚’å¤§ããå¤–ã—ãŸã€ŒHard Examples (äºˆæ¸¬å›°é›£äº‹ä¾‹)ã€ã®åˆ†æçµæœã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚

### æŠ½å‡ºã•ã‚ŒãŸ Hard Examples

| ã‚«ãƒ†ã‚´ãƒª | ä»¶æ•° | é–¾å€¤ |
|---------|------|------|
| **è¦‹é€ƒã— (Hard FN)** | {summary['Hard FN (è¦‹é€ƒã—)']} ä»¶ | prob < {summary['fn_threshold']:.4f} |
| **éå‰°æ¤œçŸ¥ (Hard FP)** | {summary['Hard FP (éå‰°æ¤œçŸ¥)']} ä»¶ | prob > {summary['fp_threshold']:.4f} |
| æ¯”è¼ƒç”¨ Easy TP | {summary['Easy TP (æ­£è§£)']} ä»¶ | - |
| æ¯”è¼ƒç”¨ Easy TN | {summary['Easy TN (æ­£è§£)']} ä»¶ | - |

---

## è¦‹é€ƒã— (Hard FN) ã®ç‰¹å¾´

Hard FN ã¨ Easy TP ã‚’æ¯”è¼ƒã—ãŸçµæœã€ä»¥ä¸‹ã®ç‰¹å¾´é‡ã§åˆ†å¸ƒãŒå¤§ããç•°ãªã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚

"""
    
    if dist_fn is not None and len(dist_fn) > 0:
        report += "| ç‰¹å¾´é‡ | KSçµ±è¨ˆé‡ | på€¤ | å¹³å‡å·® |\n|--------|----------|-----|--------|\n"
        for _, row in dist_fn.head(5).iterrows():
            report += f"| {row['feature']} | {row['ks_stat']:.4f} | {row['ks_pvalue']:.2e} | {row['mean_diff']:.2f} |\n"
    else:
        report += "*ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚æ¯”è¼ƒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚*\n"
    
    report += f"""

---

## éå‰°æ¤œçŸ¥ (Hard FP) ã®ç‰¹å¾´

Hard FP ã¨ Easy TN ã‚’æ¯”è¼ƒã—ãŸçµæœã€ä»¥ä¸‹ã®ç‰¹å¾´é‡ã§åˆ†å¸ƒãŒå¤§ããç•°ãªã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚

"""
    
    if dist_fp is not None and len(dist_fp) > 0:
        report += "| ç‰¹å¾´é‡ | KSçµ±è¨ˆé‡ | på€¤ | å¹³å‡å·® |\n|--------|----------|-----|--------|\n"
        for _, row in dist_fp.head(5).iterrows():
            report += f"| {row['feature']} | {row['ks_stat']:.4f} | {row['ks_pvalue']:.2e} | {row['mean_diff']:.2f} |\n"
    else:
        report += "*ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚æ¯”è¼ƒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚*\n"
    
    report += f"""

---

## å€‹åˆ¥äº‹ä¾‹ã®æ·±æ˜ã‚Š (SHAPåˆ†æ)

æœ€ã‚‚èª¤åˆ†é¡ãŒã²ã©ã‹ã£ãŸTop 3äº‹ä¾‹ã«ã¤ã„ã¦ã€SHAPã‚’ç”¨ã„ã¦è¦å› åˆ†æã‚’è¡Œã„ã¾ã—ãŸã€‚
è©³ç´°ã¯ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„:

- `shap_waterfall_hard_fn_1.png`, `shap_waterfall_hard_fn_2.png`, `shap_waterfall_hard_fn_3.png` (è¦‹é€ƒã—)
- `shap_waterfall_hard_fp_1.png`, `shap_waterfall_hard_fp_2.png`, `shap_waterfall_hard_fp_3.png` (éå‰°æ¤œçŸ¥)

---

## çµè«–ã¨æ”¹å–„ææ¡ˆ

1. **è¦‹é€ƒã—ã®å‚¾å‘**: Hard FN ã¯ç‰¹å®šã®æ¡ä»¶ä¸‹ã§ç™ºç”Ÿã—ã‚„ã™ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¸Šè¨˜ã®åˆ†å¸ƒæ¯”è¼ƒçµæœã‚’å‚è€ƒã«ã€ãƒ¢ãƒ‡ãƒ«ã¸ã®ç‰¹å¾´é‡è¿½åŠ ã‚„é‡ã¿èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚
2. **éå‰°æ¤œçŸ¥ã®å‚¾å‘**: Hard FP ã¯ã€Œå±é™ºã«è¦‹ãˆã‚‹ãŒå®Ÿéš›ã¯æ­»äº¡ã«è‡³ã‚‰ãªã‹ã£ãŸäº‹æ•…ã€ã‚’æ‹¾ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚é–¾å€¤ã®èª¿æ•´ã‚„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ã®è¿½åŠ ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚
3. **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: ç‰¹å®šã®æ¡ä»¶ï¼ˆä¾‹ï¼šç‰¹å®šã®é“è·¯å½¢çŠ¶ã€åœ°å½¢ï¼‰ã«ç‰¹åŒ–ã—ãŸå°‚é–€å®¶ãƒ¢ãƒ‡ãƒ« (Mixture of Experts) ã®å°å…¥ã‚’æ¤œè¨ã™ã‚‹ä¾¡å€¤ãŒã‚ã‚Šã¾ã™ã€‚

"""
    
    # ä¿å­˜
    report_path = output_dir / "hard_examples_report.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    # results/md ã«ã‚‚ã‚³ãƒ”ãƒ¼
    md_dir = Path("results/md")
    os.makedirs(md_dir, exist_ok=True)
    with open(md_dir / "hard_examples_analysis.md", 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"   ä¿å­˜: {report_path}")
    print(f"   ä¿å­˜: {md_dir / 'hard_examples_analysis.md'}")


def main():
    print("=" * 70)
    print(" ğŸ” Hard Examples (äºˆæ¸¬å›°é›£äº‹ä¾‹) åˆ†æ")
    print("=" * 70)
    
    df, threshold = load_and_align_data()
    
    # 1. Hard Examples ã®ç‰¹å®š
    masks = identify_hard_examples(df, threshold)
    
    # 2. åˆ†å¸ƒæ¯”è¼ƒ
    dist_fn = compare_distributions(
        df, masks['hard_fn'], masks['easy_tp'], 
        'Hard_FN', 'Easy_TP', OUTPUT_DIR
    )
    
    dist_fp = compare_distributions(
        df, masks['hard_fp'], masks['easy_tn'], 
        'Hard_FP', 'Easy_TN', OUTPUT_DIR
    )
    
    # 3. åˆ†å¸ƒå¯è¦–åŒ–
    visualize_hard_examples_distributions(df, masks, OUTPUT_DIR)
    
    # 4. Topäº‹ä¾‹ã®æ·±æ˜ã‚Š (SHAP)
    deep_dive_top_cases(df, masks, OUTPUT_DIR, n_cases=3)
    
    # 5. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_summary_report(df, masks, dist_fn, dist_fp, OUTPUT_DIR)
    
    print("\nâœ… Hard Examples åˆ†æå®Œäº†")
    print(f"   å‡ºåŠ›å…ˆ: {OUTPUT_DIR}")
    print(f"   ãƒ¬ãƒãƒ¼ãƒˆ: results/md/hard_examples_analysis.md")


if __name__ == "__main__":
    main()

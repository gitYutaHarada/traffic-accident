"""
Deep Dive Error Analysis Script
===============================
ç›®çš„: 
1. `analyze_ensemble_errors.py` ã§ç‰¹å®šã•ã‚ŒãŸé«˜ãƒªã‚¹ã‚¯è¦å› ï¼ˆè¸åˆ‡ã€ãƒ¯ã‚¤ãƒ¤ãƒ­ãƒ¼ãƒ—ç­‰ï¼‰ã‚’æ·±å €ã‚Šã™ã‚‹ã€‚
2. æ±ºå®šæœ¨ã‚’ç”¨ã„ã¦ã€ã‚¨ãƒ©ãƒ¼ï¼ˆFP/FNï¼‰ãŒç™ºç”Ÿã™ã‚‹è¤‡åˆæ¡ä»¶ï¼ˆãƒ«ãƒ¼ãƒ«ï¼‰ã‚’è‡ªå‹•æŠ½å‡ºã™ã‚‹ã€‚
3. åœ°ç†ç©ºé–“æƒ…å ±ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã€åœ°åŸŸçš„ãªåã‚Šã‚’å¯è¦–åŒ–ã™ã‚‹ã€‚

æ³¨æ„:
- æ±ºå®šæœ¨åˆ†æã§ã¯ã€ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’One-Hot Encodingã—ã¦å­¦ç¿’ã•ã›ã‚‹ã“ã¨ã§ã€
  ã€Œéƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰ <= 20ã€ã®ã‚ˆã†ãªç„¡æ„å‘³ãªæ•°å€¤åˆ†å‰²ã‚’é˜²ãã€
  ã€Œè¸åˆ‡ã®æœ‰ç„¡ã€ã®ã‚ˆã†ãªæ˜ç¢ºãªãƒ«ãƒ¼ãƒ«ã‚’æŠ½å‡ºã™ã‚‹ã€‚
"""

import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.preprocessing import OneHotEncoder

import warnings
warnings.filterwarnings('ignore')

# --- è¨­å®š ---
DATA_PATH = Path("data/processed/honhyo_for_analysis_with_traffic_hospital_no_leakage.csv")
STAGE1_OOF_PATH = Path("data/processed/stage1_oof_predictions.csv")
ENSEMBLE_OOF_PATH = Path("results/tabnet_optimized/oof_predictions.csv")
OUTPUT_DIR = Path("results/error_analysis_deep_dive")
os.makedirs(OUTPUT_DIR, exist_ok=True)

RANDOM_STATE = 42
TEST_SIZE = 0.2
STAGE1_RECALL_TARGET = 0.98

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'MS Gothic'
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

# åˆ†æå¯¾è±¡ã‚«ãƒ©ãƒ 
ANALYSIS_COLS = [
    'éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰', 'æ˜¼å¤œ', 'å¤©å€™', 'åœ°å½¢', 'è·¯é¢çŠ¶æ…‹',
    'é“è·¯å½¢çŠ¶', 'ä¿¡å·æ©Ÿ', 'äº‹æ•…é¡å‹', 'æ›œæ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)', 'æ™‚', 'æœˆ',
    'æ­©è»Šé“åŒºåˆ†', 'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰', 'road_type'
]

# ã‚³ãƒ¼ãƒ‰å®šç¾©ï¼ˆåˆ¤æ˜åˆ†ï¼‰
CODE_DEFINITIONS = {
    'é“è·¯å½¢çŠ¶': {
        21: 'è¸åˆ‡-ç¬¬ä¸€ç¨®',
        11: 'å˜è·¯-ãƒˆãƒ³ãƒãƒ«',
        31: 'äº¤å·®ç‚¹-ç’°çŠ¶',
        1: 'äº¤å·®ç‚¹-ãã®ä»–'
    },
    'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰': {
        7: 'ä¸­å¤®ç·š-ãƒ¯ã‚¤ãƒ¤ãƒ­ãƒ¼ãƒ—',
        1: 'ä¸­å¤®åˆ†é›¢å¸¯',
        5: 'åˆ†é›¢ãªã—'
    }
}


def load_and_align_data():
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨ç´ä»˜ã‘ (v3å†åˆ©ç”¨)"""
    print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»ç´ä»˜ã‘ä¸­...")
    df_full = pd.read_csv(DATA_PATH)
    df_full['fatal'] = df_full['fatal'].astype(int)
    
    stage1_oof = pd.read_csv(STAGE1_OOF_PATH)
    ensemble_oof = pd.read_csv(ENSEMBLE_OOF_PATH)
    
    all_indices = np.arange(len(df_full))
    train_indices, _ = train_test_split(
        all_indices, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=df_full['fatal']
    )
    
    y_train = df_full.iloc[train_indices]['fatal'].values
    stage1_prob = 0.85 * stage1_oof['prob_catboost'].values + 0.15 * stage1_oof['prob_lgbm'].values
    
    precision, recall, thresholds = precision_recall_curve(y_train, stage1_prob)
    valid_idx = np.where(recall[:-1] >= STAGE1_RECALL_TARGET)[0]
    stage1_threshold = thresholds[valid_idx[-1]] if len(valid_idx) > 0 else 0.0
    
    filter_mask = stage1_prob >= stage1_threshold
    filtered_train_indices = train_indices[filter_mask]
    
    if len(filtered_train_indices) != len(ensemble_oof):
        raise ValueError("è¡Œæ•°ä¸ä¸€è‡´")
        
    df_aligned = df_full.iloc[filtered_train_indices].reset_index(drop=True).copy()
    for col in ensemble_oof.columns:
        df_aligned[f'pred_{col}'] = ensemble_oof[col].values
        
    return df_aligned, stage1_threshold


def analyze_high_risk_segments(df, fp_mask, fn_mask, output_dir):
    """é«˜ãƒªã‚¹ã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆè¸åˆ‡ã€ãƒ¯ã‚¤ãƒ¤ãƒ­ãƒ¼ãƒ—ç­‰ï¼‰ã®è©³ç´°åˆ†æ"""
    print("\nğŸ” é«˜ãƒªã‚¹ã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°åˆ†æ...")
    
    segments = [
        {'col': 'é“è·¯å½¢çŠ¶', 'val': 21, 'name': 'è¸åˆ‡(ç¬¬ä¸€ç¨®)'},
        {'col': 'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰', 'val': 7, 'name': 'ãƒ¯ã‚¤ãƒ¤ãƒ­ãƒ¼ãƒ—'},
        {'col': 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰', 'val': 483, 'name': 'å¸‚åŒºç”ºæ‘483'},
    ]
    
    segment_stats = []
    
    for seg in segments:
        col, val, name = seg['col'], seg['val'], seg['name']
        mask = df[col] == val
        
        if mask.sum() == 0:
            continue
            
        n_total = mask.sum()
        fp_rate = (mask & fp_mask).sum() / mask.sum()
        fn_rate = (mask & fn_mask).sum() / mask.sum()
        fatal_rate = df.loc[mask, 'fatal'].mean()
        
        # é–¢é€£ã™ã‚‹ä»–ã®ç‰¹å¾´é‡ã®çµ±è¨ˆï¼ˆä¾‹ï¼šè¸åˆ‡äº‹æ•…ã¯æ˜¼ãŒå¤šã„ï¼Ÿå¤œãŒå¤šã„ï¼Ÿï¼‰
        night_rate = (df.loc[mask, 'æ˜¼å¤œ'] > 20).mean() # 21,22,23ã¯å¤œ
        rain_snow_rate = (df.loc[mask, 'å¤©å€™'].isin([3, 5])).mean() # 3=é›¨, 5=é›ª
        
        stats = {
            'segment': name,
            'total_count': n_total,
            'fp_rate': fp_rate,
            'fn_rate': fn_rate,
            'fatal_rate': fatal_rate,
            'night_ratio': night_rate,
            'bad_weather_ratio': rain_snow_rate
        }
        segment_stats.append(stats)
        
    df_stats = pd.DataFrame(segment_stats)
    print(df_stats)
    df_stats.to_csv(output_dir / "high_risk_segment_profiles.csv", index=False)
    return df_stats


def extract_error_rules_with_decision_tree(df, target_mask, target_name, output_dir):
    """
    æ±ºå®šæœ¨ã‚’ç”¨ã„ã¦ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿãƒ«ãƒ¼ãƒ«ã‚’æŠ½å‡ºã™ã‚‹
    One-Hot Encodingã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ã€Œã‚‚ã—è¸åˆ‡ãªã‚‰...ã€ã¨ã„ã£ãŸæ˜ç¢ºãªãƒ«ãƒ¼ãƒ«ã‚’ç”Ÿæˆ
    """
    print(f"\nğŸŒ² æ±ºå®šæœ¨ã«ã‚ˆã‚‹ãƒ«ãƒ¼ãƒ«æŠ½å‡º ({target_name})...")
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: æŒ‡å®šã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã‹ (1) ãã†ã§ãªã„ã‹ (0)
    y = target_mask.astype(int)
    
    # ç‰¹å¾´é‡: ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’One-HotåŒ–
    # å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ã‚’ä½¿ç”¨
    available_cols = [c for c in ANALYSIS_COLS if c in df.columns]
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°: æ—¥æœ¬èªåãŒãªã„å ´åˆã€è‹±èªåã‚’è©¦ã™
    name_mapping = {'æ™‚': 'hour', 'æœˆ': 'month', 'æ›œæ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)': 'day_of_week'}
    for jp, en in name_mapping.items():
        if jp not in df.columns and en in df.columns:
            available_cols.append(en)
            if jp in available_cols: available_cols.remove(jp) # é‡è¤‡é™¤å»
            
    # é‡è¤‡é™¤å»
    available_cols = list(set(available_cols))
    
    print(f"   ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡: {len(available_cols)} å€‹")
    X_raw = df[available_cols].fillna(-1)
    
    # æ•°å€¤ã¨ã—ã¦æ‰±ã†ã¹ãã‚«ãƒ©ãƒ ï¼ˆæ™‚ã€æœˆãªã©ï¼‰
    # è‹±èªåã‚‚å«ã‚ã‚‹
    num_cols_candidates = ['æ™‚', 'æœˆ', 'hour', 'month']
    num_cols = [c for c in num_cols_candidates if c in available_cols]
    cat_cols = [c for c in available_cols if c not in num_cols]
    
    # One-Hot Encoding
    if len(cat_cols) > 0:
        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
        X_cat = encoder.fit_transform(X_raw[cat_cols])
        feature_names_cat = encoder.get_feature_names_out(cat_cols)
    else:
        X_cat = np.empty((len(df), 0))
        feature_names_cat = []
    
    X_num = X_raw[num_cols].values
    feature_names = list(feature_names_cat) + num_cols
    
    X = np.hstack([X_cat, X_num])
    
    # æ±ºå®šæœ¨å­¦ç¿’ (æ·±ã™ãã‚‹ã¨è§£é‡ˆä¸èƒ½ãªã®ã§æ·±ã•3ã€œ4ã«åˆ¶é™)
    clf = DecisionTreeClassifier(max_depth=3, min_samples_leaf=50, random_state=42, class_weight='balanced')
    clf.fit(X, y)
    
    # å¯è¦–åŒ–
    plt.figure(figsize=(20, 10))
    plot_tree(clf, feature_names=feature_names, class_names=['Correct', 'Error'], 
              filled=True, fontsize=10, proportion=True)
    plt.title(f"{target_name} ç™ºç”Ÿãƒ«ãƒ¼ãƒ« (æ±ºå®šæœ¨)")
    plt.savefig(output_dir / f"tree_rules_{target_name}.png", dpi=150)
    plt.close()
    
    # ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ãƒ«ãƒ¼ãƒ«ã‚’å‡ºåŠ›
    rules = export_text(clf, feature_names=feature_names)
    with open(output_dir / f"rules_{target_name}.txt", "w", encoding="utf-8") as f:
        f.write(rules)
        
    print(f"   ä¿å­˜: tree_rules_{target_name}.png, rules_{target_name}.txt")


def plot_geospatial_errors(df, fp_mask, fn_mask, output_dir):
    """åœ°ç†ç©ºé–“ãƒ—ãƒ­ãƒƒãƒˆ (æ—¥æœ¬åœ°å›³)"""
    print("\nğŸ—ºï¸ åœ°ç†ç©ºé–“ã‚¨ãƒ©ãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ...")
    
    if 'åœ°ç‚¹ã€€çµŒåº¦ï¼ˆæ±çµŒï¼‰' not in df.columns or 'åœ°ç‚¹ã€€ç·¯åº¦ï¼ˆåŒ—ç·¯ï¼‰' not in df.columns:
        print("   âš ï¸ ç·¯åº¦çµŒåº¦ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        return

    # DMS (åº¦åˆ†ç§’) -> åº¦ (Decimal) å¤‰æ›ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚‹ãŒã€
    # ã“ã“ã§ã¯ãƒ‡ãƒ¼ã‚¿ãŒæ—¢ã«å¤‰æ›æ¸ˆã¿ã§ã‚ã‚‹ã‹ã€ã¾ãŸã¯ç°¡æ˜“çš„ã«ãã®ã¾ã¾ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ç¢ºèªã™ã‚‹
    # â€» æœ¬ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯é€šå¸¸ã“ã®ã¾ã¾ãƒ—ãƒ­ãƒƒãƒˆå¯èƒ½
    
    fig, ax = plt.subplots(figsize=(10, 10))
    
    # å…¨ãƒ‡ãƒ¼ã‚¿ï¼ˆèƒŒæ™¯ï¼‰
    # ãƒ‡ãƒ¼ã‚¿é‡ãŒå¤šã™ãã‚‹ã®ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    df_sample = df.sample(frac=0.1, random_state=42)
    ax.scatter(df_sample['åœ°ç‚¹ã€€çµŒåº¦ï¼ˆæ±çµŒï¼‰'], df_sample['åœ°ç‚¹ã€€ç·¯åº¦ï¼ˆåŒ—ç·¯ï¼‰'], 
               c='lightgray', s=1, alpha=0.5, label='Others')
    
    # FP (èµ¤)
    ax.scatter(df.loc[fp_mask, 'åœ°ç‚¹ã€€çµŒåº¦ï¼ˆæ±çµŒï¼‰'], df.loc[fp_mask, 'åœ°ç‚¹ã€€ç·¯åº¦ï¼ˆåŒ—ç·¯ï¼‰'], 
               c='red', s=5, alpha=0.6, label='False Positive')
    
    # FN (ã‚ªãƒ¬ãƒ³ã‚¸)
    ax.scatter(df.loc[fn_mask, 'åœ°ç‚¹ã€€çµŒåº¦ï¼ˆæ±çµŒï¼‰'], df.loc[fn_mask, 'åœ°ç‚¹ã€€ç·¯åº¦ï¼ˆåŒ—ç·¯ï¼‰'], 
               c='orange', s=5, alpha=0.6, label='False Negative')
    
    # ç‰¹å®šã®é«˜ãƒªã‚¹ã‚¯å¸‚åŒºç”ºæ‘ (483) ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    high_risk_city = df['å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰'] == 483
    if high_risk_city.sum() > 0:
        ax.scatter(df.loc[high_risk_city, 'åœ°ç‚¹ã€€çµŒåº¦ï¼ˆæ±çµŒï¼‰'], df.loc[high_risk_city, 'åœ°ç‚¹ã€€ç·¯åº¦ï¼ˆåŒ—ç·¯ï¼‰'], 
                   c='blue', s=20, marker='x', label='City 483')

    ax.set_title('ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿåœ°ç‚¹ã®åœ°ç†åˆ†å¸ƒ')
    ax.set_xlabel('çµŒåº¦')
    ax.set_ylabel('ç·¯åº¦')
    ax.legend()
    
    plt.tight_layout()
    plt.savefig(output_dir / "geospatial_error_map.png", dpi=150)
    plt.close()
    print(f"   ä¿å­˜: geospatial_error_map.png")


def main():
    print("=" * 70)
    print(" ğŸŒŠ Deep Dive Error Analysis")
    print("=" * 70)
    
    df, threshold = load_and_align_data()
    
    # FP/FN ãƒã‚¹ã‚¯ä½œæˆ
    y_true = df['fatal'].values
    y_prob = df['pred_ensemble'].values
    y_pred = (y_prob >= threshold).astype(int)
    
    fp_mask = (y_true == 0) & (y_pred == 1)
    fn_mask = (y_true == 1) & (y_pred == 0)
    
    # 1. é«˜ãƒªã‚¹ã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°åˆ†æ
    analyze_high_risk_segments(df, fp_mask, fn_mask, OUTPUT_DIR)
    
    # 2. æ±ºå®šæœ¨ã«ã‚ˆã‚‹ãƒ«ãƒ¼ãƒ«æŠ½å‡º (One-Hot Encoded)
    extract_error_rules_with_decision_tree(df, fp_mask, "False_Positive", OUTPUT_DIR)
    extract_error_rules_with_decision_tree(df, fn_mask, "False_Negative", OUTPUT_DIR)
    
    # 3. åœ°ç†ç©ºé–“ãƒ—ãƒ­ãƒƒãƒˆ
    plot_geospatial_errors(df, fp_mask, fn_mask, OUTPUT_DIR)
    
    print("\nâœ… æ·±å±¤åˆ†æå®Œäº†")
    print(f"   å‡ºåŠ›å…ˆ: {OUTPUT_DIR}")


if __name__ == "__main__":
    main()

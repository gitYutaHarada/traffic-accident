{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Spatio-Temporal Stage2 モデル\n",
                "\n",
                "交通事故データを用いた「空間・時系列（Spatio-Temporal）を取り入れた死亡事故予測モデル」の実装と評価。\n",
                "\n",
                "## 目次\n",
                "1. 環境設定\n",
                "2. データ読み込みと前処理\n",
                "3. グラフ構築\n",
                "4. モデル学習\n",
                "5. 評価\n",
                "6. 可視化（地図ヒートマップ）"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 環境設定"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# パス設定\n",
                "PROJECT_ROOT = Path.cwd().parent.parent\n",
                "sys.path.insert(0, str(PROJECT_ROOT / 'scripts' / 'spatio_temporal'))\n",
                "\n",
                "print(f\"Project Root: {PROJECT_ROOT}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 必要なパッケージのインポート\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# 自作モジュール\n",
                "from preprocess_spatio_temporal import SpatioTemporalPreprocessor\n",
                "from graph_builder import GraphBuilder, build_sample_graph\n",
                "from train_spatio_temporal import SpatioTemporalTrainer\n",
                "from evaluate import evaluate_model, ModelEvaluator\n",
                "from visualize import plot_pr_curve, plot_roc_curve, create_heatmap\n",
                "from utils.checkpoint import set_seed\n",
                "\n",
                "# ランダムシード固定\n",
                "RANDOM_SEED = 42\n",
                "set_seed(RANDOM_SEED)\n",
                "\n",
                "# デバイス\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. データ読み込みと前処理"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# データパス\n",
                "DATA_PATH = PROJECT_ROOT / 'data' / 'processed' / 'honhyo_for_analysis_with_traffic_hospital_no_leakage.csv'\n",
                "OUTPUT_DIR = PROJECT_ROOT / 'data' / 'spatio_temporal'\n",
                "\n",
                "print(f\"Data Path: {DATA_PATH}\")\n",
                "print(f\"Exists: {DATA_PATH.exists()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 前処理の実行\n",
                "preprocessor = SpatioTemporalPreprocessor(\n",
                "    data_path=str(DATA_PATH),\n",
                "    output_dir=str(OUTPUT_DIR),\n",
                "    train_years=(2018, 2019),\n",
                "    val_years=(2020, 2020),\n",
                "    test_years=(2021, 2024),\n",
                "    geohash_precision=6,\n",
                ")\n",
                "\n",
                "# 前処理実行（または既存ファイルを読み込み）\n",
                "if not (OUTPUT_DIR / 'preprocessed_train.parquet').exists():\n",
                "    preprocess_result = preprocessor.run()\n",
                "    print(f\"\\n前処理結果: {preprocess_result}\")\n",
                "else:\n",
                "    print(\"前処理済みファイルが存在します。スキップ。\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 前処理済みデータの読み込み\n",
                "train_df = pd.read_parquet(OUTPUT_DIR / 'preprocessed_train.parquet')\n",
                "val_df = pd.read_parquet(OUTPUT_DIR / 'preprocessed_val.parquet')\n",
                "test_df = pd.read_parquet(OUTPUT_DIR / 'preprocessed_test.parquet')\n",
                "\n",
                "print(f\"Train: {len(train_df):,} rows\")\n",
                "print(f\"Val:   {len(val_df):,} rows\")\n",
                "print(f\"Test:  {len(test_df):,} rows\")\n",
                "\n",
                "# ターゲット分布\n",
                "print(f\"\\nTrain Fatal: {train_df['fatal'].sum():,} ({train_df['fatal'].mean()*100:.2f}%)\")\n",
                "print(f\"Val Fatal:   {val_df['fatal'].sum():,} ({val_df['fatal'].mean()*100:.2f}%)\")\n",
                "print(f\"Test Fatal:  {test_df['fatal'].sum():,} ({test_df['fatal'].mean()*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# データの確認\n",
                "train_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. グラフ構築"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# kNNグラフの構築\n",
                "k = 8\n",
                "\n",
                "builder = GraphBuilder(k=k, use_haversine=True)\n",
                "\n",
                "# 学習データの座標\n",
                "coords = train_df[['lat', 'lon']].values\n",
                "print(f\"座標サンプル数: {len(coords):,}\")\n",
                "\n",
                "# グラフ構築（サブサンプリング）\n",
                "sample_size = min(10000, len(coords))\n",
                "sample_idx = np.random.choice(len(coords), sample_size, replace=False)\n",
                "sample_coords = coords[sample_idx]\n",
                "\n",
                "edge_index, edge_attr = builder.build_knn_graph(sample_coords)\n",
                "\n",
                "print(f\"\\nサンプルグラフ:\")\n",
                "print(f\"  ノード数: {sample_size:,}\")\n",
                "print(f\"  エッジ数: {edge_index.shape[1]:,}\")\n",
                "print(f\"  平均次数: {edge_index.shape[1] / sample_size:.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# エッジ距離の分布\n",
                "if edge_attr is not None:\n",
                "    distances = edge_attr.numpy().flatten()\n",
                "    \n",
                "    plt.figure(figsize=(10, 5))\n",
                "    plt.hist(distances, bins=50, edgecolor='black', alpha=0.7)\n",
                "    plt.xlabel('Distance (km)')\n",
                "    plt.ylabel('Frequency')\n",
                "    plt.title('kNN Edge Distance Distribution')\n",
                "    plt.axvline(np.median(distances), color='r', linestyle='--', label=f'Median: {np.median(distances):.2f} km')\n",
                "    plt.legend()\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. モデル学習"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# モデル設定\n",
                "config = {\n",
                "    'hidden_dim': 128,\n",
                "    'num_layers': 2,\n",
                "    'dropout': 0.3,\n",
                "    'learning_rate': 0.001,\n",
                "    'batch_size': 1024,\n",
                "    'epochs': 50,  # Notebookでは短めに\n",
                "    'patience': 10,\n",
                "    'focal_alpha': 0.75,\n",
                "    'focal_gamma': 2.0,\n",
                "    'k_neighbors': 8,\n",
                "}\n",
                "\n",
                "print(\"モデル設定:\")\n",
                "for k, v in config.items():\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 学習実行\n",
                "RESULTS_DIR = PROJECT_ROOT / 'results' / 'spatio_temporal'\n",
                "\n",
                "trainer = SpatioTemporalTrainer(\n",
                "    data_dir=str(OUTPUT_DIR),\n",
                "    output_dir=str(RESULTS_DIR),\n",
                "    model_type='mlp',  # まずMLPベースライン\n",
                "    config=config,\n",
                ")\n",
                "\n",
                "results = trainer.run()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 評価"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# テスト予測結果の読み込み\n",
                "test_pred_path = RESULTS_DIR / 'test_predictions.parquet'\n",
                "\n",
                "if test_pred_path.exists():\n",
                "    test_pred_df = pd.read_parquet(test_pred_path)\n",
                "    print(f\"テスト予測: {len(test_pred_df):,} rows\")\n",
                "    \n",
                "    # 評価\n",
                "    y_true = test_pred_df['fatal'].values\n",
                "    y_pred = test_pred_df['prediction'].values\n",
                "    \n",
                "    metrics = evaluate_model(y_true, y_pred)\n",
                "    \n",
                "    print(\"\\n評価結果:\")\n",
                "    for k, v in metrics.items():\n",
                "        if isinstance(v, float):\n",
                "            print(f\"  {k}: {v:.4f}\")\n",
                "else:\n",
                "    print(\"テスト予測ファイルが見つかりません\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PR曲線\n",
                "from sklearn.metrics import precision_recall_curve, auc\n",
                "\n",
                "if 'y_true' in dir() and 'y_pred' in dir():\n",
                "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
                "    pr_auc = auc(recall, precision)\n",
                "    \n",
                "    plt.figure(figsize=(10, 8))\n",
                "    plt.plot(recall, precision, 'b-', lw=2, label=f'PR-AUC = {pr_auc:.4f}')\n",
                "    plt.axhline(y=y_true.mean(), color='gray', linestyle='--', label=f'Baseline = {y_true.mean():.4f}')\n",
                "    plt.xlabel('Recall', fontsize=12)\n",
                "    plt.ylabel('Precision', fontsize=12)\n",
                "    plt.title('Precision-Recall Curve', fontsize=14)\n",
                "    plt.legend(loc='best')\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 予測確率の分布\n",
                "if 'y_pred' in dir():\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "    \n",
                "    # 全体分布\n",
                "    axes[0].hist(y_pred, bins=50, edgecolor='black', alpha=0.7)\n",
                "    axes[0].set_xlabel('Predicted Probability')\n",
                "    axes[0].set_ylabel('Frequency')\n",
                "    axes[0].set_title('Prediction Distribution (All)')\n",
                "    \n",
                "    # クラス別分布\n",
                "    axes[1].hist(y_pred[y_true == 0], bins=50, alpha=0.5, label='Negative')\n",
                "    axes[1].hist(y_pred[y_true == 1], bins=50, alpha=0.5, label='Positive (Fatal)')\n",
                "    axes[1].set_xlabel('Predicted Probability')\n",
                "    axes[1].set_ylabel('Frequency')\n",
                "    axes[1].set_title('Prediction Distribution by Class')\n",
                "    axes[1].legend()\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 可視化（地図ヒートマップ）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 高リスク地点の確認\n",
                "if 'test_pred_df' in dir():\n",
                "    top_n = 100\n",
                "    high_risk = test_pred_df.nlargest(top_n, 'prediction')\n",
                "    \n",
                "    print(f\"Top-{top_n} 高リスク地点:\")\n",
                "    print(f\"  予測確率: {high_risk['prediction'].min():.4f} - {high_risk['prediction'].max():.4f}\")\n",
                "    print(f\"  実際の死亡事故: {high_risk['fatal'].sum()}/{top_n}\")\n",
                "    print(f\"  Precision@{top_n}: {high_risk['fatal'].mean():.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ヒートマップ生成\n",
                "if 'test_pred_df' in dir():\n",
                "    heatmap_path = RESULTS_DIR / 'heatmap_notebook.html'\n",
                "    \n",
                "    # 座標が有効なサンプルのみ使用\n",
                "    valid_df = test_pred_df.dropna(subset=['lat', 'lon', 'prediction'])\n",
                "    \n",
                "    if len(valid_df) > 0:\n",
                "        create_heatmap(\n",
                "            valid_df,\n",
                "            str(heatmap_path),\n",
                "            title='交通事故死亡リスク予測ヒートマップ'\n",
                "        )\n",
                "        print(f\"\\nヒートマップ保存: {heatmap_path}\")\n",
                "        print(\"ブラウザで開いて確認してください。\")\n",
                "    else:\n",
                "        print(\"有効な座標データがありません\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 地図をNotebook内で表示（foliumがインストールされている場合）\n",
                "try:\n",
                "    import folium\n",
                "    from folium.plugins import HeatMap\n",
                "    \n",
                "    if 'valid_df' in dir() and len(valid_df) > 0:\n",
                "        # サンプリング（表示用）\n",
                "        sample_df = valid_df.sample(min(5000, len(valid_df)))\n",
                "        \n",
                "        # 地図作成\n",
                "        center_lat = sample_df['lat'].mean()\n",
                "        center_lon = sample_df['lon'].mean()\n",
                "        \n",
                "        m = folium.Map(location=[center_lat, center_lon], zoom_start=6)\n",
                "        \n",
                "        heat_data = [[row['lat'], row['lon'], row['prediction']] \n",
                "                     for _, row in sample_df.iterrows()]\n",
                "        \n",
                "        HeatMap(heat_data, radius=15, blur=10).add_to(m)\n",
                "        \n",
                "        # Notebook内で表示\n",
                "        display(m)\n",
                "except ImportError:\n",
                "    print(\"foliumがインストールされていません。pip install folium でインストールしてください。\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## まとめ\n",
                "\n",
                "このNotebookでは以下を実行しました：\n",
                "\n",
                "1. **データ前処理**: ジオハッシュ生成、時系列特徴量、時間ベース分割\n",
                "2. **グラフ構築**: kNNグラフ（Haversine距離）\n",
                "3. **モデル学習**: MLP（ベースライン）\n",
                "4. **評価**: PR-AUC, ROC-AUC, Precision/Recall@k\n",
                "5. **可視化**: ヒートマップ、PR曲線\n",
                "\n",
                "### 次のステップ\n",
                "\n",
                "- kNN-GNNモデルの学習と比較\n",
                "- Optunaによるハイパーパラメータ探索\n",
                "- Temporal GNNの実装\n",
                "\n",
                "### 実行コマンド\n",
                "\n",
                "```bash\n",
                "# 全工程を一括実行\n",
                "python scripts/spatio_temporal/run.py --all\n",
                "\n",
                "# Optuna探索付き\n",
                "python scripts/spatio_temporal/run.py --all --optuna\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
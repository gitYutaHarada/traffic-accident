"""
MLP vs TabNet å…¬å¹³æ¯”è¼ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ
=================================
TabNetã¨åŒã˜ç‰¹å¾´é‡ã‚»ãƒƒãƒˆ (honhyo_clean_with_features.csv) ã‚’ä½¿ç”¨ã—ã¦
MLPã‚’å­¦ç¿’ã—ã€å…¬å¹³ãªæ¯”è¼ƒã‚’è¡Œã†ã€‚

æ¯”è¼ƒæ¡ä»¶ã‚’çµ±ä¸€:
- åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: honhyo_clean_with_features.csv
- åŒã˜Train/Teståˆ†å‰²: 80/20 random split (stratified)
- åŒã˜5-Fold CV
"""

import pandas as pd
import numpy as np
import json
import os
from pathlib import Path
from datetime import datetime
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import (
    roc_auc_score, average_precision_score, precision_recall_curve, 
    precision_score, recall_score, f1_score, brier_score_loss
)
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# --- ãƒ‘ã‚¹è¨­å®š ---
DATA_PATH = Path("data/processed/honhyo_clean_with_features.csv")
RESULTS_DIR = Path("results/spatio_temporal")
OUTPUT_DIR = RESULTS_DIR / "mlp_tabnet_comparison"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'MS Gothic'

# ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰
RANDOM_SEED = 42
torch.manual_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

# --- ãƒªãƒ¼ã‚¯é˜²æ­¢ ---
FORBIDDEN_COLUMNS = [
    'äº‹æ•…å†…å®¹',
    'äººèº«æå‚·ç¨‹åº¦ï¼ˆå½“äº‹è€…Aï¼‰', 'äººèº«æå‚·ç¨‹åº¦ï¼ˆå½“äº‹è€…Bï¼‰',
    'è² å‚·è€…æ•°',
    'è»Šä¸¡ã®æå£Šç¨‹åº¦ï¼ˆå½“äº‹è€…Aï¼‰', 'è»Šä¸¡ã®æå£Šç¨‹åº¦ï¼ˆå½“äº‹è€…Bï¼‰',
    'è»Šä¸¡ã®è¡çªéƒ¨ä½ï¼ˆå½“äº‹è€…Aï¼‰', 'è»Šä¸¡ã®è¡çªéƒ¨ä½ï¼ˆå½“äº‹è€…Bï¼‰',
    'ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Aï¼‰', 'ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Bï¼‰',
    'ã‚µã‚¤ãƒ‰ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Aï¼‰', 'ã‚µã‚¤ãƒ‰ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Bï¼‰',
]


class FocalLoss(nn.Module):
    """Focal Loss for imbalanced classification"""
    def __init__(self, alpha=0.75, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        
    def forward(self, inputs, targets):
        bce = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)
        p = torch.sigmoid(inputs)
        pt = targets * p + (1 - targets) * (1 - p)
        alpha_weight = targets * self.alpha + (1 - targets) * (1 - self.alpha)
        focal_weight = alpha_weight * (1 - pt) ** self.gamma
        return (focal_weight * bce).mean()


class MLPClassifier(nn.Module):
    """ã‚·ãƒ³ãƒ—ãƒ«ãª3å±¤MLP"""
    def __init__(self, input_dim, hidden_dim=128, dropout=0.3):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.BatchNorm1d(hidden_dim),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, 1),
        )
        
        # é‡ã¿åˆæœŸåŒ–
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.kaiming_normal_(module.weight)
                nn.init.zeros_(module.bias)
    
    def forward(self, x):
        return self.network(x)


def load_data():
    """TabNetã¨åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ (honhyo_clean_with_features.csv)...")
    df = pd.read_csv(DATA_PATH)
    print(f"   ãƒ‡ãƒ¼ã‚¿: {len(df):,} è¡Œ, {len(df.columns)} åˆ—")
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—
    target_col = 'æ­»è€…æ•°'
    y = (df[target_col] > 0).astype(int)
    
    # ç‰¹å¾´é‡
    X = df.drop(columns=[target_col])
    if 'ç™ºç”Ÿæ—¥æ™‚' in X.columns:
        X = X.drop(columns=['ç™ºç”Ÿæ—¥æ™‚'])
    
    # ãƒªãƒ¼ã‚¯ãƒã‚§ãƒƒã‚¯
    leaked = [col for col in FORBIDDEN_COLUMNS if col in X.columns]
    if leaked:
        print(f"   âš ï¸ ãƒªãƒ¼ã‚¯è­¦å‘Š: {leaked}")
        X = X.drop(columns=leaked)
    
    print(f"   ç‰¹å¾´é‡: {len(X.columns)} åˆ—")
    print(f"   ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ: 0={sum(y==0):,}, 1={sum(y==1):,} ({sum(y==1)/len(y)*100:.2f}%)")
    
    return X, y


def prepare_features(X):
    """MLPç”¨å‰å‡¦ç†ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰"""
    print("\nğŸ”§ ç‰¹å¾´é‡å‰å‡¦ç†ä¸­...")
    
    # ã™ã¹ã¦ã‚’æ•°å€¤ã«å¤‰æ›
    X_numeric = X.copy()
    
    for col in X_numeric.columns:
        if X_numeric[col].dtype == 'object':
            # ã‚«ãƒ†ã‚´ãƒªåˆ—ã¯OrdinalEncoderã§å¤‰æ›
            X_numeric[col] = pd.Categorical(X_numeric[col]).codes
        elif X_numeric[col].dtype.name == 'category':
            X_numeric[col] = X_numeric[col].cat.codes
        else:
            X_numeric[col] = pd.to_numeric(X_numeric[col], errors='coerce')
    
    # æ¬ æå€¤è£œå®Œ
    X_numeric = X_numeric.fillna(X_numeric.median())
    
    print(f"   ç‰¹å¾´é‡æ¬¡å…ƒ: {X_numeric.shape[1]}")
    
    return X_numeric.values.astype(np.float32)


def train_mlp_cv(X_train, y_train, n_folds=5, config=None):
    """5-Fold CVã§MLPã‚’å­¦ç¿’"""
    print(f"\nğŸ§  MLP {n_folds}-Fold CV å­¦ç¿’ä¸­...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"   ãƒ‡ãƒã‚¤ã‚¹: {device}")
    
    if config is None:
        config = {
            'hidden_dim': 128,
            'dropout': 0.3,
            'learning_rate': 0.001,
            'batch_size': 2048,
            'epochs': 100,
            'patience': 15,
        }
    
    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_SEED)
    
    oof_proba = np.zeros(len(y_train))
    models = []
    scalers = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):
        print(f"\n   Fold {fold+1}/{n_folds}...")
        
        X_tr, X_val = X_train[train_idx], X_train[val_idx]
        y_tr, y_val = y_train.iloc[train_idx].values, y_train.iloc[val_idx].values
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaler = StandardScaler()
        X_tr_scaled = scaler.fit_transform(X_tr)
        X_val_scaled = scaler.transform(X_val)
        scalers.append(scaler)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        train_dataset = TensorDataset(
            torch.tensor(X_tr_scaled, dtype=torch.float32),
            torch.tensor(y_tr, dtype=torch.float32).unsqueeze(1)
        )
        val_dataset = TensorDataset(
            torch.tensor(X_val_scaled, dtype=torch.float32),
            torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)
        )
        
        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = MLPClassifier(
            input_dim=X_tr_scaled.shape[1],
            hidden_dim=config['hidden_dim'],
            dropout=config['dropout']
        ).to(device)
        
        optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)
        criterion = FocalLoss(alpha=0.75, gamma=2.0)
        
        best_val_auc = 0.0
        patience_counter = 0
        best_model_state = None
        
        for epoch in range(config['epochs']):
            # å­¦ç¿’
            model.train()
            train_loss = 0.0
            
            for batch_x, batch_y in train_loader:
                batch_x = batch_x.to(device)
                batch_y = batch_y.to(device)
                
                optimizer.zero_grad()
                outputs = model(batch_x)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
            
            train_loss /= len(train_loader)
            
            # æ¤œè¨¼
            model.eval()
            val_preds = []
            val_targets = []
            
            with torch.no_grad():
                for batch_x, batch_y in val_loader:
                    batch_x = batch_x.to(device)
                    outputs = model(batch_x)
                    probs = torch.sigmoid(outputs)
                    val_preds.extend(probs.cpu().numpy().flatten())
                    val_targets.extend(batch_y.numpy().flatten())
            
            val_preds = np.array(val_preds)
            val_targets = np.array(val_targets)
            val_auc = roc_auc_score(val_targets, val_preds)
            
            scheduler.step(val_auc)
            
            # æ”¹å–„ãƒã‚§ãƒƒã‚¯
            if val_auc > best_val_auc:
                best_val_auc = val_auc
                patience_counter = 0
                best_model_state = model.state_dict().copy()
            else:
                patience_counter += 1
            
            if epoch % 10 == 0:
                print(f"      Epoch {epoch:3d}: Loss={train_loss:.4f}, Val AUC={val_auc:.4f}")
            
            if patience_counter >= config['patience']:
                print(f"      Early stopping at epoch {epoch}")
                break
        
        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        model.load_state_dict(best_model_state)
        models.append(model)
        
        # OOFäºˆæ¸¬
        model.eval()
        with torch.no_grad():
            X_val_t = torch.tensor(X_val_scaled, dtype=torch.float32).to(device)
            outputs = model(X_val_t)
            oof_proba[val_idx] = torch.sigmoid(outputs).cpu().numpy().flatten()
        
        print(f"      Fold {fold+1} Best AUC: {best_val_auc:.4f}")
    
    return models, scalers, oof_proba


def evaluate_metrics(y_true, y_pred_proba):
    """è©³ç´°ãªè©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—"""
    # åŸºæœ¬æŒ‡æ¨™
    roc_auc = roc_auc_score(y_true, y_pred_proba)
    pr_auc = average_precision_score(y_true, y_pred_proba)
    brier = brier_score_loss(y_true, y_pred_proba)
    
    # Top-k Precision
    sorted_indices = np.argsort(y_pred_proba)[::-1]
    top_k_results = {}
    for k in [100, 500, 1000]:
        if k <= len(y_true):
            top_k_idx = sorted_indices[:k]
            top_k_precision = y_true.iloc[top_k_idx].sum() / k
            top_k_results[f'precision_at_{k}'] = float(top_k_precision)
    
    # ç‰¹å®šRecallã§ã®é–¾å€¤ã¨Precision
    precision_curve, recall_curve, thresholds = precision_recall_curve(y_true, y_pred_proba)
    recall_targets = {}
    for target_recall in [0.99, 0.95, 0.90]:
        idx = np.searchsorted(recall_curve[::-1], target_recall)
        if idx < len(thresholds):
            thresh = thresholds[::-1][idx] if idx < len(thresholds) else 0.0
            prec = precision_curve[::-1][idx] if idx < len(precision_curve) else 0.0
            recall_targets[f'threshold_at_recall_{int(target_recall*100)}'] = float(thresh)
            recall_targets[f'precision_at_recall_{int(target_recall*100)}'] = float(prec)
    
    # Best F1
    f1_scores = 2 * (precision_curve * recall_curve) / (precision_curve + recall_curve + 1e-15)
    best_f1_idx = np.argmax(f1_scores)
    best_f1 = f1_scores[best_f1_idx]
    best_thresh = thresholds[best_f1_idx] if best_f1_idx < len(thresholds) else 0.5
    best_prec = precision_curve[best_f1_idx]
    best_rec = recall_curve[best_f1_idx]
    
    metrics = {
        'roc_auc': roc_auc,
        'pr_auc': pr_auc,
        'brier_score': brier,
        'best_f1': best_f1,
        'best_f1_threshold': best_thresh,
        'best_f1_precision': best_prec,
        'best_f1_recall': best_rec,
        **top_k_results,
        **recall_targets,
    }
    
    return metrics


def compare_with_tabnet_and_lgb(mlp_metrics):
    """TabNetã¨LightGBMçµæœã¨æ¯”è¼ƒ"""
    print("\n" + "=" * 70)
    print(" ğŸ”„ MLP vs TabNet vs LightGBM æ¯”è¼ƒ (åŒä¸€ãƒ‡ãƒ¼ã‚¿)")
    print("=" * 70)
    
    # æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿
    tabnet_results = {
        'roc_auc': 0.8393,
        'precision_at_recall_95': 0.0258,
    }
    
    lgb_results = {
        'roc_auc': 0.8661,
        'precision_at_recall_95': 0.0137,
    }
    
    comparisons = [
        ('ROC-AUC', 'roc_auc'),
        ('Recall 95% Precision', 'precision_at_recall_95'),
        ('PR-AUC', 'pr_auc'),
        ('Best F1', 'best_f1'),
    ]
    
    print(f"\n   {'æŒ‡æ¨™':<28} {'TabNet':<12} {'LightGBM':<12} {'MLP':<12}")
    print("   " + "-" * 64)
    
    comparison_results = {}
    for name, key in comparisons:
        tabnet_val = tabnet_results.get(key, 0)
        lgb_val = lgb_results.get(key, 0)
        mlp_val = mlp_metrics.get(key, 0)
        print(f"   {name:<28} {tabnet_val:<12.4f} {lgb_val:<12.4f} {mlp_val:<12.4f}")
        comparison_results[key] = {
            'tabnet': tabnet_val,
            'lgb': lgb_val,
            'mlp': mlp_val
        }
    
    return comparison_results


def save_results(models, scalers, oof_proba, y_train, metrics, comparison_results):
    """çµæœã‚’ä¿å­˜"""
    print("\nğŸ’¾ çµæœã‚’ä¿å­˜ä¸­...")
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    for i, model in enumerate(models):
        torch.save(model.state_dict(), OUTPUT_DIR / f"mlp_fold{i+1}.pt")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜
    results = {
        'model_type': 'mlp',
        'data_source': 'honhyo_clean_with_features.csv',
        'comparison_note': 'TabNetã¨åŒã˜ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§å­¦ç¿’',
        'oof_metrics': metrics,
        'comparison_3way': comparison_results,
    }
    with open(OUTPUT_DIR / "results_mlp_tabnet_comparison.json", 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    # OOFäºˆæ¸¬ä¿å­˜
    oof_df = pd.DataFrame({
        'true_label': y_train.values,
        'prob': oof_proba
    })
    oof_df.to_csv(OUTPUT_DIR / "oof_predictions.csv", index=False)
    
    print(f"   çµæœä¿å­˜å…ˆ: {OUTPUT_DIR}")


def main():
    start_time = datetime.now()
    
    print("=" * 70)
    print(" ğŸ§  MLP vs TabNet å…¬å¹³æ¯”è¼ƒ")
    print(" (åŒã˜ãƒ‡ãƒ¼ã‚¿: honhyo_clean_with_features.csv)")
    print("=" * 70)
    
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    X, y = load_data()
    
    # 2. å‰å‡¦ç†
    X_numeric = prepare_features(X)
    
    # 3. Train/Teståˆ†å‰² (TabNetã¨åŒã˜: 80/20)
    print("\nâœ‚ï¸ Train/Teståˆ†å‰² (80/20)...")
    X_train, X_test, y_train, y_test = train_test_split(
        X_numeric, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y
    )
    print(f"   Train: {len(y_train):,} (Fatal: {y_train.sum():,})")
    print(f"   Test:  {len(y_test):,} (Fatal: {y_test.sum():,})")
    
    # 4. 5-Fold CVã§å­¦ç¿’
    models, scalers, oof_proba = train_mlp_cv(X_train, y_train)
    
    # 5. OOFè©•ä¾¡
    print("\nğŸ“Š OOFè©•ä¾¡ (Cross Validation)...")
    oof_metrics = evaluate_metrics(y_train, oof_proba)
    
    print(f"\n   ROC-AUC: {oof_metrics['roc_auc']:.4f}")
    print(f"   PR-AUC:  {oof_metrics['pr_auc']:.4f}")
    print(f"   Best F1: {oof_metrics['best_f1']:.4f} (é–¾å€¤: {oof_metrics['best_f1_threshold']:.4f})")
    print(f"   Recall 95% Precision: {oof_metrics.get('precision_at_recall_95', 0):.4f}")
    
    # 6. ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡
    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    test_proba = np.zeros(len(y_test))
    
    for model, scaler in zip(models, scalers):
        X_test_scaled = scaler.transform(X_test)
        X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)
        
        model.eval()
        with torch.no_grad():
            outputs = model(X_test_t)
            test_proba += torch.sigmoid(outputs).cpu().numpy().flatten() / len(models)
    
    test_metrics = evaluate_metrics(y_test, test_proba)
    print(f"   Test ROC-AUC: {test_metrics['roc_auc']:.4f}")
    print(f"   Test PR-AUC:  {test_metrics['pr_auc']:.4f}")
    print(f"   Test Best F1: {test_metrics['best_f1']:.4f}")
    print(f"   Test Recall 95% Precision: {test_metrics.get('precision_at_recall_95', 0):.4f}")
    
    # 7. æ¯”è¼ƒ
    comparison_results = compare_with_tabnet_and_lgb(oof_metrics)
    
    # 8. çµæœä¿å­˜
    save_results(models, scalers, oof_proba, y_train, oof_metrics, comparison_results)
    
    elapsed = (datetime.now() - start_time).total_seconds()
    
    print("\nğŸ‰ MLPå­¦ç¿’å®Œäº†ï¼")
    
    # ã‚µãƒãƒªãƒ¼å‡ºåŠ›
    print("\n" + "=" * 70)
    print(" ğŸ“‹ ã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    print(f"   ãƒ‡ãƒ¼ã‚¿: honhyo_clean_with_features.csv ({len(X):,} ä»¶)")
    print(f"   ç‰¹å¾´é‡: {X_numeric.shape[1]} æ¬¡å…ƒ")
    print(f"   MLP OOF ROC-AUC: {oof_metrics['roc_auc']:.4f}")
    print(f"   MLP OOF PR-AUC:  {oof_metrics['pr_auc']:.4f}")
    print(f"   MLP OOF Recall95%æ™‚Precision: {oof_metrics.get('precision_at_recall_95', 0):.4f}")
    print(f"   MLP Test ROC-AUC: {test_metrics['roc_auc']:.4f}")
    print(f"   æ‰€è¦æ™‚é–“: {elapsed:.1f}ç§’")


if __name__ == "__main__":
    main()

"""
Spatio-Temporal Stage2 çµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
========================================
ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‹ã‚‰åœ°å›³å¯è¦–åŒ–ã¾ã§ä¸€æ‹¬å®Ÿè¡Œ
"""

import os
import sys
import argparse
import json
from datetime import datetime
from pathlib import Path
from typing import Optional
import warnings

warnings.filterwarnings('ignore')

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
SCRIPT_DIR = Path(__file__).parent
sys.path.insert(0, str(SCRIPT_DIR))


def run_pipeline(
    data_path: str = "data/processed/honhyo_for_analysis_with_traffic_hospital_no_leakage.csv",
    output_dir: str = "results/spatio_temporal",
    data_dir: Optional[str] = None,
    models: list = ['mlp', 'knn_gnn'],
    train_years: str = "2018,2019",
    val_years: str = "2020,2020",
    test_years: str = "2021,2024",
    run_optuna: bool = False,
    n_optuna_trials: int = 50,
    epochs: int = 100,
    batch_size: int = 1024,
    k_neighbors: int = 8,
    skip_preprocess: bool = False,
    skip_train: bool = False,
    skip_visualize: bool = False,
):
    """
    å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    
    1. å‰å‡¦ç†
    2. ã‚°ãƒ©ãƒ•æ§‹ç¯‰
    3. (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) Optunaæ¢ç´¢
    4. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    5. è©•ä¾¡
    6. å¯è¦–åŒ–
    7. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    """
    
    print("=" * 70)
    print("ğŸš€ Spatio-Temporal Stage2 Pipeline")
    print(f"   é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    start_time = datetime.now()
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    if data_dir is None:
        data_dir = Path("data/spatio_temporal")
    else:
        data_dir = Path(data_dir)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆãªã‘ã‚Œã°ï¼‰
    data_dir.mkdir(parents=True, exist_ok=True)
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    results = {}
    
    # =====================
    # 1. å‰å‡¦ç†
    # =====================
    if not skip_preprocess:
        print("\n" + "=" * 50)
        print("ğŸ“¦ Step 1: å‰å‡¦ç†")
        print("=" * 50)
        
        from preprocess_spatio_temporal import SpatioTemporalPreprocessor
        
        train_y = tuple(map(int, train_years.split(',')))
        val_y = tuple(map(int, val_years.split(',')))
        test_y = tuple(map(int, test_years.split(',')))
        
        preprocessor = SpatioTemporalPreprocessor(
            data_path=data_path,
            output_dir=str(data_dir),
            train_years=train_y,
            val_years=val_y,
            test_years=test_y,
        )
        
        preprocess_result = preprocessor.run()
        results['preprocess'] = preprocess_result
    else:
        print("\nâ­ï¸ å‰å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    
    # =====================
    # 2. ã‚°ãƒ©ãƒ•æ§‹ç¯‰
    # =====================
    print("\n" + "=" * 50)
    print("ğŸ”— Step 2: ã‚°ãƒ©ãƒ•æ§‹ç¯‰")
    print("=" * 50)
    
    import pandas as pd
    from graph_builder import build_geohash_level_graph
    
    train_df = pd.read_parquet(data_dir / "preprocessed_train.parquet")
    graph_data = build_geohash_level_graph(train_df, k=k_neighbors, output_dir=data_dir)
    
    results['graph'] = {
        'n_nodes': graph_data['n_nodes'],
        'n_edges': graph_data['edge_index'].shape[1],
    }
    
    # =====================
    # 3. Optunaæ¢ç´¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    # =====================
    best_params = None
    if run_optuna:
        print("\n" + "=" * 50)
        print("ğŸ” Step 3: Optunaæ¢ç´¢")
        print("=" * 50)
        
        from optuna_search import run_optuna_search
        
        best_params = run_optuna_search(
            data_dir=str(data_dir),
            output_dir=str(output_dir / "optuna"),
            model_type='knn_gnn',
            n_trials=n_optuna_trials,
            n_epochs=50,
        )
        
        results['optuna'] = best_params
    
    # =====================
    # 4. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    # =====================
    if not skip_train:
        print("\n" + "=" * 50)
        print("ğŸŒ¿ Step 4: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
        print("=" * 50)
        
        from train_spatio_temporal import SpatioTemporalTrainer
        
        model_results = {}
        
        for model_type in models:
            print(f"\n--- {model_type} ---")
            
            config = {
                'hidden_dim': best_params.get('hidden_dim', 128) if best_params else 128,
                'num_layers': best_params.get('num_layers', 2) if best_params else 2,
                'dropout': best_params.get('dropout', 0.3) if best_params else 0.3,
                'learning_rate': best_params.get('learning_rate', 0.001) if best_params else 0.001,
                'batch_size': batch_size,
                'epochs': epochs,
                'patience': 15,
                'focal_alpha': best_params.get('focal_alpha', 0.75) if best_params else 0.75,
                'focal_gamma': best_params.get('focal_gamma', 2.0) if best_params else 2.0,
                'k_neighbors': k_neighbors,
            }
            
            trainer = SpatioTemporalTrainer(
                data_dir=str(data_dir),
                output_dir=str(output_dir),
                model_type=model_type,
                config=config,
            )
            
            result = trainer.run()
            model_results[model_type] = result
        
        results['models'] = model_results
    else:
        print("\nâ­ï¸ å­¦ç¿’ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    
    # =====================
    # 5. å¯è¦–åŒ–
    # =====================
    if not skip_visualize:
        print("\n" + "=" * 50)
        print("ğŸ“Š Step 5: å¯è¦–åŒ–")
        print("=" * 50)
        
        from visualize import Visualizer, plot_pr_curve, plot_roc_curve, create_heatmap
        import numpy as np
        
        visualizer = Visualizer(output_dir=str(output_dir))
        
        # äºˆæ¸¬çµæœã®èª­ã¿è¾¼ã¿
        test_pred_path = output_dir / "test_predictions.parquet"
        if test_pred_path.exists():
            test_df = pd.read_parquet(test_pred_path)
            
            # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆ
            if 'lat' in test_df.columns and 'lon' in test_df.columns:
                create_heatmap(
                    test_df.dropna(subset=['lat', 'lon', 'prediction']),
                    str(output_dir / "heatmap.html"),
                )
                
                # Top-Nåœ°å›³
                from visualize import create_top_n_map
                create_top_n_map(
                    test_df.dropna(subset=['lat', 'lon', 'prediction']),
                    str(output_dir / "top_n_map.html"),
                    n=100,
                )
            
            # PR/ROCæ›²ç·š
            if 'fatal' in test_df.columns and 'prediction' in test_df.columns:
                y_true = test_df['fatal'].values
                y_pred = test_df['prediction'].values
                
                model_results_for_curves = {
                    'Spatio-Temporal': (y_true, y_pred)
                }
                
                plot_pr_curve(model_results_for_curves, str(output_dir / "pr_curve.png"))
                plot_roc_curve(model_results_for_curves, str(output_dir / "roc_curve.png"))
        
        print("   å¯è¦–åŒ–å®Œäº†")
    else:
        print("\nâ­ï¸ å¯è¦–åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    
    # =====================
    # 6. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    # =====================
    print("\n" + "=" * 50)
    print("ğŸ“„ Step 6: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    print("=" * 50)
    
    elapsed = (datetime.now() - start_time).total_seconds()
    
    # results_summary.json
    summary = {
        'timestamp': datetime.now().isoformat(),
        'elapsed_seconds': elapsed,
        'data_path': data_path,
        'models': models,
        'results': results,
    }
    
    # ãƒ¢ãƒ‡ãƒ«çµæœã‹ã‚‰ä¸»è¦æŒ‡æ¨™ã‚’æŠ½å‡º
    if 'models' in results:
        for model_name, model_result in results['models'].items():
            if 'test_metrics' in model_result:
                summary[f'{model_name}_pr_auc'] = model_result['test_metrics'].get('pr_auc', 0)
                summary[f'{model_name}_roc_auc'] = model_result['test_metrics'].get('roc_auc', 0)
    
    with open(output_dir / "results_summary.json", 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
    
    # Markdownãƒ¬ãƒãƒ¼ãƒˆ
    report = generate_markdown_report(results, elapsed, output_dir)
    
    with open(output_dir / "experiment_report.md", 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("\n" + "=" * 70)
    print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼")
    print(f"   æ‰€è¦æ™‚é–“: {elapsed:.1f}ç§’ ({elapsed/60:.1f}åˆ†)")
    print(f"   çµæœ: {output_dir}")
    print("=" * 70)
    
    return results


def generate_markdown_report(results: dict, elapsed: float, output_dir: Path) -> str:
    """Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    report = []
    report.append("# Spatio-Temporal Stage2 å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆ\n")
    report.append(f"**å®Ÿè¡Œæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    report.append(f"**æ‰€è¦æ™‚é–“**: {elapsed:.1f}ç§’\n")
    
    # å‰å‡¦ç†çµæœ
    if 'preprocess' in results:
        report.append("\n## 1. å‰å‡¦ç†\n")
        p = results['preprocess']
        report.append(f"- Train: {p.get('train_size', 0):,} ä»¶\n")
        report.append(f"- Validation: {p.get('val_size', 0):,} ä»¶\n")
        report.append(f"- Test: {p.get('test_size', 0):,} ä»¶\n")
        report.append(f"- ç‰¹å¾´é‡æ•°: {p.get('n_features', 0)}\n")
    
    # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
    if 'graph' in results:
        report.append("\n## 2. ã‚°ãƒ©ãƒ•æ§‹ç¯‰\n")
        g = results['graph']
        report.append(f"- ãƒãƒ¼ãƒ‰æ•°: {g.get('n_nodes', 0):,}\n")
        report.append(f"- ã‚¨ãƒƒã‚¸æ•°: {g.get('n_edges', 0):,}\n")
    
    # ãƒ¢ãƒ‡ãƒ«çµæœ
    if 'models' in results:
        report.append("\n## 3. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ\n")
        report.append("\n| ãƒ¢ãƒ‡ãƒ« | PR-AUC | ROC-AUC | ECE | Brier Score |\n")
        report.append("|--------|--------|---------|-----|-------------|\n")
        
        for model_name, model_result in results['models'].items():
            if 'test_metrics' in model_result:
                m = model_result['test_metrics']
                report.append(
                    f"| {model_name} | {m.get('pr_auc', 0):.4f} | "
                    f"{m.get('roc_auc', 0):.4f} | {m.get('ece', 0):.4f} | "
                    f"{m.get('brier_score', 0):.4f} |\n"
                )
        
        # Precision/Recall@k
        report.append("\n### Precision/Recall@k\n")
        report.append("\n| ãƒ¢ãƒ‡ãƒ« | P@100 | R@100 | P@500 | R@500 |\n")
        report.append("|--------|-------|-------|-------|-------|\n")
        
        for model_name, model_result in results['models'].items():
            if 'test_metrics' in model_result:
                m = model_result['test_metrics']
                report.append(
                    f"| {model_name} | {m.get('precision_at_100', 0):.4f} | "
                    f"{m.get('recall_at_100', 0):.4f} | {m.get('precision_at_500', 0):.4f} | "
                    f"{m.get('recall_at_500', 0):.4f} |\n"
                )
    
    # å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«
    report.append("\n## 4. ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«\n")
    report.append(f"- [ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—](heatmap.html)\n")
    report.append(f"- [Top-Nåœ°ç‚¹ãƒãƒƒãƒ—](top_n_map.html)\n")
    report.append(f"- [PRæ›²ç·š](pr_curve.png)\n")
    report.append(f"- [ROCæ›²ç·š](roc_curve.png)\n")
    report.append(f"- [çµæœã‚µãƒãƒª](results_summary.json)\n")
    
    return "".join(report)


def main():
    parser = argparse.ArgumentParser(
        description="Spatio-Temporal Stage2 Complete Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # å…¨å·¥ç¨‹å®Ÿè¡Œ
  python run.py --all
  
  # å‰å‡¦ç†ã®ã¿
  python run.py --preprocess-only
  
  # å­¦ç¿’ã®ã¿ï¼ˆå‰å‡¦ç†æ¸ˆã¿ï¼‰
  python run.py --skip-preprocess
  
  # Optunaæ¢ç´¢ä»˜ã
  python run.py --all --optuna
""")
    
    parser.add_argument('--all', action='store_true', help='å…¨å·¥ç¨‹ã‚’å®Ÿè¡Œ')
    parser.add_argument('--data-path', type=str,
                        default="data/processed/honhyo_for_analysis_with_traffic_hospital_no_leakage.csv")
    parser.add_argument('--data-dir', type=str, default=None,
                        help="å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: data/spatio_temporalï¼‰")
    parser.add_argument('--output-dir', type=str, default="results/spatio_temporal")
    parser.add_argument('--models', type=str, default="mlp,knn_gnn",
                        help="å­¦ç¿’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰")
    parser.add_argument('--train-years', type=str, default="2018,2019")
    parser.add_argument('--val-years', type=str, default="2020,2020")
    parser.add_argument('--test-years', type=str, default="2021,2024")
    
    parser.add_argument('--optuna', action='store_true', help='Optunaæ¢ç´¢ã‚’å®Ÿè¡Œ')
    parser.add_argument('--n-optuna-trials', type=int, default=50)
    
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--batch-size', type=int, default=1024)
    parser.add_argument('--k', type=int, default=8, help='kNN graph k')
    
    parser.add_argument('--skip-preprocess', action='store_true')
    parser.add_argument('--skip-train', action='store_true')
    parser.add_argument('--skip-visualize', action='store_true')
    parser.add_argument('--preprocess-only', action='store_true')
    
    args = parser.parse_args()
    
    if args.preprocess_only:
        args.skip_train = True
        args.skip_visualize = True
    
    models = args.models.split(',')
    
    run_pipeline(
        data_path=args.data_path,
        output_dir=args.output_dir,
        data_dir=args.data_dir,
        models=models,
        train_years=args.train_years,
        val_years=args.val_years,
        test_years=args.test_years,
        run_optuna=args.optuna,
        n_optuna_trials=args.n_optuna_trials,
        epochs=args.epochs,
        batch_size=args.batch_size,
        k_neighbors=args.k,
        skip_preprocess=args.skip_preprocess,
        skip_train=args.skip_train,
        skip_visualize=args.skip_visualize,
    )


if __name__ == "__main__":
    main()

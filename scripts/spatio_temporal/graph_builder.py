"""
ã‚°ãƒ©ãƒ•æ§‹ç¯‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
==================
kNNã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ï¼ˆHaversineè·é›¢ï¼‰
PyTorch Geometricå½¢å¼ã§ã®ã‚¨ãƒƒã‚¸ãƒªã‚¹ãƒˆå‡ºåŠ›
"""

import numpy as np
import pandas as pd
from typing import Tuple, Optional, Dict
from pathlib import Path
import joblib
from scipy.spatial import cKDTree
from sklearn.neighbors import BallTree
import torch

# ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰å›ºå®š
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)


def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
    """
    Haversineè·é›¢ã®è¨ˆç®—ï¼ˆkmï¼‰
    """
    R = 6371  # åœ°çƒã®åŠå¾„ (km)
    
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    
    return R * c


class GraphBuilder:
    """kNNã‚°ãƒ©ãƒ•æ§‹ç¯‰ã‚¯ãƒ©ã‚¹"""
    
    def __init__(
        self,
        k: int = 8,
        max_distance_km: float = 50.0,
        use_haversine: bool = True,
    ):
        """
        Args:
            k: kNNã®kå€¤
            max_distance_km: æœ€å¤§è·é›¢åˆ¶é™ï¼ˆkmï¼‰
            use_haversine: Haversineè·é›¢ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        """
        self.k = k
        self.max_distance_km = max_distance_km
        self.use_haversine = use_haversine
    
    def build_knn_graph(
        self,
        coords: np.ndarray,
        return_distances: bool = True,
    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:
        """
        kNNã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰
        
        Args:
            coords: åº§æ¨™é…åˆ— [N, 2] (lat, lon)
            return_distances: è·é›¢ã‚’è¿”ã™ã‹
            
        Returns:
            edge_index: [2, num_edges]
            edge_attr: [num_edges, 1] (è·é›¢ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        """
        n_samples = len(coords)
        
        if self.use_haversine:
            # BallTreeã‚’ä½¿ç”¨ã—ã¦Haversineè·é›¢ã§kNNã‚’è¨ˆç®—
            coords_rad = np.radians(coords)
            tree = BallTree(coords_rad, metric='haversine')
            
            # k+1ã‚’å–å¾—ï¼ˆè‡ªåˆ†è‡ªèº«ã‚’å«ã‚€ï¼‰
            distances, indices = tree.query(coords_rad, k=min(self.k + 1, n_samples))
            
            # è·é›¢ã‚’kmã«å¤‰æ›
            distances = distances * 6371  # åœ°çƒã®åŠå¾„
        else:
            # ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã§kNNï¼ˆè¿‘ä¼¼ï¼‰
            tree = cKDTree(coords)
            distances, indices = tree.query(coords, k=min(self.k + 1, n_samples))
        
        # ã‚¨ãƒƒã‚¸ãƒªã‚¹ãƒˆã®æ§‹ç¯‰
        edge_list = []
        edge_distances = []
        
        for i in range(n_samples):
            for j_idx in range(1, len(indices[i])):  # è‡ªåˆ†è‡ªèº«ã‚’é™¤ã
                j = indices[i][j_idx]
                dist = distances[i][j_idx]
                
                # è·é›¢åˆ¶é™
                if dist <= self.max_distance_km:
                    edge_list.append([i, j])
                    edge_distances.append(dist)
        
        if not edge_list:
            # ã‚¨ãƒƒã‚¸ãŒãªã„å ´åˆï¼ˆå­¤ç«‹ãƒãƒ¼ãƒ‰ï¼‰
            edge_index = torch.zeros((2, 0), dtype=torch.long)
            edge_attr = torch.zeros((0, 1), dtype=torch.float32) if return_distances else None
        else:
            edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()
            edge_attr = torch.tensor(edge_distances, dtype=torch.float32).unsqueeze(1) if return_distances else None
        
        return edge_index, edge_attr
    
    def build_temporal_graph(
        self,
        df: pd.DataFrame,
        time_window: str = 'D',  # 'D': æ—¥, 'W': é€±
    ) -> Dict[str, Tuple[torch.Tensor, torch.Tensor]]:
        """
        æ™‚ç³»åˆ—ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆlat, lon, dateåˆ—ã‚’å«ã‚€ï¼‰
            time_window: æ™‚é–“ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            
        Returns:
            graphs: {æ™‚é–“ã‚­ãƒ¼: (edge_index, edge_attr)}
        """
        graphs = {}
        
        df['time_key'] = df['date'].dt.to_period(time_window).astype(str)
        
        for time_key, group in df.groupby('time_key'):
            if len(group) < 2:
                continue
            
            coords = group[['lat', 'lon']].values
            edge_index, edge_attr = self.build_knn_graph(coords)
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
            local_to_global = {i: idx for i, idx in enumerate(group.index)}
            
            graphs[time_key] = {
                'edge_index': edge_index,
                'edge_attr': edge_attr,
                'node_indices': group.index.tolist(),
            }
        
        return graphs
    
    def build_geohash_graph(
        self,
        df: pd.DataFrame,
        geohash_col: str = 'geohash',
    ) -> Tuple[torch.Tensor, torch.Tensor, Dict]:
        """
        ã‚¸ã‚ªãƒãƒƒã‚·ãƒ¥ãƒ¬ãƒ™ãƒ«ã§ã®ã‚°ãƒ©ãƒ•æ§‹ç¯‰
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            geohash_col: ã‚¸ã‚ªãƒãƒƒã‚·ãƒ¥åˆ—å
            
        Returns:
            edge_index: ã‚¸ã‚ªãƒãƒƒã‚·ãƒ¥é–“ã®ã‚¨ãƒƒã‚¸
            edge_attr: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡
            geohash_info: ã‚¸ã‚ªãƒãƒƒã‚·ãƒ¥æƒ…å ±
        """
        # ã‚¸ã‚ªãƒãƒƒã‚·ãƒ¥ã”ã¨ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—
        geohash_coords = df.groupby(geohash_col).agg({
            'lat': 'mean',
            'lon': 'mean',
        }).reset_index()
        
        geohash_to_idx = {gh: i for i, gh in enumerate(geohash_coords[geohash_col])}
        
        coords = geohash_coords[['lat', 'lon']].values
        edge_index, edge_attr = self.build_knn_graph(coords)
        
        geohash_info = {
            'geohash_to_idx': geohash_to_idx,
            'idx_to_geohash': {v: k for k, v in geohash_to_idx.items()},
            'geohash_coords': geohash_coords,
        }
        
        return edge_index, edge_attr, geohash_info


def build_sample_graph(
    df: pd.DataFrame,
    k: int = 8,
    output_dir: Optional[Path] = None,
) -> Dict:
    """
    äº‹æ•…ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒãƒ¼ãƒ‰ã¨ã—ãŸkNNã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰
    
    Args:
        df: å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        k: kNNã®kå€¤
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        graph_data: ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿è¾æ›¸
    """
    print(f"\nğŸ“Š kNNã‚°ãƒ©ãƒ•æ§‹ç¯‰ä¸­ (k={k})...")
    
    builder = GraphBuilder(k=k)
    
    coords = df[['lat', 'lon']].values
    edge_index, edge_attr = builder.build_knn_graph(coords)
    
    print(f"   ãƒãƒ¼ãƒ‰æ•°: {len(df):,}")
    print(f"   ã‚¨ãƒƒã‚¸æ•°: {edge_index.shape[1]:,}")
    print(f"   å¹³å‡æ¬¡æ•°: {edge_index.shape[1] / len(df):.2f}")
    
    graph_data = {
        'edge_index': edge_index,
        'edge_attr': edge_attr,
        'n_nodes': len(df),
        'k': k,
    }
    
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        torch.save(graph_data, output_dir / "graph_data.pt")
        print(f"   ä¿å­˜å…ˆ: {output_dir / 'graph_data.pt'}")
    
    return graph_data


def build_geohash_level_graph(
    df: pd.DataFrame,
    geohash_col: str = 'geohash',
    k: int = 8,
    output_dir: Optional[Path] = None,
) -> Dict:
    """
    ã‚¸ã‚ªãƒãƒƒã‚·ãƒ¥ãƒ¬ãƒ™ãƒ«ã®ã‚°ãƒ©ãƒ•æ§‹ç¯‰
    """
    print(f"\nğŸ“Š ã‚¸ã‚ªãƒãƒƒã‚·ãƒ¥ãƒ¬ãƒ™ãƒ«ã‚°ãƒ©ãƒ•æ§‹ç¯‰ä¸­ (k={k})...")
    
    builder = GraphBuilder(k=k)
    edge_index, edge_attr, geohash_info = builder.build_geohash_graph(df, geohash_col)
    
    n_geohashes = len(geohash_info['geohash_to_idx'])
    print(f"   ã‚¸ã‚ªãƒãƒƒã‚·ãƒ¥æ•°: {n_geohashes:,}")
    print(f"   ã‚¨ãƒƒã‚¸æ•°: {edge_index.shape[1]:,}")
    
    graph_data = {
        'edge_index': edge_index,
        'edge_attr': edge_attr,
        'geohash_info': geohash_info,
        'n_nodes': n_geohashes,
        'k': k,
    }
    
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        torch.save(graph_data, output_dir / "geohash_graph_data.pt")
        joblib.dump(geohash_info, output_dir / "geohash_info.joblib")
        print(f"   ä¿å­˜å…ˆ: {output_dir}")
    
    return graph_data


def build_inductive_graph(
    train_df: pd.DataFrame,
    val_df: pd.DataFrame,
    test_df: pd.DataFrame,
    k: int = 8,
    output_dir: Optional[Path] = None,
) -> Dict:
    """
    Inductiveå­¦ç¿’ç”¨ã®ã‚°ãƒ©ãƒ•æ§‹ç¯‰
    
    Train/Val/Testã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’1ã¤ã®ã‚°ãƒ©ãƒ•ã¨ã—ã¦æ§‹ç¯‰ã—ã€
    ãƒãƒ¼ãƒ‰ãƒã‚¹ã‚¯ã§å„ã‚»ãƒƒãƒˆã‚’åŒºåˆ¥ã™ã‚‹
    
    Args:
        train_df: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        val_df: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
        test_df: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        k: kNNã®kå€¤
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        graph_data: ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿è¾æ›¸ï¼ˆedge_index, maskså«ã‚€ï¼‰
    """
    print(f"\nğŸ“Š Inductive kNNã‚°ãƒ©ãƒ•æ§‹ç¯‰ä¸­ (k={k})...")
    
    # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    n_train = len(train_df)
    n_val = len(val_df)
    n_test = len(test_df)
    n_total = n_train + n_val + n_test
    
    print(f"   Train: {n_train:,} / Val: {n_val:,} / Test: {n_test:,}")
    print(f"   Total: {n_total:,}")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
    combined_df = pd.concat([train_df, val_df, test_df], ignore_index=True)
    
    # kNNã‚°ãƒ©ãƒ•æ§‹ç¯‰
    builder = GraphBuilder(k=k)
    coords = combined_df[['lat', 'lon']].values
    edge_index, edge_attr = builder.build_knn_graph(coords)
    
    # ãƒãƒ¼ãƒ‰ãƒã‚¹ã‚¯ã‚’ä½œæˆ
    train_mask = torch.zeros(n_total, dtype=torch.bool)
    val_mask = torch.zeros(n_total, dtype=torch.bool)
    test_mask = torch.zeros(n_total, dtype=torch.bool)
    
    train_mask[:n_train] = True
    val_mask[n_train:n_train + n_val] = True
    test_mask[n_train + n_val:] = True
    
    print(f"   ãƒãƒ¼ãƒ‰æ•°: {n_total:,}")
    print(f"   ã‚¨ãƒƒã‚¸æ•°: {edge_index.shape[1]:,}")
    print(f"   å¹³å‡æ¬¡æ•°: {edge_index.shape[1] / n_total:.2f}")
    
    graph_data = {
        'edge_index': edge_index,
        'edge_attr': edge_attr,
        'train_mask': train_mask,
        'val_mask': val_mask,
        'test_mask': test_mask,
        'n_nodes': n_total,
        'n_train': n_train,
        'n_val': n_val,
        'n_test': n_test,
        'k': k,
        'combined_df': combined_df,  # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
    }
    
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        # combined_dfã¯ä¿å­˜ã—ãªã„ï¼ˆå¤§ãã™ãã‚‹ï¼‰
        save_data = {k: v for k, v in graph_data.items() if k != 'combined_df'}
        torch.save(save_data, output_dir / "inductive_graph_data.pt")
        print(f"   ä¿å­˜å…ˆ: {output_dir / 'inductive_graph_data.pt'}")
    
    return graph_data


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Graph Builder")
    parser.add_argument('--data-path', type=str, default="data/spatio_temporal/preprocessed_train.parquet")
    parser.add_argument('--output-dir', type=str, default="data/spatio_temporal")
    parser.add_argument('--k', type=int, default=8)
    parser.add_argument('--graph-type', type=str, choices=['sample', 'geohash'], default='geohash')
    
    args = parser.parse_args()
    
    df = pd.read_parquet(args.data_path)
    
    if args.graph_type == 'sample':
        build_sample_graph(df, k=args.k, output_dir=Path(args.output_dir))
    else:
        build_geohash_level_graph(df, k=args.k, output_dir=Path(args.output_dir))

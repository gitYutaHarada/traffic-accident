import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.preprocessing import LabelEncoder
import cleanlab
from cleanlab.filter import find_label_issues
import os
import gc
import joblib

# ============================================================================
# è¨­å®š
# ============================================================================
FEATURES_PATH = "data/processed/honhyo_clean_with_features.csv"
RAW_DATA_PATH = "honhyo_all/csv/honhyo_all_with_datetime.csv"
TARGET_COL = "æ­»è€…æ•°"
OUTPUT_DIR = "results/data_quality/cleanlab"
RANDOM_STATE = 42
N_FOLDS = 5

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ============================================================================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (train_stage2_multiclass.py ã‹ã‚‰æ‹å€Ÿ)
# ============================================================================
def load_and_preprocess():
    print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    
    # ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿
    df_features = pd.read_csv(FEATURES_PATH)
    
    # ãƒ©ãƒ™ãƒ«ç”Ÿæˆ (0:è² å‚·, 1:æ­»äº¡)
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡æ‘˜ã«ã‚ˆã‚Šç„¡å‚·(Class 0)ã¯å­˜åœ¨aã—ãªã„å‰æ
    y_binary = (df_features[TARGET_COL] > 0).astype(int)
    
    # ç‰¹å¾´é‡
    X = df_features.drop(columns=[TARGET_COL])
    if 'ç™ºç”Ÿæ—¥æ™‚' in X.columns:
        X = X.drop(columns=['ç™ºç”Ÿæ—¥æ™‚'])
        
    print(f"   ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(X):,}")
    print(f"   ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ (0:è² å‚·, 1:æ­»äº¡): {np.bincount(y_binary)}")
    
    # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®å‡¦ç†
    for col in X.columns:
        if X[col].dtype == 'object':
            X[col] = X[col].astype('category')
            
    # Train/Test Split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_binary, test_size=0.2, random_state=RANDOM_STATE, stratify=y_binary
    )
    
    return X_train, y_train, X_test, y_test

# ============================================================================
# Cleanlab å®Ÿè¡Œ
# ============================================================================
def run_cleanlab():
    X_train, y_train, _, _ = load_and_preprocess()
    print(f"DEBUG: X_train type: {type(X_train)}")
    print(f"DEBUG: y_train type: {type(y_train)}")
    
    print("\nğŸš€ Cross-Validation ã§äºˆæ¸¬ç¢ºç‡ã‚’ç®—å‡ºä¸­ (Binary LightGBM)...")
    
    # LightGBM ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Binary)
    lgb_params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'verbosity': -1,
        'n_estimators': 1000,
        'learning_rate': 0.05,
        'num_leaves': 31,
        'scale_pos_weight': float(np.sum(y_train==0) / np.sum(y_train==1)) # Balanced Weight
    }
    
    # CVã§ç¢ºç‡ç®—å‡º
    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)
    
    final_probs = np.zeros((len(y_train), 2))
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):
        print(f"   Fold {fold+1}/{N_FOLDS}...")
        X_tr = X_train.iloc[train_idx]
        y_tr = y_train.iloc[train_idx]
        X_val = X_train.iloc[val_idx]
        y_val = y_train.iloc[val_idx]
        
        model = lgb.LGBMClassifier(**lgb_params, random_state=RANDOM_STATE+fold)
        
        model.fit(
            X_tr, y_tr,
            eval_set=[(X_val, y_val)],
            callbacks=[lgb.early_stopping(50, verbose=False)]
        )
        
        # äºˆæ¸¬ç¢ºç‡ (N, 2)
        probs = model.predict_proba(X_val)
        final_probs[val_idx] = probs
        
    print("\nğŸ” Confident Learning (Cleanlab) ã§ãƒ©ãƒ™ãƒ«ãƒã‚¤ã‚ºæ¢ç´¢ä¸­...")
    
    # Cleanlabå®Ÿè¡Œ
    # find_label_issues with return_indices_ranked_by returns a numpy array of indices, NOT a DataFrame!
    issue_indices = find_label_issues(
        labels=y_train.values,
        pred_probs=final_probs,
        return_indices_ranked_by='self_confidence',
        n_jobs=1
    )
    
    print(f"\nâœ… ç™ºè¦‹ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«å“è³ªå•é¡Œ: {len(issue_indices):,} ä»¶")
    
    # DataFrameã‚’æ§‹ç¯‰ (issue_indices ã¯ numpy array of integer indices into y_train/X_train)
    # å…ƒã®DataFrameã®index (honhyo_all.csvã®è¡Œç•ªå·ã«ç›¸å½“) ã‚’å–å¾—
    original_indices = X_train.index[issue_indices]
    given_labels = y_train.values[issue_indices]
    predicted_labels = np.argmax(final_probs[issue_indices], axis=1)
    
    # ãƒ©ãƒ™ãƒ«å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    from cleanlab.rank import get_label_quality_scores
    quality_scores = get_label_quality_scores(y_train.values, final_probs)
    issue_quality_scores = quality_scores[issue_indices]
    
    issues_df = pd.DataFrame({
        'issue_index': issue_indices,  # 0-indexed position in X_train
        'original_index': original_indices,  # Original DataFrame index
        'given_label': given_labels,
        'predicted_label': predicted_labels,
        'label_quality': issue_quality_scores
    })
    
    # è©³ç´°åˆ†æ: "Label=0 (Injury) but Predicted=1 (Fatal)" (High Confidence)
    # ã“ã‚ŒãŒã€Œæ­»äº¡äº‹æ•…ã«è¦‹ãˆã‚‹è² å‚·äº‹æ•…ã€
    
    fatal_lookalikes = issues_df[
        (issues_df['given_label'] == 0) & 
        (issues_df['predicted_label'] == 1)
    ]
    
    print(f"   âš ï¸ ã€Œè² å‚·(0)ã€ãƒ©ãƒ™ãƒ«ã ãŒã€Œæ­»äº¡(1)ã€ã¨é«˜ç¢ºä¿¡åº¦ã§äºˆæ¸¬ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿: {len(fatal_lookalikes):,} ä»¶")
    print(f"       (ã“ã‚Œã‚‰ãŒãƒ¢ãƒ‡ãƒ«ã®å¢ƒç•Œã‚’æ­ªã‚ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ã„)")
    
    # çµæœä¿å­˜
    save_path = os.path.join(OUTPUT_DIR, "label_issues.csv")
    issues_df.to_csv(save_path, index=False)
    
    # ãƒã‚¤ã‚ºã‚’é™¤å»ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆã‚‚ä¿å­˜
    noise_indices = fatal_lookalikes['original_index'].values
    np.savetxt(os.path.join(OUTPUT_DIR, "noise_indices_fatal_lookalike.txt"), noise_indices, fmt='%d')

    print(f"\n   ğŸ’¾ ä¿å­˜å®Œäº†: {save_path}")
    print(f"   ğŸ’¾ ãƒã‚¤ã‚ºã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹(Fatal Lookalike): {os.path.join(OUTPUT_DIR, 'noise_indices_fatal_lookalike.txt')}")
    
    # å…·ä½“çš„ãªä¾‹ã‚’è¡¨ç¤º
    print("\n   [Examples (Top 5 Fatal Look-alikes)]")
    print(fatal_lookalikes[['original_index', 'given_label', 'predicted_label', 'label_quality']].head())

if __name__ == "__main__":
    run_cleanlab()

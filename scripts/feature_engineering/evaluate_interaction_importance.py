"""
LightGBMã«ã‚ˆã‚‹äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã®é‡è¦åº¦è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’æ—¢å­˜ã®ç‰¹å¾´é‡ã«è¿½åŠ ã—ã€LightGBMã§5-fold CVã‚’å®Ÿè¡Œã€‚
PR-AUCã®å‘ä¸Šåº¦åˆã„ã§é‡è¦åº¦ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŒ–ã—ã¾ã™ã€‚

å‡¦ç†ãƒ•ãƒ­ãƒ¼:
1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆäº¤äº’ä½œç”¨ç‰¹å¾´é‡ãªã—ï¼‰ã®PR-AUCã‚’æ¸¬å®š
2. å„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’1ã¤ãšã¤è¿½åŠ ã—ã¦PR-AUCã‚’æ¸¬å®š
3. PR-AUCã®å‘ä¸Šåº¦ï¼ˆdelta PR-AUCï¼‰ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°
4. çµæœã‚’CSVã¨Markdownãƒ¬ãƒãƒ¼ãƒˆã§å‡ºåŠ›
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    average_precision_score, 
    roc_auc_score,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score
)
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer
import pickle
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')


class InteractionFeatureEvaluator:
    """LightGBMã§äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è©•ä¾¡ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(
        self, 
        data_path, 
        interaction_metadata_path,
        interaction_dir,
        target_column='æ­»è€…æ•°',
        n_folds=5,
        random_state=42
    ):
        """
        Parameters:
        -----------
        data_path : str
            å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
        interaction_metadata_path : str
            äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿CSVãƒ‘ã‚¹
        interaction_dir : str
            äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã®pickleãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        target_column : str
            ç›®çš„å¤‰æ•°ã®ã‚«ãƒ©ãƒ å
        n_folds : int
            äº¤å·®æ¤œè¨¼ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰æ•°
        random_state : int
            ä¹±æ•°ã‚·ãƒ¼ãƒ‰
        """
        self.data_path = data_path
        self.interaction_metadata_path = interaction_metadata_path
        self.interaction_dir = Path(interaction_dir)
        self.target_column = target_column
        self.n_folds = n_folds
        self.random_state = random_state
        
        # æœ€è‰¯ã®LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‹ã‚‰ï¼‰
        self.best_params = {
            'learning_rate': 0.07658346283890378,
            'num_leaves': 125,
            'max_depth': 8,
            'min_child_samples': 278,
            'subsample': 0.6147706754536576,
            'colsample_bytree': 0.6267708320804088,
            'reg_alpha': 0.9961403311275829,
            'reg_lambda': 8.228908331551605,
            'min_child_weight': 0.12646850234127796,
            'min_split_gain': 0.24303906753172422,
            'path_smooth': 2.254892007170922,
            'scale_pos_weight': 61.47728365878301,
            'objective': 'binary',
            'metric': 'binary_logloss',
            'boosting_type': 'gbdt',
            'n_estimators': 10000,
            'random_state': random_state,
            'n_jobs': -1,
            'verbose': -1
        }
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {data_path}")
        self.df = pd.read_csv(data_path)
        
        # ç›®çš„å¤‰æ•°ã‚’åˆ†é›¢
        self.y = self.df[target_column]
        self.X = self.df.drop(columns=[target_column])
        
        # ç™ºç”Ÿæ—¥æ™‚ã¯é™¤å¤–ï¼ˆæ—¥æ™‚å‹ã¯ãã®ã¾ã¾ã§ã¯ä½¿ãˆãªã„ï¼‰
        if 'ç™ºç”Ÿæ—¥æ™‚' in self.X.columns:
            self.X = self.X.drop(columns=['ç™ºç”Ÿæ—¥æ™‚'])
        
        print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: X={self.X.shape}, y={self.y.shape}")
        print(f"ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”: {(self.y == 0).sum() / (self.y == 1).sum():.2f}")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print(f"\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {interaction_metadata_path}")
        self.metadata = pd.read_csv(interaction_metadata_path)
        print(f"äº¤äº’ä½œç”¨ç‰¹å¾´é‡æ•°: {len(self.metadata)}")
        
        # ç‰¹å¾´é‡ã®åˆ†é¡
        self.numeric_cols = self.X.select_dtypes(include=['int64', 'float64']).columns.tolist()
        self.categorical_cols = self.X.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # æ˜ç¤ºçš„ãªã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®æŒ‡å®šï¼ˆèª¤åˆ¤å®šé˜²æ­¢ï¼‰
        explicit_cat_cols = [
            'éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'è·¯ç·šã‚³ãƒ¼ãƒ‰', 'åœ°ç‚¹ã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰',
            'æ˜¼å¤œ', 'å¤©å€™', 'åœ°å½¢', 'è·¯é¢çŠ¶æ…‹', 'é“è·¯å½¢çŠ¶', 'ä¿¡å·æ©Ÿ',
            'è¡çªåœ°ç‚¹', 'ã‚¾ãƒ¼ãƒ³è¦åˆ¶', 'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰', 'æ­©è»Šé“åŒºåˆ†',
            'äº‹æ•…é¡å‹', 'æ›œæ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)', 'ç¥æ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)'
        ]
        explicit_cat_cols = [c for c in explicit_cat_cols if c in self.X.columns]
        self.categorical_cols = list(set(self.categorical_cols + explicit_cat_cols))
        self.numeric_cols = [c for c in self.numeric_cols if c not in self.categorical_cols]
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚’æ–‡å­—åˆ—ã«çµ±ä¸€
        for col in self.categorical_cols:
            if col in self.X.columns:
                self.X[col] = self.X[col].astype(str)
                
        print(f"ç‰¹å¾´é‡: æ•°å€¤ {len(self.numeric_cols)}å€‹, ã‚«ãƒ†ã‚´ãƒª {len(self.categorical_cols)}å€‹")
        
    def evaluate_baseline(self):
        """
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆäº¤äº’ä½œç”¨ç‰¹å¾´é‡ãªã—ï¼‰ã®æ€§èƒ½ã‚’è©•ä¾¡
        
        Returns:
        --------
        dict
            å„è©•ä¾¡æŒ‡æ¨™ã®å¹³å‡å€¤
        """
        print("\n" + "="*60)
        print("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ï¼ˆäº¤äº’ä½œç”¨ç‰¹å¾´é‡ãªã—ï¼‰")
        print("="*60)
        
        cv_scores = self._cross_validate(self.X, self.y)
        
        print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ PR-AUC: {cv_scores['pr_auc']:.6f}")
        print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ ROC-AUC: {cv_scores['roc_auc']:.6f}")
        print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ F1: {cv_scores['f1']:.6f}")
        
        return cv_scores
    
    
    def _prepare_data_for_lightgbm(self, X, is_train=False, encoder=None):
        """
        LightGBMç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰
        å‹•çš„ã«ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ—ã‚’åˆ¤å®šã—ã¦å‡¦ç†
        """
        X_prepared = X.copy()
        
        # æ•°å€¤å‹ã¨ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹ã‚’å‹•çš„ã«åˆ¤å®š
        numeric_cols = X_prepared.select_dtypes(include=['int64', 'float64']).columns
        categorical_cols = X_prepared.select_dtypes(include=['object', 'category']).columns
        
        # æ•°å€¤å‹ã®æ¬ æå€¤è£œå®Œ
        for col in numeric_cols:
            if X_prepared[col].isna().any():
                X_prepared[col].fillna(X_prepared[col].median(), inplace=True)
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        if len(categorical_cols) > 0:
            # æ¬ æå€¤ã‚’æ–‡å­—åˆ—ã¨ã—ã¦åŸ‹ã‚ã‚‹
            X_prepared[categorical_cols] = X_prepared[categorical_cols].fillna('missing').astype(str)
            
            if is_train:
                encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
                X_prepared[categorical_cols] = encoder.fit_transform(X_prepared[categorical_cols])
                return X_prepared, encoder
            else:
                if encoder is None:
                    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆï¼ˆé€šå¸¸ã‚ã‚Šãˆãªã„ãŒå®‰å…¨ç­–ï¼‰
                    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
                    X_prepared[categorical_cols] = encoder.fit_transform(X_prepared[categorical_cols])
                else:
                    X_prepared[categorical_cols] = encoder.transform(X_prepared[categorical_cols])
                return X_prepared
        
        if is_train:
            return X_prepared, None
        else:
            return X_prepared

    def _cross_validate(self, X, y):
        """
        5-fold Stratified CVã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾´é‡
        y : pd.Series
            ç›®çš„å¤‰æ•°
            
        Returns:
        --------
        dict
            å„è©•ä¾¡æŒ‡æ¨™ã®å¹³å‡å€¤
        """
        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)
        
        scores = {
            'pr_auc': [],
            'roc_auc': [],
            'accuracy': [],
            'precision': [],
            'recall': [],
            'f1': []
        }
        
        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):
            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
            
            # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰
            X_train_encoded, encoder = self._prepare_data_for_lightgbm(X_train, is_train=True)
            X_val_encoded = self._prepare_data_for_lightgbm(X_val, is_train=False, encoder=encoder)
            
            # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model = lgb.LGBMClassifier(**self.best_params)
            model.fit(
                X_train_encoded, y_train,
                eval_set=[(X_val_encoded, y_val)],
                callbacks=[lgb.early_stopping(50, verbose=False)]
            )
            
            # äºˆæ¸¬
            y_pred_proba = model.predict_proba(X_val_encoded)[:, 1]
            y_pred = model.predict(X_val_encoded)
            
            # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
            scores['pr_auc'].append(average_precision_score(y_val, y_pred_proba))
            scores['roc_auc'].append(roc_auc_score(y_val, y_pred_proba))
            scores['accuracy'].append(accuracy_score(y_val, y_pred))
            scores['precision'].append(precision_score(y_val, y_pred, zero_division=0))
            scores['recall'].append(recall_score(y_val, y_pred, zero_division=0))
            scores['f1'].append(f1_score(y_val, y_pred, zero_division=0))
        
        # å¹³å‡ã‚’è¨ˆç®—
        avg_scores = {k: np.mean(v) for k, v in scores.items()}
        
        return avg_scores
    
    def evaluate_all_interactions(self, baseline_scores):
        """
        ã™ã¹ã¦ã®äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è©•ä¾¡
        
        Parameters:
        -----------
        baseline_scores : dict
            ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™
            
        Returns:
        --------
        pd.DataFrame
            è©•ä¾¡çµæœï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ãï¼‰
        """
        print("\n" + "="*60)
        print("äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã®è©•ä¾¡é–‹å§‹")
        print("="*60)
        print(f"è©•ä¾¡å¯¾è±¡: {len(self.metadata)} å€‹ã®äº¤äº’ä½œç”¨ç‰¹å¾´é‡")
        print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ PR-AUC: {baseline_scores['pr_auc']:.6f}")
        print("="*60)
        
        results = []
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        checkpoint_path = Path(self.interaction_dir).parent / 'results' / 'interaction_features_road_type' / 'checkpoint_results.csv'
        checkpoint_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ—¢å­˜ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
        processed_features = set()
        if checkpoint_path.exists():
            print(f"\nğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œå‡º: {checkpoint_path}")
            existing_df = pd.read_csv(checkpoint_path)
            results = existing_df.to_dict('records')
            processed_features = set(existing_df['feature_name'].tolist())
            print(f"   æ—¢ã«å‡¦ç†æ¸ˆã¿: {len(processed_features)} å€‹")
            print(f"   æ®‹ã‚Š: {len(self.metadata) - len(processed_features)} å€‹")
            print("="*60)
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§è©•ä¾¡
        remaining = len(self.metadata) - len(processed_features)
        pbar = tqdm(total=remaining, desc="äº¤äº’ä½œç”¨ç‰¹å¾´é‡è©•ä¾¡")
        
        for idx, row in self.metadata.iterrows():
            feature_name = row['feature_name']
            
            # æ—¢ã«å‡¦ç†æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
            if feature_name in processed_features:
                continue
            
            feature_path = self.interaction_dir / f"{feature_name}.pkl"
            
            # äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’èª­ã¿è¾¼ã¿
            with open(feature_path, 'rb') as f:
                interaction_feature = pickle.load(f)
            
            # å…ƒã®ç‰¹å¾´é‡ã«è¿½åŠ 
            X_with_interaction = self.X.copy()
            X_with_interaction[feature_name] = interaction_feature
            
            # è©•ä¾¡
            try:
                scores = self._cross_validate(X_with_interaction, self.y)
                
                # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®å·®åˆ†ã‚’è¨ˆç®—
                delta_pr_auc = scores['pr_auc'] - baseline_scores['pr_auc']
                delta_roc_auc = scores['roc_auc'] - baseline_scores['roc_auc']
                delta_f1 = scores['f1'] - baseline_scores['f1']
                
                # çµæœã‚’è¨˜éŒ²
                result = {
                    'feature_name': feature_name,
                    'feature1': row['feature1'],
                    'feature2': row['feature2'],
                    'interaction_type': row['interaction_type'],
                    'pr_auc': scores['pr_auc'],
                    'delta_pr_auc': delta_pr_auc,
                    'roc_auc': scores['roc_auc'],
                    'delta_roc_auc': delta_roc_auc,
                    'f1': scores['f1'],
                    'delta_f1': delta_f1,
                    'accuracy': scores['accuracy'],
                    'precision': scores['precision'],
                    'recall': scores['recall'],
                    'n_unique': row['n_unique'],
                    'missing_rate': row['missing_rate']
                }
                results.append(result)
                
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜ï¼ˆ10å€‹ã”ã¨ï¼‰
                if len(results) % 10 == 0:
                    checkpoint_df = pd.DataFrame(results)
                    checkpoint_df.to_csv(checkpoint_path, index=False, encoding='utf-8-sig')
                
            except Exception as e:
                print(f"\nè­¦å‘Š: {feature_name} ã®è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                continue
            
            pbar.update(1)
            
            # é€²æ—ã‚’å®šæœŸçš„ã«è¡¨ç¤ºï¼ˆ50å€‹ã”ã¨ï¼‰
            if len(results) % 50 == 0:
                pbar.set_postfix({
                    'Current': feature_name[:30],
                    'Best Delta': f"{max([r['delta_pr_auc'] for r in results]):.6f}"
                })
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚‚ä¿å­˜
                checkpoint_df = pd.DataFrame(results)
                checkpoint_df.to_csv(checkpoint_path, index=False, encoding='utf-8-sig')
                print(f"\nğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: {len(results)} å€‹å®Œäº†")
        
        pbar.close()
        
        # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
        checkpoint_df = pd.DataFrame(results)
        checkpoint_df.to_csv(checkpoint_path, index=False, encoding='utf-8-sig')
        print(f"\nâœ… æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: {checkpoint_path}")
        
        # çµæœã‚’DataFrameã«å¤‰æ›
        results_df = pd.DataFrame(results)
        
        # delta_pr_aucã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        results_df = results_df.sort_values('delta_pr_auc', ascending=False).reset_index(drop=True)
        
        # ãƒ©ãƒ³ã‚¯ä»˜ã‘
        results_df['rank'] = range(1, len(results_df) + 1)
        
        return results_df
    
    def save_results(self, results_df, output_dir='results/interaction_features'):
        """
        è©•ä¾¡çµæœã‚’ä¿å­˜
        
        Parameters:
        -----------
        results_df : pd.DataFrame
            è©•ä¾¡çµæœ
        output_dir : str
            ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # å…¨çµæœã‚’CSVä¿å­˜
        full_csv_path = output_path / f'interaction_features_ranking_full_{timestamp}.csv'
        results_df.to_csv(full_csv_path, index=False, encoding='utf-8-sig')
        print(f"\nå…¨çµæœã‚’ä¿å­˜: {full_csv_path}")
        
        # Top 100ã‚’CSVä¿å­˜
        top100_csv_path = output_path / f'interaction_features_ranking_top100_{timestamp}.csv'
        results_df.head(100).to_csv(top100_csv_path, index=False, encoding='utf-8-sig')
        print(f"Top 100ã‚’ä¿å­˜: {top100_csv_path}")
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\n" + "="*60)
        print("è©•ä¾¡å®Œäº†ã‚µãƒãƒªãƒ¼")
        print("="*60)
        print(f"è©•ä¾¡ã—ãŸäº¤äº’ä½œç”¨ç‰¹å¾´é‡æ•°: {len(results_df)}")
        print(f"\nTop 5 äº¤äº’ä½œç”¨ç‰¹å¾´é‡:")
        for idx, row in results_df.head(5).iterrows():
            print(f"  {row['rank']}. {row['feature_name']}")
            print(f"     Delta PR-AUC: {row['delta_pr_auc']:+.6f} ({row['delta_pr_auc']*100:+.2f}%)")
            print(f"     PR-AUC: {row['pr_auc']:.6f}")
        
        print(f"\nPR-AUCå‘ä¸Šã—ãŸç‰¹å¾´é‡æ•°: {(results_df['delta_pr_auc'] > 0).sum()}")
        print(f"PR-AUCä½ä¸‹ã—ãŸç‰¹å¾´é‡æ•°: {(results_df['delta_pr_auc'] < 0).sum()}")
        
        return full_csv_path, top100_csv_path


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # è¨­å®šï¼ˆå®Ÿè¡Œæ™‚ã«æœ€æ–°ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰
    DATA_PATH = 'data/processed/honhyo_clean_predictable_only.csv'
    INTERACTION_DIR = 'data/interaction_features_20251211_140000'  # generate_interaction_features.pyã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    METADATA_PATH = f'{INTERACTION_DIR}/interaction_features_metadata.csv'
    TARGET_COLUMN = 'æ­»è€…æ•°'
    OUTPUT_DIR = 'results/interaction_features'
    
    print("="*60)
    print("LightGBMã«ã‚ˆã‚‹äº¤äº’ä½œç”¨ç‰¹å¾´é‡é‡è¦åº¦è©•ä¾¡")
    print("="*60)
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {DATA_PATH}")
    print(f"äº¤äº’ä½œç”¨ç‰¹å¾´é‡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {INTERACTION_DIR}")
    print(f"å‡ºåŠ›å…ˆ: {OUTPUT_DIR}")
    print("="*60)
    
    # è©•ä¾¡å™¨ã®åˆæœŸåŒ–
    evaluator = InteractionFeatureEvaluator(
        data_path=DATA_PATH,
        interaction_metadata_path=METADATA_PATH,
        interaction_dir=INTERACTION_DIR,
        target_column=TARGET_COLUMN,
        n_folds=5,
        random_state=42
    )
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡
    baseline_scores = evaluator.evaluate_baseline()
    
    # ã™ã¹ã¦ã®äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è©•ä¾¡
    results_df = evaluator.evaluate_all_interactions(baseline_scores)
    
    # çµæœã‚’ä¿å­˜
    full_csv, top100_csv = evaluator.save_results(results_df, output_dir=OUTPUT_DIR)
    
    print("\nâœ… ã™ã¹ã¦ã®è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print(f"æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: generate_ranking_report.py ã‚’å®Ÿè¡Œã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")


if __name__ == '__main__':
    main()

"""
Stage 2 Optuna ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
======================================
Implementation Plan v22

- è©•ä¾¡æŒ‡æ¨™: PR-AUC (ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°)
- Pruning: è¦‹è¾¼ã¿ã®ãªã„è©¦è¡Œã‚’æ—©æœŸæ‰“ã¡åˆ‡ã‚Š
- æŽ¢ç´¢: num_leaves, reg, scale_pos_weight ç­‰
- é€²æ—è¡¨ç¤º: tqdmã¨Optunaæ¨™æº–ãƒ­ã‚°ã§ç¢ºèªå¯èƒ½
"""

import pandas as pd
import numpy as np
import os
import pickle
import gc
from datetime import datetime
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import average_precision_score, precision_score, recall_score
import lightgbm as lgb
import optuna
from optuna.integration import LightGBMPruningCallback
import warnings

warnings.filterwarnings('ignore')


# ============================================================
# ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡é–¢æ•°ï¼ˆPR-AUCï¼‰
# ============================================================
def pr_auc_metric(preds, train_data):
    """LightGBMç”¨ã‚«ã‚¹ã‚¿ãƒ PR-AUCè©•ä¾¡é–¢æ•°"""
    y_true = train_data.get_label()
    score = average_precision_score(y_true, preds)
    return 'pr_auc', score, True  # higher_is_better=True


# ============================================================
# Optuna Objectiveé–¢æ•°
# ============================================================
class Stage2Objective:
    """Stage 2ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ç”¨Objective"""
    
    def __init__(self, X, y, n_folds=5, random_state=42):
        self.X = X
        self.y = y
        self.n_folds = n_folds
        self.random_state = random_state
        self.trial_count = 0
        self.best_score = 0.0
        self.start_time = datetime.now()
    
    def __call__(self, trial):
        self.trial_count += 1
        
        # æŽ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        params = {
            'objective': 'binary',
            'boosting_type': 'gbdt',
            'verbosity': -1,
            'n_jobs': -1,
            'random_state': self.random_state,
            
            # æŽ¢ç´¢å¯¾è±¡
            'num_leaves': trial.suggest_int('num_leaves', 31, 255),
            'max_depth': trial.suggest_int('max_depth', 8, 15),
            'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),
            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),
            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),
            'subsample': trial.suggest_float('subsample', 0.5, 0.9),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),
            'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 50.0),
        }
        
        # Cross-Validation
        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)
        pr_auc_scores = []
        
        for fold, (train_idx, val_idx) in enumerate(skf.split(self.X, self.y)):
            X_train = self.X.iloc[train_idx]
            y_train = self.y[train_idx]
            X_val = self.X.iloc[val_idx]
            y_val = self.y[val_idx]
            
            # LightGBM Dataset
            dtrain = lgb.Dataset(X_train, label=y_train)
            dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)
            
            # Pruning Callback
            pruning_callback = LightGBMPruningCallback(trial, 'pr_auc')
            
            try:
                model = lgb.train(
                    params,
                    dtrain,
                    num_boost_round=500,
                    valid_sets=[dval],
                    feval=pr_auc_metric,
                    callbacks=[
                        lgb.early_stopping(50, verbose=False),
                        pruning_callback
                    ]
                )
                
                y_prob = model.predict(X_val)
                pr_auc = average_precision_score(y_val, y_prob)
                pr_auc_scores.append(pr_auc)
                
            except optuna.TrialPruned:
                raise
            
            del model
            gc.collect()
        
        mean_pr_auc = np.mean(pr_auc_scores)
        
        # é€²æ—è¡¨ç¤º
        elapsed = (datetime.now() - self.start_time).total_seconds()
        if mean_pr_auc > self.best_score:
            self.best_score = mean_pr_auc
            print(f"   ðŸ† Trial {self.trial_count}: PR-AUC={mean_pr_auc:.4f} (NEW BEST!) [{elapsed/60:.1f}min]")
        else:
            print(f"   Trial {self.trial_count}: PR-AUC={mean_pr_auc:.4f} [{elapsed/60:.1f}min]")
        
        return mean_pr_auc


# ============================================================
# ãƒ¡ã‚¤ãƒ³
# ============================================================
def run_optuna_optimization(
    data_path: str = "results/two_stage_model/optuna_data/stage2_train_data.pkl",
    n_trials: int = 50,
    n_folds: int = 5,
    random_state: int = 42,
    output_dir: str = "results/two_stage_model/optuna_results"
):
    """Optunaæœ€é©åŒ–ã‚’å®Ÿè¡Œ"""
    
    os.makedirs(output_dir, exist_ok=True)
    
    print("=" * 70)
    print("Stage 2 Optuna ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–")
    print(f"è©•ä¾¡æŒ‡æ¨™: PR-AUC (Precision-Recall AUC)")
    print(f"è©¦è¡Œå›žæ•°: {n_trials}")
    print("=" * 70)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nðŸ“‚ Stage 2ç”¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
    with open(data_path, 'rb') as f:
        data = pickle.load(f)
    
    X_s2 = data['X_s2']
    y_s2 = data['y_s2']
    
    n_pos = y_s2.sum()
    n_neg = len(y_s2) - n_pos
    print(f"   ãƒ‡ãƒ¼ã‚¿æ•°: {len(y_s2):,} (Pos: {n_pos:,}, Neg: {n_neg:,}, æ¯”çŽ‡ 1:{n_neg//n_pos})")
    
    # Optuna Studyä½œæˆ
    print("\nðŸ” æœ€é©åŒ–é–‹å§‹...")
    print("-" * 70)
    
    study = optuna.create_study(
        direction='maximize',
        study_name='stage2_pr_auc_optimization',
        sampler=optuna.samplers.TPESampler(seed=random_state)
    )
    
    objective = Stage2Objective(X_s2, y_s2, n_folds=n_folds, random_state=random_state)
    
    study.optimize(
        objective,
        n_trials=n_trials,
        show_progress_bar=True,
        gc_after_trial=True
    )
    
    # çµæžœè¡¨ç¤º
    print("\n" + "=" * 70)
    print("âœ… æœ€é©åŒ–å®Œäº†ï¼")
    print("=" * 70)
    
    best = study.best_trial
    print(f"\nðŸ† ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢: PR-AUC = {best.value:.4f}")
    print(f"\nðŸ“‹ ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    for key, value in best.params.items():
        print(f"   {key}: {value}")
    
    # çµæžœä¿å­˜
    results_df = study.trials_dataframe()
    results_df.to_csv(os.path.join(output_dir, "optuna_trials.csv"), index=False)
    
    best_params_df = pd.DataFrame([best.params])
    best_params_df['pr_auc'] = best.value
    best_params_df.to_csv(os.path.join(output_dir, "best_params.csv"), index=False)
    
    print(f"\nðŸ’¾ çµæžœä¿å­˜:")
    print(f"   - {output_dir}/optuna_trials.csv")
    print(f"   - {output_dir}/best_params.csv")
    
    return study


if __name__ == "__main__":
    # å¼•æ•°ã§n_trialsã‚’èª¿æ•´å¯èƒ½
    import sys
    n_trials = int(sys.argv[1]) if len(sys.argv) > 1 else 50
    
    run_optuna_optimization(n_trials=n_trials)

"""
2æ®µéšãƒ¢ãƒ‡ãƒ« æœ€çµ‚ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
============================
Implementation Plan v18

Stage 1: LightGBM + 1:2 Under-sampling + 3-Seed Averaging
Stage 2: High Complexity + Strong Regularization

ç‰¹å¾´ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°:
- prob_stage1 (OOFäºˆæ¸¬å€¤ã‚’ä½¿ç”¨ã€ãƒªãƒ¼ã‚¯é˜²æ­¢)
- Categorical Interaction Features (æ–‡å­—åˆ—çµåˆ)
"""

import pandas as pd
import numpy as np
import os
import gc
from datetime import datetime
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve
import lightgbm as lgb
from scipy.special import expit
import warnings

warnings.filterwarnings('ignore')


def get_focal_loss_lgb(alpha: float = 0.75, gamma: float = 1.0):
    """
    LightGBMç”¨ Focal Loss ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°
    
    Args:
        alpha: æ­£ä¾‹(æ­»äº¡äº‹æ•…)ã®é‡ã¿ (0.5ã‚ˆã‚Šå¤§ãã„ã¨æ­£ä¾‹ã‚’é‡è¦–)
        gamma: é›£æ˜“åº¦ã«å¿œã˜ãŸé‡ã¿ä»˜ã‘ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (0ã§é€šå¸¸ã®CE, å¤§ãã„ã»ã©é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’é‡è¦–)
    
    Returns:
        focal_loss_lgb: LightGBMç”¨ã‚«ã‚¹ã‚¿ãƒ æå¤±é–¢æ•°
    """
    def focal_loss_lgb(y_true, preds):
        """
        LightGBMç”¨ Focal Loss
        
        æ³¨æ„: LGBMClassifier (sklearn API) ã§ã¯å¼•æ•°ã®é †åºãŒ (y_true, preds) ã¨ãªã‚‹
        preds: ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿå‡ºåŠ› (Logits)
        y_true: æ­£è§£ãƒ©ãƒ™ãƒ« (numpy array)
        """
        # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å¤‰æ›
        p = expit(preds)
        p = np.clip(p, 1e-15, 1 - 1e-15)  # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã‚¯ãƒªãƒƒãƒ—
        
        # p_t: æ­£è§£ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡
        # y=1 ã®å ´åˆ p_t = p, y=0 ã®å ´åˆ p_t = 1-p
        p_t = y_true * p + (1 - y_true) * (1 - p)
        
        # alpha_t: ã‚¯ãƒ©ã‚¹ã”ã¨ã®é‡ã¿
        # y=1 ã®å ´åˆ alpha, y=0 ã®å ´åˆ 1-alpha
        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)
        
        # Focal weight: (1 - p_t)^gamma
        focal_weight = (1 - p_t) ** gamma
        
        # ç°¡ç•¥åŒ–ã—ãŸå‹¾é…è¨ˆç®—
        # grad = alpha_t * focal_weight * (p - y_true)
        # ã“ã‚Œã¯ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®å‹¾é… (p - y) ã« focal_weight ã¨ alpha_t ã‚’æ›ã‘ãŸã‚‚ã®
        grad = alpha_t * focal_weight * (p - y_true)
        
        # ãƒ˜ãƒƒã‚»è¡Œåˆ—ï¼ˆè¿‘ä¼¼ï¼‰
        # æ¨™æº–çš„ãªãƒ­ã‚°ãƒ­ã‚¹ã®ãƒ˜ãƒƒã‚»è¡Œåˆ—ã« focal_weight ã¨ alpha_t ã‚’æ›ã‘ã‚‹
        hess = alpha_t * focal_weight * p * (1 - p)
        # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã€ãƒ˜ãƒƒã‚»è¡Œåˆ—ã«æœ€å°å€¤ã‚’è¨­å®š
        hess = np.maximum(hess, 1e-7)
        
        return grad, hess
    
    return focal_loss_lgb



class TwoStageFinalPipeline:
    """2æ®µéšãƒ¢ãƒ‡ãƒ«æœ€çµ‚ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    def __init__(
        self,
        data_path: str = "data/processed/honhyo_clean_with_features.csv",
        target_col: str = "æ­»è€…æ•°",
        n_folds: int = 5,
        random_state: int = 42,
        stage1_recall_target: float = 0.99,
        undersample_ratio: float = 2.0,  # 1:2
        n_seeds: int = 3,
        top_k_interactions: int = 5,
        test_size: float = 0.2,  # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆæ¯”ç‡
        # Optunaæœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (optuna_focal_loss_v2)
        focal_alpha: float = 0.6321,
        focal_gamma: float = 1.1495,
        output_dir: str = "results/two_stage_model/final_pipeline",  # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    ):
        self.data_path = data_path
        self.target_col = target_col
        self.n_folds = n_folds
        self.random_state = random_state
        self.stage1_recall_target = stage1_recall_target
        self.undersample_ratio = undersample_ratio
        self.n_seeds = n_seeds
        self.top_k_interactions = top_k_interactions
        self.test_size = test_size
        self.focal_alpha = focal_alpha
        self.focal_gamma = focal_gamma
        
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
        
        print("=" * 60)
        print("2æ®µéšãƒ¢ãƒ‡ãƒ« æœ€çµ‚ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ (Optunaæœ€é©åŒ–ç‰ˆ)")
        print(f"Stage 1: 1:{int(self.undersample_ratio)} Under-sampling, Recall {self.stage1_recall_target:.0%}")
        print(f"Focal Loss: Alpha={self.focal_alpha:.4f}, Gamma={self.focal_gamma:.4f}")
        print(f"Test Set: {self.test_size:.0%}")
        print("=" * 60)
    
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨Train/Teståˆ†å‰²"""
        print("\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        df = pd.read_csv(self.data_path)
        y_all = df[self.target_col].values
        X_all = df.drop(columns=[self.target_col])
        
        if 'ç™ºç”Ÿæ—¥æ™‚' in X_all.columns:
            X_all = X_all.drop(columns=['ç™ºç”Ÿæ—¥æ™‚'])
        
        known_categoricals = [
            'éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰', 'è­¦å¯Ÿç½²ç­‰ã‚³ãƒ¼ãƒ‰',
            'æ˜¼å¤œ', 'å¤©å€™', 'åœ°å½¢', 'è·¯é¢çŠ¶æ…‹', 'é“è·¯å½¢çŠ¶', 'ä¿¡å·æ©Ÿ',
            'è¡çªåœ°ç‚¹', 'ã‚¾ãƒ¼ãƒ³è¦åˆ¶', 'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰', 'æ­©è»Šé“åŒºåˆ†',
            'äº‹æ•…é¡å‹', 'æ›œæ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)', 'ç¥æ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)',
            'road_type', 'area_id', 'åœ°ç‚¹ã‚³ãƒ¼ãƒ‰'
        ]
        
        self.categorical_cols = []
        for col in X_all.columns:
            if col in known_categoricals or X_all[col].dtype == 'object':
                self.categorical_cols.append(col)
                X_all[col] = X_all[col].astype('category')
            else:
                X_all[col] = X_all[col].astype(np.float32)
        
        self.feature_names = list(X_all.columns)
        
        # Train/Teståˆ†å‰²
        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰² (Train: {1-self.test_size:.0%} / Test: {self.test_size:.0%})")
        self.X, self.X_test, self.y, self.y_test = train_test_split(
            X_all, y_all,
            test_size=self.test_size,
            random_state=self.random_state,
            stratify=y_all
        )
        self.X = self.X.reset_index(drop=True)
        self.X_test = self.X_test.reset_index(drop=True)
        
        print(f"   Train: æ­£ä¾‹ {self.y.sum():,} / {len(self.y):,}")
        print(f"   Test:  æ­£ä¾‹ {self.y_test.sum():,} / {len(self.y_test):,}")
        gc.collect()

    
    def undersample(self, X, y, seed):
        """è² ä¾‹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        pos_idx = np.where(y == 1)[0]
        neg_idx = np.where(y == 0)[0]
        n_neg_sample = int(len(pos_idx) * self.undersample_ratio)
        np.random.seed(seed)
        sampled_neg_idx = np.random.choice(neg_idx, size=min(n_neg_sample, len(neg_idx)), replace=False)
        sampled_idx = np.concatenate([pos_idx, sampled_neg_idx])
        np.random.shuffle(sampled_idx)
        return X.iloc[sampled_idx], y[sampled_idx]
    
    def train_stage1(self):
        """Stage 1: OOFå­¦ç¿’ + Feature Importanceå–å¾—"""
        print("\nğŸŒ¿ Stage 1: LightGBM + Under-sampling (1:2) + 3-Seed Averaging")
        
        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)
        self.oof_proba_stage1 = np.zeros(len(self.y))
        feature_importances = np.zeros(len(self.feature_names))
        
        lgb_params = {
            'objective': 'binary',
            'metric': 'auc',
            'boosting_type': 'gbdt',
            'verbosity': -1,
            'num_leaves': 31,
            'max_depth': 8,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
            'n_estimators': 1000,
            'learning_rate': 0.05,
            'n_jobs': -1
        }
        
        self.stage1_models = []
        
        for fold, (train_idx, val_idx) in enumerate(skf.split(self.X, self.y)):
            print(f"   Fold {fold+1}/{self.n_folds}...")
            X_train_full = self.X.iloc[train_idx]
            y_train_full = self.y[train_idx]
            X_val = self.X.iloc[val_idx]
            y_val = self.y[val_idx]
            
            fold_proba = np.zeros(len(val_idx))
            fold_models = []
            
            for seed_offset in range(self.n_seeds):
                seed = self.random_state + fold * 100 + seed_offset
                X_train_under, y_train_under = self.undersample(X_train_full, y_train_full, seed)
                
                model = lgb.LGBMClassifier(**lgb_params, random_state=seed)
                model.fit(
                    X_train_under, y_train_under,
                    eval_set=[(X_val, y_val)],
                    callbacks=[lgb.early_stopping(50, verbose=False)]
                )
                
                fold_proba += model.predict_proba(X_val)[:, 1] / self.n_seeds
                feature_importances += model.feature_importances_ / (self.n_folds * self.n_seeds)
                fold_models.append(model)
                
                del model
                gc.collect()
            
            self.oof_proba_stage1[val_idx] = fold_proba
            self.stage1_models.append(fold_models)
        
        # Feature Importance
        self.feature_importance_df = pd.DataFrame({
            'feature': self.feature_names, 'importance': feature_importances
        }).sort_values('importance', ascending=False)
        self.top_features = self.feature_importance_df.head(self.top_k_interactions)['feature'].tolist()
        
        # OOFç²¾åº¦
        oof_pred = (self.oof_proba_stage1 >= 0.5).astype(int)
        print(f"   OOF (é–¾å€¤0.5): Prec={precision_score(self.y, oof_pred):.4f}, Rec={recall_score(self.y, oof_pred):.4f}, AUC={roc_auc_score(self.y, self.oof_proba_stage1):.4f}")
    
    def find_recall_threshold(self):
        """Recallç›®æ¨™é–¾å€¤æ¢ç´¢"""
        for thresh in np.arange(0.50, 0.001, -0.005):
            y_pred = (self.oof_proba_stage1 >= thresh).astype(int)
            recall = recall_score(self.y, y_pred)
            if recall >= self.stage1_recall_target:
                self.threshold_stage1 = thresh
                break
        else:
            self.threshold_stage1 = 0.001
        
        y_pred_final = (self.oof_proba_stage1 >= self.threshold_stage1).astype(int)
        self.stage1_recall = recall_score(self.y, y_pred_final)
        self.stage1_precision = precision_score(self.y, y_pred_final)
        n_candidates = y_pred_final.sum()
        self.filter_rate = 1 - (n_candidates / len(self.y))
        
        print(f"   é–¾å€¤: {self.threshold_stage1:.4f}, Recall: {self.stage1_recall:.4f}")
        print(f"   ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç‡: {self.filter_rate*100:.2f}% é™¤å¤–, å€™è£œ: {n_candidates:,}")
        
        self.stage2_mask = self.oof_proba_stage1 >= self.threshold_stage1
        
        # OOFçµæœä¿å­˜ï¼ˆXGBoostã¨ã®ç›¸é–¢åˆ†æç”¨ï¼‰
        oof_df = pd.DataFrame({
            'y_true': self.y,
            'oof_proba': self.oof_proba_stage1
        })
        oof_path = "results/two_stage_model/lightgbm_stage1_oof.csv"
        os.makedirs(os.path.dirname(oof_path), exist_ok=True)
        oof_df.to_csv(oof_path, index=False)
        print(f"   ğŸ’¾ OOFçµæœä¿å­˜: {oof_path}")
    
    def generate_stage2_features(self, X_subset, prob_stage1_subset, fit_categories=True):
        """
        Stage 2ç”¨ç‰¹å¾´é‡ç”Ÿæˆ
        
        Args:
            X_subset: å…¥åŠ›ç‰¹å¾´é‡DataFrame
            prob_stage1_subset: Stage 1ã®äºˆæ¸¬ç¢ºç‡
            fit_categories: Trueã®å ´åˆã€ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å­¦ç¿’ã—ã¦ä¿å­˜ã€‚
                           Falseã®å ´åˆã€ä¿å­˜æ¸ˆã¿ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨ï¼ˆãƒ†ã‚¹ãƒˆæ™‚ç”¨ï¼‰ã€‚
        """
        X_out = X_subset.copy()
        
        # (a) prob_stage1 è¿½åŠ 
        X_out['prob_stage1'] = prob_stage1_subset
        
        # (b) Categorical Interaction Features
        top_cat_features = [f for f in self.top_features if f in self.categorical_cols]
        
        if fit_categories:
            # å­¦ç¿’æ™‚: ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¿å­˜
            self.interaction_categories = {}
        
        for i, f1 in enumerate(top_cat_features[:self.top_k_interactions]):
            for f2 in top_cat_features[i+1:self.top_k_interactions]:
                name = f"{f1}_{f2}"
                interaction_values = X_subset[f1].astype(str) + "_" + X_subset[f2].astype(str)
                
                if fit_categories:
                    # å­¦ç¿’æ™‚: ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆã—ã¦ä¿å­˜
                    cat_type = pd.CategoricalDtype(categories=interaction_values.unique())
                    self.interaction_categories[name] = cat_type
                    X_out[name] = pd.Categorical(interaction_values, dtype=cat_type)
                else:
                    # ãƒ†ã‚¹ãƒˆæ™‚: ä¿å­˜æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªã‚’ä½¿ç”¨ï¼ˆæœªçŸ¥ã®ã‚«ãƒ†ã‚´ãƒªã¯NaNã«ãªã‚‹ï¼‰
                    if hasattr(self, 'interaction_categories') and name in self.interaction_categories:
                        X_out[name] = pd.Categorical(interaction_values, dtype=self.interaction_categories[name])
                    else:
                        X_out[name] = interaction_values.astype('category')
        
        return X_out
    
    def get_stage2_data(self):
        """
        Optunaç­‰ã®å¤–éƒ¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”¨: Stage 2ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦è¿”ã™
        
        Returns:
            X_s2: Stage 2ç”¨ã®ç‰¹å¾´é‡DataFrame
            y_s2: Stage 2ç”¨ã®ãƒ©ãƒ™ãƒ«array
        """
        self.load_data()
        self.train_stage1()
        self.find_recall_threshold()
        
        X_s2 = self.generate_stage2_features(
            self.X[self.stage2_mask].copy(),
            self.oof_proba_stage1[self.stage2_mask]
        )
        y_s2 = self.y[self.stage2_mask]
        
        print(f"\nğŸ“¦ Stage 2ç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†:")
        print(f"   ãƒ‡ãƒ¼ã‚¿æ•°: {len(y_s2):,} (Pos: {y_s2.sum():,}, Neg: {len(y_s2)-y_s2.sum():,})")
        
        return X_s2, y_s2
    
    def train_stage2(self):
        """
        Stage 2: Cross Validationã«ã‚ˆã‚‹å­¦ç¿’ã¨è©•ä¾¡
        (å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹éå­¦ç¿’ã‚’é˜²ãã€çœŸã®æ±åŒ–æ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹)
        """
        print("\nğŸŒ¿ Stage 2: High Complexity + Strong Regularization (5-Fold CV)")
        print(f"   Focal Loss: Alpha={self.focal_alpha:.4f}, Gamma={self.focal_gamma:.4f}")
        
        # Stage 2ç”¨ã®å…¨ãƒ‡ãƒ¼ã‚¿
        X_s2_full = self.generate_stage2_features(
            self.X[self.stage2_mask].copy(),
            self.oof_proba_stage1[self.stage2_mask]
        ).reset_index(drop=True)
        
        y_s2_full = self.y[self.stage2_mask]
        
        n_pos, n_neg = y_s2_full.sum(), len(y_s2_full) - y_s2_full.sum()
        print(f"   Stage 2 ãƒ‡ãƒ¼ã‚¿: {len(y_s2_full):,} (Pos: {n_pos:,}, Neg: {n_neg:,})")
        print(f"   Top Features for Interaction: {self.top_features}")
        
        # Stage 2ã®OOFäºˆæ¸¬å€¤ã‚’æ ¼ç´ã™ã‚‹é…åˆ—
        self.oof_proba_stage2 = np.zeros(len(y_s2_full))
        self.stage2_models = []
        
        # CVè¨­å®š
        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)
        
        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Optunaæœ€é©åŒ– - optuna_focal_loss_v2)
        focal_loss_fn = get_focal_loss_lgb(alpha=self.focal_alpha, gamma=self.focal_gamma)
        lgb_params = {
            'objective': focal_loss_fn,  # ã‚«ã‚¹ã‚¿ãƒ Focal Loss (å‹•çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
            'metric': 'auc',
            'boosting_type': 'gbdt',
            'verbosity': -1,
            'num_leaves': 127,        # Optunaæœ€é©åŒ–
            'max_depth': -1,          # num_leaves=127ã‚’æ´»ã‹ã™ãŸã‚åˆ¶é™ãªã—
            'min_child_samples': 44,  # Optunaæœ€é©åŒ–
            'reg_alpha': 2.3897,      # Optunaæœ€é©åŒ–
            'reg_lambda': 2.2842,     # Optunaæœ€é©åŒ–
            'colsample_bytree': 0.8646,  # Optunaæœ€é©åŒ–
            'subsample': 0.6328,      # Optunaæœ€é©åŒ–
            'learning_rate': 0.0477,  # Optunaæœ€é©åŒ–
            'is_unbalance': False,
            'n_estimators': 1000,
            'n_jobs': -1
        }

        
        for fold, (train_idx, val_idx) in enumerate(skf.split(X_s2_full, y_s2_full)):
            print(f"   Fold {fold+1}/{self.n_folds}...")
            X_train, y_train = X_s2_full.iloc[train_idx], y_s2_full[train_idx]
            X_val, y_val = X_s2_full.iloc[val_idx], y_s2_full[val_idx]
            
            model = lgb.LGBMClassifier(**lgb_params, random_state=self.random_state + fold)
            
            # Early Stoppingã‚’åˆ©ç”¨ã—ã¦éå­¦ç¿’æŠ‘åˆ¶
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                callbacks=[lgb.early_stopping(50, verbose=False)]
            )
            
            # Focal Lossä½¿ç”¨æ™‚ã¯raw_score=Trueã§logitã‚’å–å¾—ã—ã€ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å¤‰æ›
            y_pred_raw = model.predict(X_val, raw_score=True)
            y_pred_proba = 1.0 / (1.0 + np.exp(-y_pred_raw))
            
            self.oof_proba_stage2[val_idx] = y_pred_proba
            self.stage2_models.append(model)
            
            del model
            gc.collect()
        
        # OOFç²¾åº¦ï¼ˆStage 2ã®ã¿ï¼‰
        oof_auc = roc_auc_score(y_s2_full, self.oof_proba_stage2)
        print(f"   Stage 2 OOF AUC: {oof_auc:.4f}")
        
        self.stage2_feature_names = list(X_s2_full.columns)
    
    def evaluate(self):
        """æœ€çµ‚è©•ä¾¡ï¼ˆCVã®OOFäºˆæ¸¬å€¤ã‚’ç”¨ã„ãŸå…¬å¹³ãªè©•ä¾¡ï¼‰"""
        print("\nğŸ“ˆ æœ€çµ‚è©•ä¾¡ (Cross Validation OOF)")
        
        # Stage 2ã®OOFäºˆæ¸¬ç¢ºç‡ã‚’ä½¿ç”¨ï¼ˆtrain_stage2ã§ç”Ÿæˆæ¸ˆã¿ï¼‰
        y_prob_s2 = self.oof_proba_stage2
        
        # Stage 2 ã®ã‚¹ã‚³ã‚¢åˆ†å¸ƒã‚’è¡¨ç¤º
        print("\n   ğŸ“Š äºˆæ¸¬ã‚¹ã‚³ã‚¢åˆ†å¸ƒ (Stage 2 OOF):")
        prob_series = pd.Series(y_prob_s2)
        print(f"      mean={prob_series.mean():.4f}, std={prob_series.std():.4f}")
        print(f"      min={prob_series.min():.4f}, 25%={prob_series.quantile(0.25):.4f}, 50%={prob_series.quantile(0.5):.4f}, 75%={prob_series.quantile(0.75):.4f}, max={prob_series.max():.4f}")
        
        # Stage 2å¯¾è±¡å¤–ã®ãƒ‡ãƒ¼ã‚¿ã¯ç¢ºç‡0ã¨ã—ã¦å…¨ä½“ã®é…åˆ—ã‚’ä½œæˆ
        final_proba = np.zeros(len(self.y))
        final_proba[self.stage2_mask] = y_prob_s2
        
        # å‹•çš„é–¾å€¤æ¢ç´¢: Stage 2å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§è¨ˆç®—
        y_s2_true = self.y[self.stage2_mask]
        precisions, recalls, thresholds = precision_recall_curve(y_s2_true, y_prob_s2)
        
        target_recalls = [0.99, 0.98, 0.95]
        self.dynamic_results = {}
        
        print("\n   ğŸ“Š å‹•çš„é–¾å€¤è©•ä¾¡:")
        for target_recall in target_recalls:
            # recalls ã¯é™é †ãªã®ã§ã€target_recall ä»¥ä¸Šã®æœ€åˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¢ã™
            idx = np.where(recalls >= target_recall)[0]
            if len(idx) > 0:
                idx = idx[-1]  # recallsã¯é™é †ãªã®ã§æœ€å¾Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                if idx < len(thresholds):
                    best_thresh = thresholds[idx]
                    best_prec = precisions[idx]
                else:
                    best_thresh = 0.0
                    best_prec = precisions[-1]
            else:
                best_thresh = 0.0
                best_prec = 0.0
            
            self.dynamic_results[target_recall] = {
                'threshold': best_thresh,
                'precision': best_prec
            }
            print(f"      Recall ~{target_recall:.0%}: é–¾å€¤={best_thresh:.4f}, Precision={best_prec:.4f}")
        
        # å›ºå®šé–¾å€¤0.5ã§ã®è©•ä¾¡ï¼ˆå¾“æ¥ã¨ã®æ¯”è¼ƒç”¨ï¼‰
        y_pred = (final_proba >= 0.5).astype(int)
        
        self.final_precision = precision_score(self.y, y_pred) if y_pred.sum() > 0 else 0
        self.final_recall = recall_score(self.y, y_pred)
        self.final_f1 = f1_score(self.y, y_pred)
        self.final_auc = roc_auc_score(self.y, final_proba)
        self.final_proba = final_proba  # ãƒ¬ãƒãƒ¼ãƒˆç”¨ã«ä¿æŒ
        
        # Baseline (Stage 1 å˜ç‹¬ é–¾å€¤0.5)
        y_pred_bl = (self.oof_proba_stage1 >= 0.5).astype(int)
        self.baseline_precision = precision_score(self.y, y_pred_bl)
        self.baseline_recall = recall_score(self.y, y_pred_bl)
        
        print(f"\n   [é–¾å€¤0.5] Precision: {self.final_precision:.4f}, Recall: {self.final_recall:.4f}, F1: {self.final_f1:.4f}")
        print(f"   [ãƒ™ãƒ¼ã‚¹(Stage1)] Precision: {self.baseline_precision:.4f}, Recall: {self.baseline_recall:.4f}")
        
        improvement = (self.final_precision - self.baseline_precision) / self.baseline_precision * 100 if self.baseline_precision > 0 else 0
        print(f"   Precisionæ”¹å–„ç‡ (é–¾å€¤0.5): {improvement:+.2f}%")
        
        return {
            'stage1_threshold': self.threshold_stage1,
            'stage1_recall': self.stage1_recall,
            'filter_rate': self.filter_rate,
            'final_precision': self.final_precision,
            'final_recall': self.final_recall,
            'final_f1': self.final_f1,
            'final_auc': self.final_auc,
            'baseline_precision': self.baseline_precision,
            'baseline_recall': self.baseline_recall,
            'precision_improvement_pct': improvement,
            'dynamic_recall_98_precision': self.dynamic_results.get(0.98, {}).get('precision', 0),
            'dynamic_recall_98_threshold': self.dynamic_results.get(0.98, {}).get('threshold', 0),
        }
    
    def evaluate_test_set(self):
        """
        ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®æœ€çµ‚è©•ä¾¡
        å­¦ç¿’ã«ä½¿ç”¨ã—ã¦ã„ãªã„å®Œå…¨ã«ç‹¬ç«‹ã—ãŸãƒ‡ãƒ¼ã‚¿ã§æ±åŒ–æ€§èƒ½ã‚’ç¢ºèªã™ã‚‹
        """
        print("\nğŸ“ˆ ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡ (Hold-Out)")
        
        # Stage 1: å…¨Foldã®ãƒ¢ãƒ‡ãƒ«ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        test_proba_stage1 = np.zeros(len(self.y_test))
        for fold_models in self.stage1_models:
            for model in fold_models:
                test_proba_stage1 += model.predict_proba(self.X_test)[:, 1]
        test_proba_stage1 /= (self.n_folds * self.n_seeds)
        
        # Stage 1é–¾å€¤ã‚’é©ç”¨ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        test_stage2_mask = test_proba_stage1 >= self.threshold_stage1
        n_candidates = test_stage2_mask.sum()
        n_pos_in_candidates = self.y_test[test_stage2_mask].sum()
        
        print(f"   Stage 1 ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œ: {n_candidates:,} / {len(self.y_test):,}")
        print(f"   æ­£ä¾‹æ®‹å­˜: {n_pos_in_candidates:,} / {self.y_test.sum():,}")
        
        if n_candidates == 0:
            print("   âš ï¸ Stage 2ã«é€²ã‚€ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            self.test_results = {'error': 'No candidates after Stage 1'}
            return self.test_results
        
        # Stage 2ç”¨ã®ç‰¹å¾´é‡ç”Ÿæˆ (ãƒ†ã‚¹ãƒˆæ™‚ã¯ä¿å­˜æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªã‚’ä½¿ç”¨)
        X_test_s2 = self.generate_stage2_features(
            self.X_test[test_stage2_mask].copy(),
            test_proba_stage1[test_stage2_mask],
            fit_categories=False  # ãƒ†ã‚¹ãƒˆæ™‚ã¯å­¦ç¿’æ™‚ã®ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨
        )
        y_test_s2 = self.y_test[test_stage2_mask]
        
        # Stage 2: å…¨Foldã®ãƒ¢ãƒ‡ãƒ«ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ (Focal Lossä½¿ç”¨æ™‚ã¯raw_score)
        test_proba_stage2 = np.zeros(len(y_test_s2))
        for model in self.stage2_models:
            raw_score = model.predict(X_test_s2, raw_score=True)
            proba = 1.0 / (1.0 + np.exp(-raw_score))
            test_proba_stage2 += proba
        test_proba_stage2 /= self.n_folds
        
        # å‹•çš„é–¾å€¤è©•ä¾¡
        precisions, recalls, thresholds = precision_recall_curve(y_test_s2, test_proba_stage2)
        
        self.test_dynamic_results = {}
        target_recalls = [0.99, 0.98, 0.95]
        
        print("\n   ğŸ“Š ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆå‹•çš„é–¾å€¤è©•ä¾¡:")
        for target_recall in target_recalls:
            idx = np.where(recalls >= target_recall)[0]
            if len(idx) > 0:
                idx = idx[-1]
                if idx < len(thresholds):
                    best_thresh = thresholds[idx]
                    best_prec = precisions[idx]
                else:
                    best_thresh = 0.0
                    best_prec = precisions[-1]
            else:
                best_thresh = 0.0
                best_prec = 0.0
            
            self.test_dynamic_results[target_recall] = {
                'threshold': best_thresh,
                'precision': best_prec
            }
            print(f"      Recall ~{target_recall:.0%}: é–¾å€¤={best_thresh:.4f}, Precision={best_prec:.4f}")
        
        # å›ºå®šé–¾å€¤0.5ã§ã®è©•ä¾¡
        final_test_proba = np.zeros(len(self.y_test))
        final_test_proba[test_stage2_mask] = test_proba_stage2
        y_test_pred = (final_test_proba >= 0.5).astype(int)
        
        test_precision = precision_score(self.y_test, y_test_pred) if y_test_pred.sum() > 0 else 0
        test_recall = recall_score(self.y_test, y_test_pred)
        test_f1 = f1_score(self.y_test, y_test_pred)
        test_auc = roc_auc_score(self.y_test, final_test_proba)
        
        print(f"\n   [ãƒ†ã‚¹ãƒˆé–¾å€¤0.5] Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}")
        print(f"   [ãƒ†ã‚¹ãƒˆAUC]: {test_auc:.4f}")
        
        self.test_results = {
            'test_precision': test_precision,
            'test_recall': test_recall,
            'test_f1': test_f1,
            'test_auc': test_auc,
            'test_precision_at_recall99': self.test_dynamic_results.get(0.99, {}).get('precision', 0),
            'test_precision_at_recall98': self.test_dynamic_results.get(0.98, {}).get('precision', 0),
            'test_precision_at_recall95': self.test_dynamic_results.get(0.95, {}).get('precision', 0),
        }
        
        return self.test_results
    
    def generate_report(self, results: dict, elapsed_sec: float):
        """å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownã§å‡ºåŠ›"""
        report_path = os.path.join(self.output_dir, "experiment_report.md")
        
        report_content = f"""# Focal Loss å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆ (Optunaæœ€é©åŒ–ç‰ˆ)

**å®Ÿè¡Œæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**å®Ÿè¡Œæ™‚é–“**: {elapsed_sec:.1f}ç§’

## ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š (Optunaæœ€é©åŒ–)

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å€¤ |
|-----------|----| 
| Focal Alpha | {self.focal_alpha:.4f} |
| Focal Gamma | {self.focal_gamma:.4f} |
| num_leaves | 127 |
| max_depth | 6 |
| min_child_samples | 44 |
| reg_alpha | 2.3897 |
| reg_lambda | 2.2842 |
| colsample_bytree | 0.8646 |
| subsample | 0.6328 |
| learning_rate | 0.0477 |
| Stage 1 Recall Target | {self.stage1_recall_target:.0%} |
| Under-sampling Ratio | 1:{int(self.undersample_ratio)} |
| Test Set Ratio | {self.test_size:.0%} |

## çµæœã‚µãƒãƒª

### Stage 1
- **é–¾å€¤**: {results['stage1_threshold']:.4f}
- **Recall**: {results['stage1_recall']:.4f}
- **ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç‡**: {results['filter_rate']*100:.2f}%

### Stage 2 (Focal Loss) - CV OOFè©•ä¾¡

#### å›ºå®šé–¾å€¤ (0.5) ã§ã®è©•ä¾¡
| æŒ‡æ¨™ | å€¤ |
|------|----| 
| Precision | {results['final_precision']:.4f} |
| Recall | {results['final_recall']:.4f} |
| F1 | {results['final_f1']:.4f} |
| AUC | {results['final_auc']:.4f} |

#### å‹•çš„é–¾å€¤ã§ã®è©•ä¾¡ (CV OOF)
| Target Recall | é–¾å€¤ | Precision |
|---------------|------|----------|
| 99% | {self.dynamic_results.get(0.99, {}).get('threshold', 0):.4f} | {self.dynamic_results.get(0.99, {}).get('precision', 0):.4f} |
| 98% | {self.dynamic_results.get(0.98, {}).get('threshold', 0):.4f} | {self.dynamic_results.get(0.98, {}).get('precision', 0):.4f} |
| 95% | {self.dynamic_results.get(0.95, {}).get('threshold', 0):.4f} | {self.dynamic_results.get(0.95, {}).get('precision', 0):.4f} |

## Baseline ã¨ã®æ¯”è¼ƒ (CV OOF)

| æŒ‡æ¨™ | Baseline (Stage1) | Focal Loss (å›ºå®šé–¾å€¤) | å¤‰åŒ– |
|------|-------------------|----------------------|------|
| Precision | {results['baseline_precision']:.4f} | {results['final_precision']:.4f} | {results['precision_improvement_pct']:+.2f}% |
| Recall | {results['baseline_recall']:.4f} | {results['final_recall']:.4f} | - |

## äºˆæ¸¬ã‚¹ã‚³ã‚¢åˆ†å¸ƒ

```
mean={pd.Series(self.final_proba[self.stage2_mask]).mean():.4f}
std={pd.Series(self.final_proba[self.stage2_mask]).std():.4f}
min={pd.Series(self.final_proba[self.stage2_mask]).min():.4f}
max={pd.Series(self.final_proba[self.stage2_mask]).max():.4f}
```

## è€ƒå¯Ÿ

- Focal Alpha={self.focal_alpha:.4f} ã¯æ­£ä¾‹ï¼ˆæ­»äº¡äº‹æ•…ï¼‰ã®é‡ã¿ã‚’èª¿æ•´
- Focal Gamma={self.focal_gamma:.4f} ã¯é›£æ˜“åº¦ã«å¿œã˜ãŸé‡ã¿ä»˜ã‘
- Optunaæœ€é©åŒ–ã«ã‚ˆã‚Šã€Recall 99%æ™‚ã®Precisionã‚’æœ€å¤§åŒ–ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ç´¢
- CV OOF ã¨ Test Set ã®çµæœãŒè¿‘ã„ã»ã©ã€æ±åŒ–æ€§èƒ½ãŒé«˜ã„
"""
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"\n   ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›: {report_path}")
        return report_path
    
    def run(self):
        start = datetime.now()
        self.load_data()
        self.train_stage1()
        self.find_recall_threshold()
        self.train_stage2()
        results = self.evaluate()
        
        # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡
        test_results = self.evaluate_test_set()
        results.update(test_results)
        
        elapsed_sec = (datetime.now() - start).total_seconds()
        results['elapsed_sec'] = elapsed_sec
        
        # çµæœä¿å­˜
        pd.DataFrame([results]).to_csv(os.path.join(self.output_dir, "final_results.csv"), index=False)
        self.feature_importance_df.to_csv(os.path.join(self.output_dir, "stage1_feature_importance.csv"), index=False)
        
        # Markdown ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_report(results, elapsed_sec)
        
        print("\n" + "=" * 60)
        print("âœ… å®Œäº†ï¼")
        print(f"   çµæœCSV: {self.output_dir}/final_results.csv")
        print(f"   ãƒ¬ãƒãƒ¼ãƒˆMD: {self.output_dir}/experiment_report.md")
        print("=" * 60)
        
        return results


if __name__ == "__main__":
    pipeline = TwoStageFinalPipeline()
    pipeline.run()

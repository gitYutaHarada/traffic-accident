"""
Stage 2ç”¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
================================
train_two_stage_final.py ã®Stage 1éƒ¨åˆ†ã‚’å®Ÿè¡Œã—ã€
OOFäºˆæ¸¬å€¤ã‚’å«ã‚€Stage 2ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ã€‚

Optunaæœ€é©åŒ–ã®äº‹å‰æº–å‚™ã¨ã—ã¦ä½¿ç”¨ã€‚
"""

import pandas as pd
import numpy as np
import os
import gc
import pickle
from datetime import datetime
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import precision_score, recall_score, roc_auc_score
import lightgbm as lgb
import warnings

warnings.filterwarnings('ignore')


def prepare_stage2_data(
    data_path: str = "data/processed/honhyo_clean_with_features.csv",
    target_col: str = "æ­»è€…æ•°",
    n_folds: int = 5,
    random_state: int = 42,
    stage1_recall_target: float = 0.99,
    undersample_ratio: float = 2.0,
    n_seeds: int = 3,
    top_k_interactions: int = 5,
    output_dir: str = "results/two_stage_model/optuna_data"
):
    """Stage 2ç”¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆãƒ»ä¿å­˜"""
    
    os.makedirs(output_dir, exist_ok=True)
    
    print("=" * 60)
    print("Stage 2ç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆOOFäºˆæ¸¬å€¤ä»˜ãï¼‰")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    df = pd.read_csv(data_path)
    y = df[target_col].values
    X = df.drop(columns=[target_col])
    
    if 'ç™ºç”Ÿæ—¥æ™‚' in X.columns:
        X = X.drop(columns=['ç™ºç”Ÿæ—¥æ™‚'])
    
    known_categoricals = [
        'éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰', 'è­¦å¯Ÿç½²ç­‰ã‚³ãƒ¼ãƒ‰',
        'æ˜¼å¤œ', 'å¤©å€™', 'åœ°å½¢', 'è·¯é¢çŠ¶æ…‹', 'é“è·¯å½¢çŠ¶', 'ä¿¡å·æ©Ÿ',
        'è¡çªåœ°ç‚¹', 'ã‚¾ãƒ¼ãƒ³è¦åˆ¶', 'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰', 'æ­©è»Šé“åŒºåˆ†',
        'äº‹æ•…é¡å‹', 'æ›œæ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)', 'ç¥æ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)',
        'road_type', 'area_id', 'åœ°ç‚¹ã‚³ãƒ¼ãƒ‰'
    ]
    
    categorical_cols = []
    for col in X.columns:
        if col in known_categoricals or X[col].dtype == 'object':
            categorical_cols.append(col)
            X[col] = X[col].astype('category')
        else:
            X[col] = X[col].astype(np.float32)
    
    feature_names = list(X.columns)
    print(f"   æ­£ä¾‹: {y.sum():,} / {len(y):,}")
    
    # Stage 1: OOFå­¦ç¿’
    print("\nğŸŒ¿ Stage 1: OOFäºˆæ¸¬å€¤ç”Ÿæˆï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰")
    
    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)
    oof_proba = np.zeros(len(y))
    feature_importances = np.zeros(len(feature_names))
    
    lgb_params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'verbosity': -1,
        'num_leaves': 31,
        'max_depth': 8,
        'reg_alpha': 0.1,
        'reg_lambda': 0.1,
        'n_estimators': 1000,
        'learning_rate': 0.05,
        'n_jobs': -1
    }
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):
        print(f"   Fold {fold+1}/{n_folds}...")
        X_train_full = X.iloc[train_idx]
        y_train_full = y[train_idx]
        X_val = X.iloc[val_idx]
        y_val = y[val_idx]
        
        fold_proba = np.zeros(len(val_idx))
        
        for seed_offset in range(n_seeds):
            seed = random_state + fold * 100 + seed_offset
            
            # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            pos_idx = np.where(y_train_full == 1)[0]
            neg_idx = np.where(y_train_full == 0)[0]
            n_neg_sample = int(len(pos_idx) * undersample_ratio)
            np.random.seed(seed)
            sampled_neg_idx = np.random.choice(neg_idx, size=min(n_neg_sample, len(neg_idx)), replace=False)
            sampled_idx = np.concatenate([pos_idx, sampled_neg_idx])
            np.random.shuffle(sampled_idx)
            X_train_under = X_train_full.iloc[sampled_idx]
            y_train_under = y_train_full[sampled_idx]
            
            model = lgb.LGBMClassifier(**lgb_params, random_state=seed)
            model.fit(
                X_train_under, y_train_under,
                eval_set=[(X_val, y_val)],
                callbacks=[lgb.early_stopping(50, verbose=False)]
            )
            
            fold_proba += model.predict_proba(X_val)[:, 1] / n_seeds
            feature_importances += model.feature_importances_ / (n_folds * n_seeds)
            
            del model
            gc.collect()
        
        oof_proba[val_idx] = fold_proba
    
    # Feature Importance
    feature_importance_df = pd.DataFrame({
        'feature': feature_names, 'importance': feature_importances
    }).sort_values('importance', ascending=False)
    top_features = feature_importance_df.head(top_k_interactions)['feature'].tolist()
    
    print(f"   OOF AUC: {roc_auc_score(y, oof_proba):.4f}")
    
    # é–¾å€¤æ¢ç´¢
    for thresh in np.arange(0.50, 0.001, -0.005):
        y_pred = (oof_proba >= thresh).astype(int)
        recall = recall_score(y, y_pred)
        if recall >= stage1_recall_target:
            threshold = thresh
            break
    else:
        threshold = 0.001
    
    stage2_mask = oof_proba >= threshold
    n_candidates = stage2_mask.sum()
    filter_rate = 1 - (n_candidates / len(y))
    print(f"   é–¾å€¤: {threshold:.4f}, ãƒ•ã‚£ãƒ«ã‚¿ç‡: {filter_rate*100:.2f}%")
    print(f"   Stage 2 å€™è£œæ•°: {n_candidates:,}")
    
    # Stage 2ç”¨ç‰¹å¾´é‡ç”Ÿæˆ
    print("\nğŸ”§ Stage 2ç”¨ç‰¹å¾´é‡ç”Ÿæˆ...")
    X_s2 = X[stage2_mask].copy()
    y_s2 = y[stage2_mask]
    prob_s2 = oof_proba[stage2_mask]
    
    # prob_stage1 è¿½åŠ 
    X_s2['prob_stage1'] = prob_s2
    
    # Categorical Interaction Features
    top_cat_features = [f for f in top_features if f in categorical_cols]
    for i, f1 in enumerate(top_cat_features[:top_k_interactions]):
        for f2 in top_cat_features[i+1:top_k_interactions]:
            name = f"{f1}_{f2}"
            X_s2[name] = (X[stage2_mask][f1].astype(str) + "_" + X[stage2_mask][f2].astype(str)).astype('category')
    
    print(f"   ç‰¹å¾´é‡æ•°: {len(X_s2.columns)}")
    
    # ä¿å­˜
    print("\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜...")
    save_data = {
        'X_s2': X_s2,
        'y_s2': y_s2,
        'prob_s2': prob_s2,
        'threshold': threshold,
        'top_features': top_features,
        'categorical_cols': categorical_cols,
        'feature_importance': feature_importance_df
    }
    
    save_path = os.path.join(output_dir, "stage2_train_data.pkl")
    with open(save_path, 'wb') as f:
        pickle.dump(save_data, f)
    
    print(f"   ä¿å­˜å®Œäº†: {save_path}")
    print("=" * 60)
    
    return save_data


if __name__ == "__main__":
    prepare_stage2_data()

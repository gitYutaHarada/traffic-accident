"""
2æ®µéšãƒ¢ãƒ‡ãƒ«ï¼ˆTwo-Stage Cascade Modelï¼‰å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
======================================================
Implementation Plan v5 ã«åŸºã¥ãå®Ÿè£…

Stage 1: RandomForest (OOF, Recall 99%é–¾å€¤)
Stage 2: LightGBM (å‹•çš„ã‚¯ãƒ©ã‚¹é‡ã¿, ç›¸äº’ä½œç”¨ç‰¹å¾´é‡)

æ¨å®šå®Ÿè¡Œæ™‚é–“: 10-15åˆ† (Core Ultra 9 / 64GB RAM)
"""

import pandas as pd
import numpy as np
import os
import gc
import joblib
from datetime import datetime
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import OrdinalEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve
import lightgbm as lgb
import warnings

warnings.filterwarnings('ignore')


class TwoStagePipeline:
    """
    2æ®µéšãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """
    
    def __init__(
        self,
        data_path: str = "data/processed/honhyo_clean_with_features.csv",
        target_col: str = "æ­»è€…æ•°",
        n_folds: int = 5,
        random_state: int = 42,
        stage1_recall_target: float = 0.99,
        top_k_features: int = 10
    ):
        self.data_path = data_path
        self.target_col = target_col
        self.n_folds = n_folds
        self.random_state = random_state
        self.stage1_recall_target = stage1_recall_target
        self.top_k_features = top_k_features
        
        self.output_dir = "results/two_stage_model"
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ
        self.stage1_models = []
        self.stage2_model = None
        self.threshold_stage1 = None
        self.top_features = None
        self.interaction_pairs = None
        
        print("=" * 70)
        print("2æ®µéšãƒ¢ãƒ‡ãƒ«ï¼ˆTwo-Stage Cascade Modelï¼‰å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
        print("=" * 70)
        print(f"å‡ºåŠ›å…ˆ: {self.output_dir}")
        print(f"Stage 1 Recallç›®æ¨™: {self.stage1_recall_target:.0%}")
    
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"""
        print("\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        self.df = pd.read_csv(self.data_path)
        print(f"   ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {self.df.shape}")
        
        self.y = self.df[self.target_col].values
        self.X = self.df.drop(columns=[self.target_col])
        
        if 'ç™ºç”Ÿæ—¥æ™‚' in self.X.columns:
            self.X = self.X.drop(columns=['ç™ºç”Ÿæ—¥æ™‚'])
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®ç‰¹å®š
        known_categoricals = [
            'éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰', 'è­¦å¯Ÿç½²ç­‰ã‚³ãƒ¼ãƒ‰',
            'æ˜¼å¤œ', 'å¤©å€™', 'åœ°å½¢', 'è·¯é¢çŠ¶æ…‹', 'é“è·¯å½¢çŠ¶', 'ä¿¡å·æ©Ÿ',
            'è¡çªåœ°ç‚¹', 'ã‚¾ãƒ¼ãƒ³è¦åˆ¶', 'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰', 'æ­©è»Šé“åŒºåˆ†',
            'äº‹æ•…é¡å‹', 'æ›œæ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)', 'ç¥æ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)',
            'road_type', 'area_id', 'åœ°ç‚¹ã‚³ãƒ¼ãƒ‰'
        ]
        
        self.categorical_cols = []
        self.numeric_cols = []
        
        for col in self.X.columns:
            if col in known_categoricals or self.X[col].dtype == 'object':
                self.categorical_cols.append(col)
                self.X[col] = self.X[col].astype(str).fillna('Missing')
            else:
                self.numeric_cols.append(col)
                median_val = self.X[col].median()
                self.X[col] = self.X[col].fillna(median_val).astype(np.float32)
        
        print(f"   æ•°å€¤ç‰¹å¾´é‡: {len(self.numeric_cols)}, ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡: {len(self.categorical_cols)}")
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼æº–å‚™
        self.ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
        self.ordinal_encoder.fit(self.X[self.categorical_cols])
        
        self.feature_names = self.numeric_cols + self.categorical_cols
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        X_cat_enc = self.ordinal_encoder.transform(self.X[self.categorical_cols])
        self.X_encoded = np.hstack([self.X[self.numeric_cols].values, X_cat_enc])
        
        print(f"   æ­£ä¾‹ï¼ˆæ­»äº¡ï¼‰: {self.y.sum():,} / {len(self.y):,} ({self.y.mean()*100:.3f}%)")
        gc.collect()
    
    def train_stage1_oof(self):
        """Stage 1: RandomForest OOFäºˆæ¸¬ & Feature Importance"""
        print(f"\nğŸŒ² Stage 1: RandomForest OOFå­¦ç¿’ ({self.n_folds}-Fold)...")
        
        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)
        self.oof_proba_stage1 = np.zeros(len(self.y))
        feature_importances = np.zeros(len(self.feature_names))
        
        for fold, (train_idx, val_idx) in enumerate(skf.split(self.X_encoded, self.y)):
            print(f"   Fold {fold + 1}/{self.n_folds}...")
            
            X_train = self.X_encoded[train_idx]
            X_val = self.X_encoded[val_idx]
            y_train = self.y[train_idx]
            
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                min_samples_leaf=20,
                class_weight='balanced',
                random_state=self.random_state,
                n_jobs=-1
            )
            model.fit(X_train, y_train)
            
            y_prob = model.predict_proba(X_val)[:, 1]
            self.oof_proba_stage1[val_idx] = y_prob
            
            feature_importances += model.feature_importances_ / self.n_folds
            self.stage1_models.append(model)
            
            del model, X_train, X_val
            gc.collect()
        
        # Feature Importance é›†è¨ˆ
        self.feature_importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': feature_importances
        }).sort_values('importance', ascending=False)
        
        self.top_features = self.feature_importance_df.head(self.top_k_features)['feature'].tolist()
        print(f"\n   ğŸ“Š Top {self.top_k_features} ç‰¹å¾´é‡: {self.top_features}")
        
        # OOFç²¾åº¦ç¢ºèª
        oof_pred = (self.oof_proba_stage1 >= 0.5).astype(int)
        recall_05 = recall_score(self.y, oof_pred)
        precision_05 = precision_score(self.y, oof_pred)
        print(f"   OOF (é–¾å€¤0.5): Precision={precision_05:.4f}, Recall={recall_05:.4f}")
    
    def find_recall_threshold(self):
        """Recallç›®æ¨™ã‚’æº€ãŸã™é–¾å€¤ã‚’æ¢ç´¢"""
        print(f"\nğŸ“ Recall {self.stage1_recall_target:.0%} é–¾å€¤æ¢ç´¢...")
        
        # é–¾å€¤ã‚’ä¸‹ã’ã¦ã„ãã€RecallãŒç›®æ¨™ã‚’è¶…ãˆã‚‹ã‚‚ã®ã‚’æ¢ã™
        thresholds = np.arange(0.01, 0.5, 0.01)
        
        for thresh in thresholds:
            y_pred = (self.oof_proba_stage1 >= thresh).astype(int)
            recall = recall_score(self.y, y_pred)
            if recall >= self.stage1_recall_target:
                self.threshold_stage1 = thresh
                break
        else:
            # ç›®æ¨™Recallã«é”ã—ãªã„å ´åˆã¯æœ€ä½é–¾å€¤ã‚’ä½¿ç”¨
            self.threshold_stage1 = 0.01
        
        # æœ€çµ‚ç¢ºèª
        y_pred_final = (self.oof_proba_stage1 >= self.threshold_stage1).astype(int)
        recall_final = recall_score(self.y, y_pred_final)
        precision_final = precision_score(self.y, y_pred_final)
        n_candidates = y_pred_final.sum()
        
        print(f"   é¸å®šé–¾å€¤: {self.threshold_stage1:.3f}")
        print(f"   Recall: {recall_final:.4f}, Precision: {precision_final:.4f}")
        print(f"   Stage 2 å€™è£œæ•°: {n_candidates:,} / {len(self.y):,} ({n_candidates/len(self.y)*100:.2f}%)")
        
        # Stage 2ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        self.stage2_mask = self.oof_proba_stage1 >= self.threshold_stage1
    
    def generate_interaction_features(self, X_subset, indices):
        """é‡è¦åº¦ä¸Šä½ç‰¹å¾´é‡ã«åŸºã¥ãç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã‚’ç”Ÿæˆ"""
        print(f"\nğŸ”§ ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ç”Ÿæˆ (Top {self.top_k_features} é–“)...")
        
        # ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å–å¾—
        top_feature_indices = [self.feature_names.index(f) for f in self.top_features if f in self.feature_names]
        
        interaction_features = []
        interaction_names = []
        
        # ãƒšã‚¢ã”ã¨ã«æ›ã‘ç®—ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
        for i, idx1 in enumerate(top_feature_indices):
            for idx2 in top_feature_indices[i+1:]:
                f1_name = self.feature_names[idx1]
                f2_name = self.feature_names[idx2]
                
                interaction = X_subset[:, idx1] * X_subset[:, idx2]
                interaction_features.append(interaction)
                interaction_names.append(f"{f1_name}*{f2_name}")
        
        if interaction_features:
            interaction_matrix = np.column_stack(interaction_features)
            X_augmented = np.hstack([X_subset, interaction_matrix])
            augmented_names = self.feature_names + interaction_names
            print(f"   ç”Ÿæˆã•ã‚ŒãŸç›¸äº’ä½œç”¨ç‰¹å¾´é‡: {len(interaction_names)}")
        else:
            X_augmented = X_subset
            augmented_names = self.feature_names
        
        self.interaction_names = interaction_names
        return X_augmented, augmented_names
    
    def train_stage2(self):
        """Stage 2: LightGBMå­¦ç¿’"""
        print(f"\nğŸŒ¿ Stage 2: LightGBM å­¦ç¿’...")
        
        # Stage 2ç”¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        X_stage2_base = self.X_encoded[self.stage2_mask]
        y_stage2 = self.y[self.stage2_mask]
        
        # ç›¸äº’ä½œç”¨ç‰¹å¾´é‡è¿½åŠ 
        X_stage2, augmented_names = self.generate_interaction_features(
            X_stage2_base, np.where(self.stage2_mask)[0]
        )
        
        # ä¸å‡è¡¡æ¯”ã®è¨ˆç®—
        n_pos = y_stage2.sum()
        n_neg = len(y_stage2) - n_pos
        scale_pos_weight = n_neg / n_pos if n_pos > 0 else 1.0
        
        print(f"   Stage 2 ãƒ‡ãƒ¼ã‚¿: {len(y_stage2):,} (Pos: {n_pos:,}, Neg: {n_neg:,})")
        print(f"   å‹•çš„ scale_pos_weight: {scale_pos_weight:.2f}")
        
        # LightGBMå­¦ç¿’
        lgb_params = {
            'objective': 'binary',
            'metric': 'binary_logloss',
            'boosting_type': 'gbdt',
            'verbosity': -1,
            'n_estimators': 500,
            'learning_rate': 0.05,
            'num_leaves': 31,
            'max_depth': 8,
            'scale_pos_weight': scale_pos_weight,
            'random_state': self.random_state,
            'n_jobs': -1
        }
        
        self.stage2_model = lgb.LGBMClassifier(**lgb_params)
        self.stage2_model.fit(X_stage2, y_stage2)
        
        # Stage 2 OOFäºˆæ¸¬ï¼ˆç°¡æ˜“ç¢ºèªï¼‰
        y_prob_stage2 = self.stage2_model.predict_proba(X_stage2)[:, 1]
        y_pred_stage2 = (y_prob_stage2 >= 0.5).astype(int)
        
        recall_s2 = recall_score(y_stage2, y_pred_stage2)
        precision_s2 = precision_score(y_stage2, y_pred_stage2)
        print(f"   Stage 2 Trainç²¾åº¦: Precision={precision_s2:.4f}, Recall={recall_s2:.4f}")
        
        self.augmented_feature_names = augmented_names
    
    def evaluate_pipeline(self):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®è©•ä¾¡"""
        print(f"\nğŸ“ˆ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“è©•ä¾¡...")
        
        # Stage 1 ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ã§Stage 2äºˆæ¸¬
        X_stage2_base = self.X_encoded[self.stage2_mask]
        y_stage2_true = self.y[self.stage2_mask]
        
        # ç›¸äº’ä½œç”¨ç‰¹å¾´é‡è¿½åŠ 
        X_stage2, _ = self.generate_interaction_features(
            X_stage2_base, np.where(self.stage2_mask)[0]
        )
        
        y_prob_final = self.stage2_model.predict_proba(X_stage2)[:, 1]
        
        # å…¨ä½“ã«å¯¾ã™ã‚‹æœ€çµ‚äºˆæ¸¬
        final_proba = np.zeros(len(self.y))
        final_proba[self.stage2_mask] = y_prob_final
        
        # è©•ä¾¡
        y_pred_final = (final_proba >= 0.5).astype(int)
        
        recall_final = recall_score(self.y, y_pred_final)
        precision_final = precision_score(self.y, y_pred_final) if y_pred_final.sum() > 0 else 0
        f1_final = f1_score(self.y, y_pred_final)
        
        print(f"\n   ========== æœ€çµ‚çµæœ ==========")
        print(f"   Precision: {precision_final:.4f}")
        print(f"   Recall:    {recall_final:.4f}")
        print(f"   F1-Score:  {f1_final:.4f}")
        
        # Baselineæ¯”è¼ƒï¼ˆStage 1 å˜ç‹¬ï¼‰
        y_pred_s1 = (self.oof_proba_stage1 >= 0.5).astype(int)
        precision_s1 = precision_score(self.y, y_pred_s1)
        recall_s1 = recall_score(self.y, y_pred_s1)
        
        print(f"\n   --- Baselineï¼ˆStage 1å˜ç‹¬, é–¾å€¤0.5ï¼‰---")
        print(f"   Precision: {precision_s1:.4f}")
        print(f"   Recall:    {recall_s1:.4f}")
        
        # æ”¹å–„å¹…
        precision_improvement = (precision_final - precision_s1) / precision_s1 * 100 if precision_s1 > 0 else 0
        print(f"\n   â¬†ï¸ Precisionæ”¹å–„: {precision_improvement:+.1f}%")
        
        # çµæœä¿å­˜
        results = {
            'stage1_threshold': self.threshold_stage1,
            'stage1_recall': recall_score(self.y, (self.oof_proba_stage1 >= self.threshold_stage1).astype(int)),
            'final_precision': precision_final,
            'final_recall': recall_final,
            'final_f1': f1_final,
            'baseline_precision': precision_s1,
            'baseline_recall': recall_s1,
            'precision_improvement_pct': precision_improvement
        }
        
        pd.DataFrame([results]).to_csv(os.path.join(self.output_dir, "evaluation_results.csv"), index=False)
        self.feature_importance_df.to_csv(os.path.join(self.output_dir, "feature_importance.csv"), index=False)
        
        return results
    
    def save_models(self):
        """ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        print(f"\nğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ä¸­...")
        joblib.dump(self.stage1_models, os.path.join(self.output_dir, "stage1_models.pkl"))
        joblib.dump(self.stage2_model, os.path.join(self.output_dir, "stage2_model.pkl"))
        joblib.dump({
            'threshold_stage1': self.threshold_stage1,
            'top_features': self.top_features,
            'interaction_names': self.interaction_names,
            'feature_names': self.feature_names,
            'ordinal_encoder': self.ordinal_encoder
        }, os.path.join(self.output_dir, "pipeline_config.pkl"))
        print(f"   ä¿å­˜å®Œäº†: {self.output_dir}")
    
    def run(self):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        start_time = datetime.now()
        
        self.load_data()
        self.train_stage1_oof()
        self.find_recall_threshold()
        self.train_stage2()
        results = self.evaluate_pipeline()
        self.save_models()
        
        elapsed = (datetime.now() - start_time).total_seconds()
        print(f"\n{'='*70}")
        print(f"âœ… å®Œäº†ï¼ å®Ÿè¡Œæ™‚é–“: {elapsed/60:.1f}åˆ†")
        print(f"{'='*70}")
        
        return results


if __name__ == "__main__":
    pipeline = TwoStagePipeline()
    results = pipeline.run()

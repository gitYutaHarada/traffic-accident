import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score, 
    f1_score,
    confusion_matrix,
    precision_recall_curve
)
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib as mpl
import os

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š (Windowså‘ã‘)
mpl.rcParams['font.family'] = 'MS Gothic'

def main():
    """
    SMOTEã¨LightGBMã‚’ä½¿ç”¨ã—ã€é–¾å€¤èª¿æ•´ã‚’è¡Œã£ã¦Recallæ”¹å–„ã‚’ç›®æŒ‡ã™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    """
    
    print("=" * 80)
    print("é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«æ”¹å–„: SMOTE Ã— LightGBM Ã— é–¾å€¤èª¿æ•´")
    print("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    file_path = 'data/raw/honhyo_all_shishasuu_binary.csv'
    print(f"\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {file_path}")
    
    try:
        df = pd.read_csv(file_path)
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,} ä»¶")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ç›®çš„å¤‰æ•°
    target_col = 'æ­»è€…æ•°'
    
    # é™¤å¤–ã™ã‚‹åˆ—ï¼ˆäº‹å¾Œæƒ…å ±ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯åŸå› ã‚’å¾¹åº•æ’é™¤ï¼‰
    drop_cols = [
        'è³‡æ–™åŒºåˆ†', 'æœ¬ç¥¨ç•ªå·',
        'äººèº«æå‚·ç¨‹åº¦ï¼ˆå½“äº‹è€…Aï¼‰', 'äººèº«æå‚·ç¨‹åº¦ï¼ˆå½“äº‹è€…Bï¼‰',
        'è»Šä¸¡ã®æå£Šç¨‹åº¦ï¼ˆå½“äº‹è€…Aï¼‰', 'è»Šä¸¡ã®æå£Šç¨‹åº¦ï¼ˆå½“äº‹è€…Bï¼‰',
        'è² å‚·è€…æ•°',
        'è»Šä¸¡ã®è¡çªéƒ¨ä½ï¼ˆå½“äº‹è€…Aï¼‰', 'è»Šä¸¡ã®è¡çªéƒ¨ä½ï¼ˆå½“äº‹è€…Bï¼‰',
        'ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Aï¼‰', 'ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Bï¼‰',
        'ã‚µã‚¤ãƒ‰ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Aï¼‰', 'ã‚µã‚¤ãƒ‰ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Bï¼‰',
        'äº‹æ•…å†…å®¹'  # ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯åŸå› 
    ]
    
    print("\nğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­ï¼ˆäº‹å¾Œæƒ…å ±ã®é™¤å¤–ï¼‰...")
    df_clean = df.drop(columns=drop_cols, errors='ignore')
    
    # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°
    X = df_clean.drop(columns=[target_col])
    y = df_clean[target_col]
    
    # æ¬ æå€¤å‡¦ç†
    num_cols = X.select_dtypes(include=[np.number]).columns
    X[num_cols] = X[num_cols].fillna(X[num_cols].median())
    
    cat_cols = X.select_dtypes(include=['object']).columns
    for col in cat_cols:
        X[col] = X[col].fillna(X[col].mode()[0] if len(X[col].mode()) > 0 else 'Unknown')
    
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    le = LabelEncoder()
    for col in cat_cols:
        X[col] = le.fit_transform(X[col].astype(str))
        
    print(f"âœ“ å‰å‡¦ç†å®Œäº† - ç‰¹å¾´é‡æ•°: {X.shape[1]}")
    
    # LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    lgbm_params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'verbosity': -1,
        'boosting_type': 'gbdt',
        'n_estimators': 1000,
        'learning_rate': 0.05,
        'num_leaves': 31,
        'random_state': 42,
        'n_jobs': -1
    }
    
    # äº¤å·®æ¤œè¨¼ (5-fold)
    k_folds = 5
    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
    
    print(f"\nğŸ”„ {k_folds}-fold äº¤å·®æ¤œè¨¼ã‚’é–‹å§‹ (SMOTEé©ç”¨)...")
    
    fold_metrics = []
    threshold_metrics = [] # é–¾å€¤ã”ã¨ã®æ€§èƒ½ã‚’è¨˜éŒ²
    
    # å…¨ä½“ã®äºˆæ¸¬çµæœã‚’æ ¼ç´ã™ã‚‹é…åˆ—
    y_true_all = []
    y_prob_all = []
    
    for i, (train_index, val_index) in enumerate(skf.split(X, y)):
        print(f"\n--- Fold {i+1}/{k_folds} ---")
        
        X_train, X_val = X.iloc[train_index], X.iloc[val_index]
        y_train, y_val = y.iloc[train_index], y.iloc[val_index]
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰: SMOTE -> LightGBM
        # Pipelineã‚’ä½¿ã†ã“ã¨ã§ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«ã¯SMOTEã‚’é©ç”¨ã›ãšã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã«é©ç”¨ã§ãã‚‹ï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
        model = Pipeline([
            ('smote', SMOTE(random_state=42)),
            ('lgbm', lgb.LGBMClassifier(**lgbm_params))
        ])
        
        # å­¦ç¿’
        model.fit(X_train, y_train)
        
        # äºˆæ¸¬ï¼ˆç¢ºç‡ï¼‰
        y_prob = model.predict_proba(X_val)[:, 1]
        
        # å…¨ä½“ã®çµæœã«è“„ç©
        y_true_all.extend(y_val)
        y_prob_all.extend(y_prob)
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤(0.5)ã§ã®è©•ä¾¡
        y_pred_default = (y_prob >= 0.5).astype(int)
        
        acc = accuracy_score(y_val, y_pred_default)
        prec = precision_score(y_val, y_pred_default, average='binary', zero_division=0)
        rec = recall_score(y_val, y_pred_default, average='binary')
        f1 = f1_score(y_val, y_pred_default, average='binary')
        
        print(f"  [Threshold 0.5] Acc: {acc:.4f}, Prec: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}")
        
        fold_metrics.append({
            'Fold': i+1,
            'Accuracy': acc,
            'Precision': prec,
            'Recall': rec,
            'F1 Score': f1
        })

    # å…¨ãƒ‡ãƒ¼ã‚¿ã§ã®PRæ›²ç·šã¨æœ€é©é–¾å€¤ã®æ¢ç´¢
    y_true_all = np.array(y_true_all)
    y_prob_all = np.array(y_prob_all)
    
    precisions, recalls, thresholds = precision_recall_curve(y_true_all, y_prob_all)
    
    # F1ã‚¹ã‚³ã‚¢ãŒæœ€å¤§ã«ãªã‚‹é–¾å€¤ã‚’æ¢ã™
    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)
    best_idx = np.argmax(f1_scores)
    best_threshold = thresholds[best_idx]
    best_f1 = f1_scores[best_idx]
    
    print("\n" + "=" * 80)
    print("ğŸ¯ æœ€é©é–¾å€¤ã®æ¢ç´¢çµæœ")
    print("=" * 80)
    print(f"Best Threshold (Max F1): {best_threshold:.4f}")
    print(f"Max F1 Score: {best_f1:.4f}")
    print(f"Precision at Best: {precisions[best_idx]:.4f}")
    print(f"Recall at Best: {recalls[best_idx]:.4f}")
    
    # Recallé‡è¦–ã®é–¾å€¤è¨­å®šï¼ˆä¾‹: Recall >= 0.5 ã‚’æº€ãŸã™ä¸­ã§æœ€å¤§ã®Precisionï¼‰
    target_recall = 0.5
    valid_indices = np.where(recalls >= target_recall)[0]
    if len(valid_indices) > 0:
        # valid_indicesã®ä¸­ã§PrecisionãŒæœ€å¤§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¢ã™
        # recallsã¯é™é †ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚æ³¨æ„ãŒå¿…è¦ã ãŒã€é€šå¸¸PRæ›²ç·šã§ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•
        # ã“ã“ã§ã¯å˜ç´”ã«validãªä¸­ã§Precisionæœ€å¤§ã‚’é¸ã¶
        best_prec_idx = valid_indices[np.argmax(precisions[valid_indices])]
        recall_threshold = thresholds[best_prec_idx] if best_prec_idx < len(thresholds) else thresholds[-1]
        
        print(f"\n[Recallé‡è¦–è¨­å®š (Target >= {target_recall})]")
        print(f"Threshold: {recall_threshold:.4f}")
        print(f"Precision: {precisions[best_prec_idx]:.4f}")
        print(f"Recall: {recalls[best_prec_idx]:.4f}")
    
    # PRæ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ
    plt.figure(figsize=(10, 6))
    plt.plot(recalls, precisions, marker='.', label='LightGBM + SMOTE')
    plt.xlabel('Recall (å†ç¾ç‡)')
    plt.ylabel('Precision (é©åˆç‡)')
    plt.title('Precision-Recall Curve')
    plt.legend()
    plt.grid(True)
    
    pr_path = 'results/visualizations/pr_curve_advanced.png'
    plt.savefig(pr_path)
    print(f"\nâœ“ PRæ›²ç·šã‚’ä¿å­˜: {pr_path}")
    
    # æœ€é©é–¾å€¤ã§ã®æ··åŒè¡Œåˆ—
    y_pred_best = (y_prob_all >= best_threshold).astype(int)
    cm = confusion_matrix(y_true_all, y_pred_best)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['éæ­»äº¡', 'æ­»äº¡'], yticklabels=['éæ­»äº¡', 'æ­»äº¡'])
    plt.title(f'Confusion Matrix (Threshold={best_threshold:.4f})')
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    
    cm_path = 'results/visualizations/confusion_matrix_advanced.png'
    plt.savefig(cm_path)
    print(f"âœ“ æ··åŒè¡Œåˆ—ã‚’ä¿å­˜: {cm_path}")
    
    # è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜
    metrics_df = pd.DataFrame(fold_metrics)
    metrics_df.to_csv('results/analysis/advanced_model_metrics.csv', index=False)
    print("âœ“ è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜: results/analysis/advanced_model_metrics.csv")
    
    print("\nâœ… å®Ÿé¨“å®Œäº†")

if __name__ == "__main__":
    main()

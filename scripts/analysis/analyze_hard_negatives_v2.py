"""
Phase 3: Re-Profiling Hard FPs (æ®‹å­˜FPå†åˆ†æ)

ãƒ¢ãƒ‡ãƒ«æ”¹å–„å¾Œã«æ®‹ã£ãŸã€Œã‚ˆã‚Šé›£ã—ã„FPã€ã‚’å†åˆ†æã—ã€
ä»¥å‰ã®ä¸»çŠ¯æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¶ˆãˆãŸã‹ã€æ–°ãŸãªå¼·æ•µãŒå‡ºç¾ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚

Output:
- reprofiling_report.md (æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ)
- cluster_comparison.csv (å‰å› vs ä»Šå›ã®ã‚¯ãƒ©ã‚¹ã‚¿æ¯”è¼ƒ)
- hard_fp_clusters_v2.csv (æ–°ã—ã„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ)
"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import matplotlib as mpl
import matplotlib.font_manager as fm
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
fonts = [f.name for f in fm.fontManager.ttflist]
if 'MS Gothic' in fonts:
    mpl.rcParams['font.family'] = 'MS Gothic'
elif 'IPAexGothic' in fonts:
    mpl.rcParams['font.family'] = 'IPAexGothic'
mpl.rcParams['axes.unicode_minus'] = False

# ãƒ‘ã‚¹è¨­å®š
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
FP_DATA_PATH = os.path.join(BASE_DIR, "results", "experiments", "interaction_features", "fp_new_model.csv")
TP_DATA_PATH = os.path.join(BASE_DIR, "results", "experiments", "interaction_features", "tp_new_model.csv")
PREV_CLUSTER_PATH = os.path.join(BASE_DIR, "results", "analysis", "hard_negatives", "cluster_characteristics.csv")
RESULTS_DIR = os.path.join(BASE_DIR, "results", "analysis", "hard_negatives_v2")
os.makedirs(RESULTS_DIR, exist_ok=True)

# ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°å®šç¾©
CATEGORICAL_COLS = [
    'é“è·¯å½¢çŠ¶', 'ä¿¡å·æ©Ÿ', 'æ˜¼å¤œ', 'å¤©å€™', 'è·¯é¢çŠ¶æ…‹', 'åœ°å½¢',
    'å½“äº‹è€…ç¨®åˆ¥ï¼ˆå½“äº‹è€…Aï¼‰', 'é€Ÿåº¦è¦åˆ¶ï¼ˆæŒ‡å®šã®ã¿ï¼‰ï¼ˆå½“äº‹è€…Aï¼‰', 'é€Ÿåº¦è¦åˆ¶ï¼ˆæŒ‡å®šã®ã¿ï¼‰ï¼ˆå½“äº‹è€…Bï¼‰',
    'party_type_daytime', 'road_shape_terrain', 'night_terrain'
]

# å‰å›ã®Cluster 0ã®ç‰¹æ€§ï¼ˆä¸»çŠ¯æ ¼ï¼‰- å€¤ã¨å‰²åˆã®ãƒšã‚¢
PREV_CLUSTER_0_PROFILE = {
    'æ˜¼å¤œ': (22, 75.0),           # 75% ãŒå¤œé–“
    'åœ°å½¢': (1, 72.0),            # 72% ãŒå¸‚è¡—åœ°
    'é“è·¯å½¢çŠ¶': (14, 44.0),       # 44% ãŒå˜è·¯
    'å½“äº‹è€…ç¨®åˆ¥ï¼ˆå½“äº‹è€…Aï¼‰': (3, 57.0)  # 57% ãŒä¹—ç”¨è»Š
}


def load_data():
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    print("Loading data...")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹æ¤œè¨¼
    if not os.path.exists(FP_DATA_PATH):
        print(f"  âš ï¸ Warning: FP data not found at {FP_DATA_PATH}")
        print(f"  Make sure you ran the experiment first!")
        return pd.DataFrame(), pd.DataFrame(), None
    
    df_fp = pd.read_csv(FP_DATA_PATH)
    df_tp = pd.read_csv(TP_DATA_PATH)
    
    print(f"  Current FP samples: {len(df_fp)}")
    print(f"  Current TP samples: {len(df_tp)}")
    print(f"  Data loaded from: {FP_DATA_PATH}")
    
    # å‰å›ã®ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ã‚’èª­ã¿è¾¼ã¿ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    prev_cluster = None
    if os.path.exists(PREV_CLUSTER_PATH):
        prev_cluster = pd.read_csv(PREV_CLUSTER_PATH)
        print(f"  Previous cluster characteristics loaded")
    
    return df_fp, df_tp, prev_cluster


def select_hard_fp(df_fp: pd.DataFrame, top_n: int = 500):
    """Hard FP é¸æŠ"""
    print(f"\nSelecting top {top_n} Hard FPs...")
    
    if 'oof_proba' not in df_fp.columns:
        return df_fp.head(top_n)
    
    df_hard = df_fp.nlargest(top_n, 'oof_proba').copy()
    print(f"  Probability range: {df_hard['oof_proba'].min():.4f} - {df_hard['oof_proba'].max():.4f}")
    
    return df_hard


def profile_current_fp(df_hard: pd.DataFrame):
    """ç¾åœ¨ã®Hard FPã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ–°ç‰¹å¾´é‡å«ã‚€ï¼‰"""
    print("\n--- Current Hard FP Profile ---")
    
    profile = {}
    
    # æ–°ç‰¹å¾´é‡ã‚’è¿½åŠ 
    new_features = ['night_terrain', 'party_type_daytime', 'road_shape_terrain']
    key_features = ['æ˜¼å¤œ', 'åœ°å½¢', 'é“è·¯å½¢çŠ¶', 'å½“äº‹è€…ç¨®åˆ¥ï¼ˆå½“äº‹è€…Aï¼‰', 'å¤©å€™', 'ä¿¡å·æ©Ÿ', 'hour'] + new_features
    
    for feat in key_features:
        if feat not in df_hard.columns:
            continue
        
        if feat in CATEGORICAL_COLS or df_hard[feat].dtype == 'object':
            mode = df_hard[feat].mode()[0] if not df_hard[feat].mode().empty else None
            pct = (df_hard[feat] == mode).mean() * 100
            profile[feat] = {'mode': mode, 'pct': pct}
            print(f"  {feat}: mode={mode} ({pct:.1f}%)")
        else:
            mean = df_hard[feat].mean()
            profile[feat] = {'mean': mean}
            print(f"  {feat}: mean={mean:.2f}")
    
    return profile


def check_cluster0_elimination(current_profile: dict):
    """Cluster 0 (å‰å›ã®ä¸»çŠ¯æ ¼) ãŒæ¶ˆãˆãŸã‹ãƒã‚§ãƒƒã‚¯ - å‰²åˆå¤‰åŒ–ã‚‚è©•ä¾¡"""
    print("\n--- Cluster 0 Elimination Check ---")
    
    score = 0
    details = []
    
    for feat, (prev_val, prev_pct) in PREV_CLUSTER_0_PROFILE.items():
        if feat not in current_profile:
            continue
        
        curr_mode = current_profile[feat].get('mode')
        curr_pct = current_profile[feat].get('pct', 0)
        
        # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
        if curr_mode != prev_val:
            status = "âœ… Disappeared (Type Change)"
            score += 1
        elif curr_pct < (prev_pct * 0.7):  # 3å‰²ä»¥ä¸Šæ¸›ã£ã¦ã„ã‚Œã°æ”¹å–„
            status = f"âœ… Reduced ({prev_pct:.0f}% â†’ {curr_pct:.1f}%)"
            score += 0.5
        else:
            status = f"âš ï¸ Still Dominant ({prev_pct:.0f}% â†’ {curr_pct:.1f}%)"
        
        details.append({
            'feature': feat,
            'prev_val': prev_val,
            'prev_pct': prev_pct,
            'curr_mode': curr_mode,
            'curr_pct': curr_pct,
            'status': status
        })
        print(f"  {feat}: {prev_val}({prev_pct:.0f}%) â†’ {curr_mode}({curr_pct:.1f}%) | {status}")
    
    # ç·åˆåˆ¤å®š
    total = len(PREV_CLUSTER_0_PROFILE)
    print(f"\n  Score: {score}/{total}")
    
    if score >= 3:
        print("  âœ… æˆåŠŸ: ä¸»çŠ¯æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯è§£æ¶ˆã¾ãŸã¯å¤§å¹…ã«ç¸®å°ã—ã¾ã—ãŸã€‚")
        return True, details
    elif score >= 2:
        print("  âš ï¸ éƒ¨åˆ†çš„æ”¹å–„: ä¸€éƒ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ”¹å–„ã—ã¾ã—ãŸãŒã€ã¾ã å‚¾å‘ãŒæ®‹ã£ã¦ã„ã¾ã™ã€‚")
        return False, details
    else:
        print("  âš ï¸ è­¦å‘Š: ã¾ã ä»¥å‰ã®å‚¾å‘ãŒå¼·ãæ®‹ã£ã¦ã„ã¾ã™ã€‚")
        return False, details


def cluster_hard_fp(df_hard: pd.DataFrame, n_clusters: int = 5):
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°"""
    print(f"\n--- Clustering into {n_clusters} groups ---")
    
    cluster_cols = [
        'é“è·¯å½¢çŠ¶', 'æ˜¼å¤œ', 'å¤©å€™', 'åœ°å½¢',
        'å½“äº‹è€…ç¨®åˆ¥ï¼ˆå½“äº‹è€…Aï¼‰', 'å¹´é½¢ï¼ˆå½“äº‹è€…Aï¼‰', 'speed_reg_diff_abs'
    ]
    use_cols = [c for c in cluster_cols if c in df_hard.columns]
    
    X = df_hard[use_cols].copy()
    
    num_cols = [c for c in use_cols if c not in CATEGORICAL_COLS]
    cat_cols = [c for c in use_cols if c in CATEGORICAL_COLS]
    
    if num_cols:
        X[num_cols] = X[num_cols].fillna(X[num_cols].median())
    
    X_encoded = pd.get_dummies(X, columns=cat_cols, dummy_na=False, drop_first=False)
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_encoded)
    
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(X_scaled)
    
    df_hard = df_hard.copy()
    df_hard['cluster'] = clusters
    
    # PCAå¯è¦–åŒ–
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_scaled)
    
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10', alpha=0.7)
    plt.colorbar(scatter, label='Cluster')
    plt.xlabel('PC1')
    plt.ylabel('PC2')
    plt.title('Hard FP Clusters v2 (After Model Improvement)')
    plt.tight_layout()
    plt.savefig(os.path.join(RESULTS_DIR, 'hard_fp_clusters_v2_pca.png'), dpi=150)
    plt.close()
    
    return df_hard, use_cols


def analyze_new_clusters(df_hard: pd.DataFrame, cluster_cols: list):
    """æ–°ã—ã„ã‚¯ãƒ©ã‚¹ã‚¿ã®ç‰¹æ€§åˆ†æ"""
    print("\n--- New Cluster Characteristics ---")
    
    results = []
    
    for c in sorted(df_hard['cluster'].unique()):
        subset = df_hard[df_hard['cluster'] == c]
        row = {'Cluster': c, 'Count': len(subset)}
        
        if 'oof_proba' in subset.columns:
            row['Avg_Prob'] = subset['oof_proba'].mean()
        
        # å„ç‰¹å¾´é‡ã®ä»£è¡¨å€¤
        for col in cluster_cols:
            if col not in subset.columns:
                continue
            if col in CATEGORICAL_COLS:
                mode = subset[col].mode()[0] if not subset[col].mode().empty else None
                pct = (subset[col] == mode).mean() * 100
                row[f'{col}_mode'] = mode
                row[f'{col}_pct'] = f"{pct:.1f}%"
            else:
                row[f'{col}_mean'] = subset[col].mean()
        
        results.append(row)
        print(f"  Cluster {c}: {len(subset)} samples")
    
    return pd.DataFrame(results)


def detect_new_enemies(df_hard: pd.DataFrame, prev_cluster: pd.DataFrame):
    """æ–°ãŸãªå¼·æ•µãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
    print("\n--- New Enemy Pattern Detection ---")
    
    new_patterns = []
    
    # é »å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
    key_features = ['æ˜¼å¤œ', 'åœ°å½¢', 'é“è·¯å½¢çŠ¶', 'å¤©å€™', 'å½“äº‹è€…ç¨®åˆ¥ï¼ˆå½“äº‹è€…Aï¼‰']
    
    for feat in key_features:
        if feat not in df_hard.columns:
            continue
        
        value_counts = df_hard[feat].value_counts(normalize=True)
        top_value = value_counts.index[0]
        top_pct = value_counts.iloc[0] * 100
        
        # 50%ä»¥ä¸Šã‚’å ã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã€Œæ”¯é…çš„ã€ã¨åˆ¤å®š
        if top_pct >= 50:
            new_patterns.append({
                'Feature': feat,
                'Dominant_Value': top_value,
                'Percentage': f"{top_pct:.1f}%",
                'Warning': "âš ï¸ NEW ENEMY" if top_pct >= 70 else "ğŸ‘€ Watch"
            })
            print(f"  {feat}: {top_value} ({top_pct:.1f}%) â†’ {new_patterns[-1]['Warning']}")
    
    return pd.DataFrame(new_patterns)


def generate_report(current_profile: dict, cluster0_eliminated: bool, elimination_details: list,
                    cluster_df: pd.DataFrame, new_enemies: pd.DataFrame, df_hard: pd.DataFrame):
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    report_path = os.path.join(RESULTS_DIR, 'reprofiling_report.md')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# Hard FP Re-Profiling Report (v2)\n\n")
        f.write("## æ¦‚è¦\n")
        f.write(f"ãƒ¢ãƒ‡ãƒ«æ”¹å–„å¾Œã®æ®‹å­˜FPã‚’å†åˆ†æã—ãŸçµæœã‚’å ±å‘Šã™ã‚‹ã€‚\n\n")
        f.write(f"- **åˆ†æå¯¾è±¡**: äºˆæ¸¬ç¢ºç‡ä¸Šä½ {len(df_hard)} ä»¶ã®FP\n")
        f.write(f"- **äºˆæ¸¬ç¢ºç‡ç¯„å›²**: {df_hard['oof_proba'].min():.4f} - {df_hard['oof_proba'].max():.4f}\n\n")
        
        f.write("## 1. Cluster 0 æ¶ˆæ»…ãƒã‚§ãƒƒã‚¯\n\n")
        if cluster0_eliminated:
            f.write("> [!TIP]\n")
            f.write("> **âœ… æˆåŠŸ**: å‰å›ã®ä¸»çŠ¯æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¤œé–“Ã—å¸‚è¡—åœ°Ã—å˜è·¯Ã—ä¹—ç”¨è»Šï¼‰ã¯å¤‰åŒ–ã—ã¾ã—ãŸã€‚\n\n")
        else:
            f.write("> [!WARNING]\n")
            f.write("> **âš ï¸ è­¦å‘Š**: å‰å›ã®ä¸»çŠ¯æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ä¾ç„¶ã¨ã—ã¦æ®‹ã£ã¦ã„ã¾ã™ã€‚\n\n")
        
        f.write("### å‰å› vs ä»Šå›ã®æ¯”è¼ƒï¼ˆå‰²åˆå¤‰åŒ–è©•ä¾¡ï¼‰\n")
        f.write("| Feature | å‰å›å€¤ | å‰å›å‰²åˆ | ä»Šå›å€¤ | ä»Šå›å‰²åˆ | Status |\n")
        f.write("| :--- | :--- | :--- | :--- | :--- | :--- |\n")
        for d in elimination_details:
            f.write(f"| {d['feature']} | {d['prev_val']} | {d['prev_pct']:.0f}% | {d['curr_mode']} | {d['curr_pct']:.1f}% | {d['status']} |\n")
        f.write("\n")
        
        f.write("## 2. æ–°ãŸãªå¼·æ•µãƒ‘ã‚¿ãƒ¼ãƒ³\n\n")
        if len(new_enemies) > 0:
            f.write(new_enemies.to_markdown(index=False))
        else:
            f.write("æ–°ãŸãªæ”¯é…çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n")
        f.write("\n\n")
        
        f.write("## 3. ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æ\n\n")
        f.write(cluster_df.to_markdown(index=False))
        f.write("\n\n")
        
        f.write("## 4. ã‚¯ãƒ©ã‚¹ã‚¿å¯è¦–åŒ–\n")
        f.write("![Clusters v2](hard_fp_clusters_v2_pca.png)\n\n")
        
        f.write("## 5. æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n")
        if cluster0_eliminated:
            f.write("1. æ–°ãŸã«æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾ã™ã‚‹ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’æ¤œè¨\n")
            f.write("2. ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã‚ˆã‚‹æ›´ãªã‚‹ç²¾åº¦å‘ä¸Š\n")
        else:
            f.write("1. ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’æ¤œè¨ï¼ˆç‰¹å¾´é‡ã§ã¯åŒºåˆ¥å›°é›£ï¼‰\n")
            f.write("2. Cluster 0 ã«å¯¾ã™ã‚‹é‡ã¿ä»˜ã‘å­¦ç¿’\n")
    
    print(f"\nReport saved: {report_path}")


def main():
    print("=" * 60)
    print("Phase 3: Re-Profiling Hard FPs (After Model Improvement)")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df_fp, df_tp, prev_cluster = load_data()
    
    # Hard FP é¸æŠ
    df_hard = select_hard_fp(df_fp, top_n=500)
    
    # ç¾åœ¨ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
    current_profile = profile_current_fp(df_hard)
    
    # Cluster 0 æ¶ˆæ»…ãƒã‚§ãƒƒã‚¯
    cluster0_eliminated, elimination_details = check_cluster0_elimination(current_profile)
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    df_hard, cluster_cols = cluster_hard_fp(df_hard, n_clusters=5)
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§åˆ†æ
    cluster_df = analyze_new_clusters(df_hard, cluster_cols)
    
    # æ–°ãŸãªå¼·æ•µæ¤œå‡º
    new_enemies = detect_new_enemies(df_hard, prev_cluster)
    
    # çµæœä¿å­˜
    df_hard.to_csv(os.path.join(RESULTS_DIR, 'hard_fp_clusters_v2.csv'), index=False)
    cluster_df.to_csv(os.path.join(RESULTS_DIR, 'cluster_characteristics_v2.csv'), index=False)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_report(current_profile, cluster0_eliminated, elimination_details, cluster_df, new_enemies, df_hard)
    
    print("\nPhase 3 Complete!")
    print(f"Results saved to: {RESULTS_DIR}")


if __name__ == "__main__":
    main()

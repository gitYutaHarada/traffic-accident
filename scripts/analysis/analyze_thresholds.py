"""
ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®é–¾å€¤åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
====================================
ç›®çš„:
1. Precision-Recall Curve (PRæ›²ç·š) ã®æç”»
2. F1 ScoreãŒæœ€å¤§ã«ãªã‚‹ã€Œæœ€é©é–¾å€¤ã€ã®ç‰¹å®š
3. ä»¥ä¸‹ã®3ã¤ã®ã‚·ãƒŠãƒªã‚ªã«åŸºã¥ãé–¾å€¤ææ¡ˆ
    - ã‚¹ãƒ†ãƒƒãƒ—1: ãƒãƒ©ãƒ³ã‚¹é‡è¦– (Max F1)
    - ã‚¹ãƒ†ãƒƒãƒ—2: è¦‹é€ƒã—é˜²æ­¢ (High Recall)
    - ã‚¹ãƒ†ãƒƒãƒ—3: ç¢ºå®Ÿæ€§é‡è¦– (High Precision)

å®Ÿè¡Œæ–¹æ³•:
    python scripts/analysis/analyze_thresholds.py
"""

import pandas as pd
import numpy as np
import os
import joblib
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import precision_recall_curve, f1_score, auc, recall_score, precision_score
from scipy.optimize import minimize

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
# sns.set(style="whitegrid")

class ThresholdAnalyzer:
    def __init__(
        self,
        data_path="data/processed/honhyo_for_analysis_with_traffic_hospital_no_leakage.csv",
        target_col="fatal",
        ckpt_dir="results/ensemble_stage2/checkpoints",
        output_dir="results/ensemble_stage2",
        random_state=42,
        n_folds=5,
        n_seeds=3,
        undersample_ratio=2.0
    ):
        self.data_path = data_path
        self.target_col = target_col
        self.ckpt_dir = ckpt_dir
        self.output_dir = output_dir
        self.random_state = random_state
        self.n_folds = n_folds
        self.n_seeds = n_seeds
        self.undersample_ratio = undersample_ratio
        
        self.tabnet_available = True  # å®Ÿé¨“ã§TabNetä½¿ç”¨æ¸ˆã¿ã¨ä»®å®š

    def load_and_reconstruct_oof(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨OOFå†æ§‹ç¯‰"""
        print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€OOFã‚’å†æ§‹ç¯‰ä¸­...")
        
        # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & åˆ†å‰²
        df = pd.read_csv(self.data_path)
        y_all = df[self.target_col].values
        X_all = df.drop(columns=[self.target_col])
        if 'ç™ºç”Ÿæ—¥æ™‚' in X_all.columns:
            X_all = X_all.drop(columns=['ç™ºç”Ÿæ—¥æ™‚'])
            
        X_train, X_test, y_train, y_test = train_test_split(
            X_all, y_all, test_size=0.2, random_state=self.random_state, stratify=y_all
        )
        X_train = X_train.reset_index(drop=True)
        self.y_train = y_train  # CVç”¨GT

        # 2. Stage 1 OOF å†æ§‹ç¯‰
        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)
        oof_stage1 = np.zeros(len(y_train))
        
        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):
            fold_dir = os.path.join(self.ckpt_dir, f"stage1_fold{fold}")
            fold_pred = np.zeros(len(val_idx))
            for seed in range(self.n_seeds):
                pred_path = os.path.join(fold_dir, f"seed{seed}_pred.npy")
                if os.path.exists(pred_path):
                    fold_pred += np.load(pred_path)
            oof_stage1[val_idx] = fold_pred / self.n_seeds
            
        # 3. Stage 1 Threshold & Recall
        # train_ensemble_stage2.py ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å†ç¾ (Recall 99%ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ)
        stage1_recall_target = 0.99
        threshold_stage1 = 0.001
        for thresh in np.arange(0.50, 0.001, -0.005):
            y_pred = (oof_stage1 >= thresh).astype(int)
            recall = recall_score(y_train, y_pred)
            if recall >= stage1_recall_target:
                threshold_stage1 = thresh
                break
        
        stage2_mask = oof_stage1 >= threshold_stage1
        self.y_s2 = y_train[stage2_mask]
        print(f"   Stage 1 Threshold: {threshold_stage1:.4f}")
        print(f"   Stage 2 Data Count: {len(self.y_s2):,} (Positive: {self.y_s2.sum()})")

        # 4. Stage 2 OOF å†æ§‹ç¯‰
        X_s2 = X_train[stage2_mask].reset_index(drop=True) # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚»ãƒƒãƒˆé‡è¦
        # Stage 2ã®CVåˆ†å‰²ã‚‚å†ç¾ãŒå¿…è¦
        # train_ensemble_stage2.pyã§ã¯ X_s2 ã«å¯¾ã—ã¦ StratifiedKFold ã—ã¦ã„ã‚‹
        skf_s2 = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)
        
        self.oof_lgb = np.zeros(len(self.y_s2))
        self.oof_cat = np.zeros(len(self.y_s2))
        self.oof_tab = np.zeros(len(self.y_s2))
        
        for fold, (train_idx, val_idx) in enumerate(skf_s2.split(X_s2, self.y_s2)):
            fold_dir = os.path.join(self.ckpt_dir, f"stage2_fold{fold}")
            
            p_lgb = os.path.join(fold_dir, "lgb_pred.npy")
            p_cat = os.path.join(fold_dir, "cat_pred.npy")
            p_tab = os.path.join(fold_dir, "tab_pred.npy")
            
            if os.path.exists(p_lgb): self.oof_lgb[val_idx] = np.load(p_lgb)
            if os.path.exists(p_cat): self.oof_cat[val_idx] = np.load(p_cat)
            if os.path.exists(p_tab): self.oof_tab[val_idx] = np.load(p_tab)

    def optimize_ensemble(self):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿ã®å†æœ€é©åŒ–"""
        print("âš–ï¸ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿æœ€é©åŒ–ä¸­...")
        def loss_func(weights):
            weights = np.array(weights)
            weights = np.clip(weights, 0, 1)
            weights /= weights.sum() + 1e-8
            ens_proba = weights[0]*self.oof_lgb + weights[1]*self.oof_cat + weights[2]*self.oof_tab
            y_pred = (ens_proba >= 0.5).astype(int)
            return -f1_score(self.y_s2, y_pred) # F1æœ€å¤§åŒ–

        init_weights = [1/3, 1/3, 1/3]
        bounds = [(0.05, 0.9)] * 3
        constraints = {'type': 'eq', 'fun': lambda w: 1 - sum(w)}
        
        res = minimize(loss_func, init_weights, method='SLSQP', bounds=bounds, constraints=constraints)
        self.weights = res.x / res.x.sum()
        print(f"   Optimal Weights: LGB={self.weights[0]:.3f}, Cat={self.weights[1]:.3f}, Tab={self.weights[2]:.3f}")
        
        self.oof_ensemble = (
            self.weights[0]*self.oof_lgb + 
            self.weights[1]*self.oof_cat + 
            self.weights[2]*self.oof_tab
        )

    def analyze_thresholds(self):
        """3ã¤ã®ã‚·ãƒŠãƒªã‚ªã«åŸºã¥ãé–¾å€¤åˆ†æ"""
        print("\nğŸ“Š é–¾å€¤åˆ†æã‚’å®Ÿè¡Œä¸­...")
        
        precisions, recalls, thresholds = precision_recall_curve(self.y_s2, self.oof_ensemble)
        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)
        
        # --- ã‚¹ãƒ†ãƒƒãƒ—1: ãƒãƒ©ãƒ³ã‚¹é‡è¦– (Max F1) ---
        best_idx = np.argmax(f1_scores)
        best_f1 = f1_scores[best_idx]
        best_thresh = thresholds[best_idx]
        best_prec = precisions[best_idx]
        best_rec = recalls[best_idx]
        
        # --- ã‚¹ãƒ†ãƒƒãƒ—2: è¦‹é€ƒã—é˜²æ­¢ (High Recall) ---
        # Recall >= 0.98 ã‚’æº€ãŸã™ä¸­ã§ã®æœ€å¤§Precision
        # Recallã¯é™é †ã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ãŒã€å¿µã®ãŸã‚æ¤œç´¢
        # thresholdsã¯æ˜‡é †, precisions/recallsã¯thresholdsã«å¯¾å¿œ(æœ€å¾Œã®è¦ç´ ã¯1,0)
        # thresholdsã®é•·ã•ã¯ len(precisions)-1
        
        # target_recall = 0.98
        # idx_recall = np.where(recalls[:-1] >= target_recall)[0]
        # if len(idx_recall) > 0:
        #     # Recallæ¡ä»¶ã‚’æº€ãŸã™ä¸­ã§æœ€å¤§ã®Precisionã‚’æŒã¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆä¸€èˆ¬ã«é–¾å€¤ãŒé«˜ã„ã»ã©Precisioné«˜ã„ï¼‰
        #     # thresholdsã¯æ˜‡é †ãªã®ã§ã€æ¡ä»¶ã‚’æº€ãŸã™æœ€å¤§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæœ€ã‚‚é«˜ã„é–¾å€¤
        #     target_idx = idx_recall[-1] 
        # else:
        #     target_idx = 0
            
        # ã‚‚ã£ã¨å˜ç´”ã«ã€RecallãŒXä»¥ä¸Šã«ãªã‚‹ã‚®ãƒªã‚®ãƒªã®é–¾å€¤ã‚’æ¢ã™
        def get_metrics_at_recall(target_recall):
            idx = np.where(recalls >= target_recall)[0]
            if len(idx) == 0: return 0, 0, 0, 0
            # idx[-1] ãŒæ¡ä»¶ã‚’æº€ãŸã™ä¸­ã§æœ€ã‚‚é«˜ã„é–¾å€¤ï¼ˆPrecisionãŒé«˜ããªã‚Šã‚„ã™ã„ï¼‰
            i = idx[-1]
            # iãŒthresholdsã®ç¯„å›²å¤–ã«ãªã‚‹å ´åˆ(æœ€å¾Œ)ã®ã‚±ã‚¢
            th = thresholds[i] if i < len(thresholds) else 1.0
            return th, precisions[i], recalls[i], f1_scores[i]

        rec_th, rec_pre, rec_rec, rec_f1 = get_metrics_at_recall(0.98) # 98% Recallç›®æ¨™

        # --- ã‚¹ãƒ†ãƒƒãƒ—3: ç¢ºå®Ÿæ€§é‡è¦– (High Precision) ---
        # Precision >= 0.80 ãªã©ã‚’ç‹™ã†ã€ã‚ã‚‹ã„ã¯F0.5ã‚¹ã‚³ã‚¢æœ€å¤§åŒ–ãªã©
        # ã“ã“ã§ã¯ã€Œäºˆç®—é™å®šã€â†’ Top 100ä»¶ç¨‹åº¦ã«çµã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã ãŒã€é–¾å€¤ã¨ã—ã¦ã¯
        # PrecisionãŒæ€¥æ¿€ã«ä¸ŠãŒã‚‹ãƒã‚¤ãƒ³ãƒˆã€ã¾ãŸã¯Precision 80%ãƒ©ã‚¤ãƒ³
        
        def get_metrics_at_precision(target_precision):
            idx = np.where(precisions >= target_precision)[0]
            if len(idx) == 0: return 0, 0, 0, 0
            # idx[0] ãŒæ¡ä»¶ã‚’æº€ãŸã™æœ€ã‚‚ä½ã„é–¾å€¤ (RecallãŒé«˜ããªã‚Šã‚„ã™ã„)
            i = idx[0]
            th = thresholds[i] if i < len(thresholds) else 1.0
            return th, precisions[i], recalls[i], f1_scores[i]

        prec_th, prec_pre, prec_rec, prec_f1 = get_metrics_at_precision(0.80) 
        # ã‚‚ã—80%ã«å±Šã‹ãªã‘ã‚Œã°æœ€å¤§Precision
        if prec_th == 0:
            max_p_idx = np.argmax(precisions)
            prec_th = thresholds[max_p_idx] if max_p_idx < len(thresholds) else 1.0
            prec_pre = precisions[max_p_idx]
            prec_rec = recalls[max_p_idx]
            prec_f1 = f1_scores[max_p_idx]

        # ã‚°ãƒ©ãƒ•æç”»
        plt.figure(figsize=(10, 6))
        plt.plot(recalls, precisions, label='Ensemble Model')
        plt.scatter(best_rec, best_prec, c='red', s=100, label=f'Max F1 (Th={best_thresh:.3f})', zorder=5)
        plt.scatter(rec_rec, rec_pre, c='orange', s=100, label=f'High Recall (Th={rec_th:.3f})', zorder=5)
        plt.scatter(prec_rec, prec_pre, c='green', s=100, label=f'High Precision (Th={prec_th:.3f})', zorder=5)
        
        plt.title('Precision-Recall Curve with Strategy Points')
        plt.xlabel('Recall (Detection Rate)')
        plt.ylabel('Precision (Hit Rate)')
        plt.legend()
        plt.grid(True)
        plt.savefig(os.path.join(self.output_dir, 'threshold_analysis_pr_curve.png'))
        plt.close()

        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        report = f"""
# é–¾å€¤æœ€é©åŒ– & æˆ¦ç•¥åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## ã‚¹ãƒ†ãƒƒãƒ—1: é–¾å€¤ã®æœ€é©åŒ– (Max F1 Score)
**ãƒãƒ©ãƒ³ã‚¹é‡è¦–**: ç²¾åº¦ã¨æ¤œçŸ¥ç‡ã®ãƒãƒ©ãƒ³ã‚¹ãŒæœ€ã‚‚è‰¯ã„ãƒã‚¤ãƒ³ãƒˆ
- **Threshold**: {best_thresh:.4f}
- **F1 Score**: {best_f1:.4f}
- Precision: {best_prec:.4f}
- Recall: {best_rec:.4f}

## ã‚¹ãƒ†ãƒƒãƒ—2: è¦‹é€ƒã—ã‚’æ¸›ã‚‰ã—ãŸã„ (High Recall Strategy)
**è­¦å¯Ÿãƒ‘ãƒˆãƒ­ãƒ¼ãƒ«é‡ç‚¹ç®‡æ‰€**: ã€Œæ€ªã—ã„å ´æ‰€ã¯å…¨éƒ¨æ¤œçŸ¥ã€
- **Target Recall**: ~98%
- **Threshold**: {rec_th:.4f}
- **Precision**: {rec_pre:.4f}
- Recall: {rec_rec:.4f}
- F1 Score: {rec_f1:.4f}
*è§£èª¬: PrecisionãŒä½ã„ï¼ˆ{rec_pre:.2%}ï¼‰ãŸã‚ã€ç©ºæŒ¯ã‚ŠãŒå¤šã„ãŒã€å±é™ºãªå ´æ‰€ã®98%ã‚’ç¶²ç¾…ã§ãã‚‹è¨­å®šã€‚*

## ã‚¹ãƒ†ãƒƒãƒ—3: ç¢ºå®Ÿãªå ´æ‰€ã ã‘çŸ¥ã‚ŠãŸã„ (High Precision Strategy)
**äºˆç®—é™å®šãƒ»é›†ä¸­å¯¾ç­–**: ã€Œçµ¶å¯¾ã«äº‹æ•…ãŒèµ·ãã‚‹å ´æ‰€ã ã‘ã€
- **Target Precision**: ~80% (ã¾ãŸã¯æœ€å¤§)
- **Threshold**: {prec_th:.4f}
- **Precision**: {prec_pre:.4f}
- Recall: {prec_rec:.4f}
- F1 Score: {prec_f1:.4f}
*è§£èª¬: æ¤œçŸ¥æ•°ï¼ˆRecallï¼‰ã¯ä½ã„ï¼ˆ{prec_rec:.2%}ï¼‰ãŒã€è­¦å ±ãŒå‡ºãŸå ´æ‰€ã®{prec_pre:.2%}ã§å®Ÿéš›ã«äº‹æ•…ãŒç™ºç”Ÿã—ã¦ã„ã‚‹é«˜ç¢ºåº¦è¨­å®šã€‚*
"""
        print(report)
        with open(os.path.join(self.output_dir, 'threshold_strategies.md'), 'w', encoding='utf-8') as f:
            f.write(report)

        return report

if __name__ == "__main__":
    analyzer = ThresholdAnalyzer()
    analyzer.load_and_reconstruct_oof()
    analyzer.optimize_ensemble()
    analyzer.analyze_thresholds()

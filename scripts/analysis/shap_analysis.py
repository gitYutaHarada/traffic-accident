import pandas as pd
import numpy as np
import shap
import lightgbm as lgb
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import matplotlib as mpl
import os

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š (Windowså‘ã‘)
mpl.rcParams['font.family'] = 'MS Gothic'
# ãƒã‚¤ãƒŠã‚¹è¨˜å·ã®æ–‡å­—åŒ–ã‘é˜²æ­¢
mpl.rcParams['axes.unicode_minus'] = False

def main():
    """
    LightGBMãƒ¢ãƒ‡ãƒ«ã®SHAPåˆ†æã‚’è¡Œã„ã€äºˆæ¸¬ã®æ ¹æ‹ ã‚’å¯è¦–åŒ–ã™ã‚‹
    """
    
    print("=" * 80)
    print("ãƒ¢ãƒ‡ãƒ«è§£é‡ˆ: SHAPåˆ†æã«ã‚ˆã‚‹å¯è¦–åŒ–")
    print("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    file_path = 'data/raw/honhyo_all_shishasuu_binary.csv'
    print(f"\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {file_path}")
    
    try:
        df = pd.read_csv(file_path)
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,} ä»¶")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ç›®çš„å¤‰æ•°
    target_col = 'æ­»è€…æ•°'
    
    # é™¤å¤–ã™ã‚‹åˆ—ï¼ˆäº‹å¾Œæƒ…å ±ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯åŸå› ï¼‰
    drop_cols = [
        'è³‡æ–™åŒºåˆ†', 'æœ¬ç¥¨ç•ªå·',
        'äººèº«æå‚·ç¨‹åº¦ï¼ˆå½“äº‹è€…Aï¼‰', 'äººèº«æå‚·ç¨‹åº¦ï¼ˆå½“äº‹è€…Bï¼‰',
        'è»Šä¸¡ã®æå£Šç¨‹åº¦ï¼ˆå½“äº‹è€…Aï¼‰', 'è»Šä¸¡ã®æå£Šç¨‹åº¦ï¼ˆå½“äº‹è€…Bï¼‰',
        'è² å‚·è€…æ•°',
        'è»Šä¸¡ã®è¡çªéƒ¨ä½ï¼ˆå½“äº‹è€…Aï¼‰', 'è»Šä¸¡ã®è¡çªéƒ¨ä½ï¼ˆå½“äº‹è€…Bï¼‰',
        'ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Aï¼‰', 'ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Bï¼‰',
        'ã‚µã‚¤ãƒ‰ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Aï¼‰', 'ã‚µã‚¤ãƒ‰ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™ï¼ˆå½“äº‹è€…Bï¼‰',
        'äº‹æ•…å†…å®¹'
    ]
    
    print("\nğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
    df_clean = df.drop(columns=drop_cols, errors='ignore')
    
    # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°
    X = df_clean.drop(columns=[target_col])
    y = df_clean[target_col]
    
    # æ¬ æå€¤å‡¦ç†
    num_cols = X.select_dtypes(include=[np.number]).columns
    X[num_cols] = X[num_cols].fillna(X[num_cols].median())
    
    cat_cols = X.select_dtypes(include=['object']).columns
    for col in cat_cols:
        X[col] = X[col].fillna(X[col].mode()[0] if len(X[col].mode()) > 0 else 'Unknown')
    
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    le = LabelEncoder()
    for col in cat_cols:
        X[col] = le.fit_transform(X[col].astype(str))
        
    print(f"âœ“ å‰å‡¦ç†å®Œäº† - ç‰¹å¾´é‡æ•°: {X.shape[1]}")
    print("ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ç‰¹å¾´é‡ä¸€è¦§:")
    print(list(X.columns))
    
    # é™¤å¤–ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹åˆ—ãŒæ®‹ã£ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
    remaining_drop_cols = [col for col in drop_cols if col in X.columns]
    if remaining_drop_cols:
        print(f"âš ï¸ è­¦å‘Š: é™¤å¤–ã™ã¹ãåˆ—ãŒæ®‹ã£ã¦ã„ã¾ã™: {remaining_drop_cols}")
    else:
        print("âœ“ é™¤å¤–ãƒªã‚¹ãƒˆã®åˆ—ã¯ã™ã¹ã¦å‰Šé™¤ã•ã‚Œã¦ã„ã¾ã™")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ï¼ˆå­¦ç¿’ç”¨ã¨SHAPè¨ˆç®—ç”¨ï¼‰
    # SHAPè¨ˆç®—ã¯é‡ã„ãŸã‚ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’ä½¿ç”¨ã™ã‚‹
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦SMOTEé©ç”¨
    print("\nğŸ”„ SMOTEã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œä¸­...")
    smote = SMOTE(random_state=42)
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
    print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°: {len(X_train)} -> {len(X_train_res)}")
    
    # LightGBMãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
    print("\nğŸŒ² LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
    lgbm_params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'verbosity': -1,
        'boosting_type': 'gbdt',
        'n_estimators': 1000,
        'learning_rate': 0.05,
        'num_leaves': 31,
        'random_state': 42,
        'n_jobs': -1
    }
    
    model = lgb.LGBMClassifier(**lgbm_params)
    model.fit(X_train_res, y_train_res)
    print("âœ“ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
    
    # SHAPå€¤ã®è¨ˆç®—
    print("\nğŸ” SHAPå€¤ã‚’è¨ˆç®—ä¸­...")
    # è¨ˆç®—æ™‚é–“ã‚’è€ƒæ…®ã—ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆä¾‹: 2000ä»¶ï¼‰
    # æ­»äº¡äº‹æ•…ï¼ˆå°‘æ•°æ´¾ï¼‰ã‚’å¤šã‚ã«å«ã‚ã‚‹ã¨ç‰¹å¾´ãŒè¦‹ãˆã‚„ã™ã„ãŒã€
    # å…¨ä½“ã®å‚¾å‘ã‚’è¦‹ã‚‹ãŸã‚ã«ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨ã™ã‚‹
    sample_size = 2000
    if len(X_test) > sample_size:
        X_shap = X_test.sample(n=sample_size, random_state=42)
    else:
        X_shap = X_test
        
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_shap)
    
    # LightGBMã®binary classificationã®å ´åˆã€shap_valuesã¯ãƒªã‚¹ãƒˆã§è¿”ã‚‹å ´åˆã¨arrayã§è¿”ã‚‹å ´åˆãŒã‚ã‚‹
    # shap ver 0.40ä»¥é™ã®æŒ™å‹•ã‚’ç¢ºèª
    if isinstance(shap_values, list):
        # ã‚¯ãƒ©ã‚¹1ï¼ˆæ­»äº¡äº‹æ•…ï¼‰ã«å¯¾ã™ã‚‹SHAPå€¤ã‚’å–å¾—
        shap_values_target = shap_values[1]
    else:
        # arrayã®å ´åˆ (n_samples, n_features) ã¾ãŸã¯ (n_samples, n_features, n_classes)
        if len(shap_values.shape) == 3:
             shap_values_target = shap_values[:, :, 1]
        else:
             shap_values_target = shap_values

    print("âœ“ SHAPå€¤è¨ˆç®—å®Œäº†")
    
    # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_dir = 'results/visualizations/shap'
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. Summary Plot (Bar) - ç‰¹å¾´é‡é‡è¦åº¦
    print("\nğŸ“Š Summary Plot (Bar) ã‚’ä½œæˆä¸­...")
    plt.figure()
    shap.summary_plot(shap_values_target, X_shap, plot_type="bar", show=False)
    plt.title('SHAP ç‰¹å¾´é‡é‡è¦åº¦', fontsize=16)
    plt.tight_layout()
    plt.savefig(f'{output_dir}/shap_summary_bar.png', bbox_inches='tight')
    plt.close()
    
    # 2. Summary Plot (Dot) - å½±éŸ¿ã®æ–¹å‘æ€§
    print("ğŸ“Š Summary Plot (Dot) ã‚’ä½œæˆä¸­...")
    plt.figure()
    shap.summary_plot(shap_values_target, X_shap, show=False)
    plt.title('SHAP Summary Plot', fontsize=16)
    plt.tight_layout()
    plt.savefig(f'{output_dir}/shap_summary_dot.png', bbox_inches='tight')
    plt.close()
    
    # 3. Dependence Plot - ä¸Šä½ç‰¹å¾´é‡ã®è©³ç´°åˆ†æ
    # é‡è¦åº¦ä¸Šä½ã®ç‰¹å¾´é‡ã‚’å–å¾—
    # shap_valuesã®çµ¶å¯¾å€¤ã®å¹³å‡ã‚’ã¨ã£ã¦ãƒ©ãƒ³ã‚¯ä»˜ã‘
    mean_abs_shap = np.abs(shap_values_target).mean(axis=0)
    top_features_indices = np.argsort(mean_abs_shap)[::-1][:3] # Top 3
    top_features = X.columns[top_features_indices]
    
    print(f"ğŸ“Š Dependence Plot ã‚’ä½œæˆä¸­ (Top 3ç‰¹å¾´é‡: {list(top_features)})...")
    
    for feature in top_features:
        plt.figure()
        shap.dependence_plot(feature, shap_values_target, X_shap, show=False)
        plt.title(f'SHAP Dependence Plot: {feature}', fontsize=14)
        plt.tight_layout()
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆãªã„æ–‡å­—ã‚’ç½®æ›
        safe_feature_name = feature.replace('/', '_').replace(':', '_').replace(' ', '_')
        plt.savefig(f'{output_dir}/shap_dependence_{safe_feature_name}.png', bbox_inches='tight')
        plt.close()
        
    print("\nâœ… åˆ†æå®Œäº†")
    print(f"çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()

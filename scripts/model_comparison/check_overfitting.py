"""
éå­¦ç¿’ç¢ºèªç”¨: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã§æ€§èƒ½ã‚’æ¸¬å®š

æ—¢å­˜ã®1%ã‚µãƒ³ãƒ—ãƒ«çµæœã«å¯¾ã—ã¦ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½ã‚‚æ¸¬å®šã—ã€
éå­¦ç¿’ã®æœ‰ç„¡ã‚’ç¢ºèªã™ã‚‹ã€‚
"""

import pandas as pd
import numpy as np
import warnings
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score
)
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib as mpl

warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
mpl.rcParams['font.family'] = 'MS Gothic'

def main():
    """
    éå­¦ç¿’ç¢ºèª: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®æ€§èƒ½ã‚’æ¯”è¼ƒ
    """
    
    print("=" * 80)
    print("éå­¦ç¿’ç¢ºèª: ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸° (1%ã‚µãƒ³ãƒ—ãƒ«)")
    print("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    file_path = 'data/processed/honhyo_model_ready.csv'
    print(f"\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {file_path}")
    
    df = pd.read_csv(file_path)
    print(f"âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,} ä»¶")
    
    # ç›®çš„å¤‰æ•°
    target_col = 'æ­»è€…æ•°'
    
    # 1%ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°(å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)
    sample_rate = 0.01
    print(f"\nğŸ² {sample_rate*100:.1f}% ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä¸­(å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)...")
    df_0 = df[df[target_col] == 0].sample(frac=sample_rate, random_state=42)
    df_1 = df[df[target_col] == 1].sample(frac=sample_rate, random_state=42)
    df = pd.concat([df_0, df_1], ignore_index=True)
    df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)
    print(f"âœ“ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Œäº†: {len(df):,} ä»¶")
    
    # é™¤å¤–ã™ã‚‹åˆ—
    drop_cols = [
        'è³‡æ–™åŒºåˆ†', 'æœ¬ç¥¨ç•ªå·',
        'äººèº«æå‚·ç¨‹åº¦(å½“äº‹è€…A)', 'äººèº«æå‚·ç¨‹åº¦(å½“äº‹è€…B)',
        'è»Šä¸¡ã®æå£Šç¨‹åº¦(å½“äº‹è€…A)', 'è»Šä¸¡ã®æå£Šç¨‹åº¦(å½“äº‹è€…B)',
        'è² å‚·è€…æ•°',
        'è»Šä¸¡ã®è¡çªéƒ¨ä½(å½“äº‹è€…A)', 'è»Šä¸¡ã®è¡çªéƒ¨ä½(å½“äº‹è€…B)',
        'ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™(å½“äº‹è€…A)', 'ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™(å½“äº‹è€…B)',
        'ã‚µã‚¤ãƒ‰ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™(å½“äº‹è€…A)', 'ã‚µã‚¤ãƒ‰ã‚¨ã‚¢ãƒãƒƒã‚°ã®è£…å‚™(å½“äº‹è€…B)',
        'äº‹æ•…å†…å®¹'
    ]
    
    # ã‚«ãƒ©ãƒ åã®æ­£è¦åŒ–
    df.columns = df.columns.str.replace('(', '(').str.replace(')', ')')
    
    print("\nğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
    df_clean = df.drop(columns=drop_cols, errors='ignore')
    
    # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°
    X = df_clean.drop(columns=[target_col])
    y = df_clean[target_col]
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¨æ•°å€¤å¤‰æ•°ã®åˆ†é¡
    count_encoding_cols = [col for col in X.columns if col.endswith('_count')]
    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    
    explicit_cat_cols = [
        'éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'è·¯ç·šã‚³ãƒ¼ãƒ‰', 'åœ°ç‚¹ã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰',
        'æ˜¼å¤œ', 'å¤©å€™', 'åœ°å½¢', 'è·¯é¢çŠ¶æ…‹', 'é“è·¯å½¢çŠ¶', 'ä¿¡å·æ©Ÿ',
        'ä¸€æ™‚åœæ­¢è¦åˆ¶ æ¨™è­˜', 'ä¸€æ™‚åœæ­¢è¦åˆ¶ è¡¨ç¤º', 'è»Šé“å¹…å“¡', 'é“è·¯ç·šå½¢',
        'è¡çªåœ°ç‚¹', 'ã‚¾ãƒ¼ãƒ³è¦åˆ¶', 'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰', 'æ­©è»Šé“åŒºåˆ†',
        'äº‹æ•…é¡å‹', 'å¹´é½¢', 'å½“äº‹è€…ç¨®åˆ¥', 'ç”¨é€”åˆ¥', 'è»Šä¸¡å½¢çŠ¶',
        'ã‚ªãƒ¼ãƒˆãƒãƒãƒƒã‚¯è»Š', 'ã‚µãƒã‚«ãƒ¼', 'é€Ÿåº¦è¦åˆ¶(æŒ‡å®šã®ã¿)',
        'æ›œæ—¥', 'ç¥æ—¥', 'ç™ºç”Ÿæœˆ', 'ç™ºç”Ÿæ™‚', 'ç™ºç”Ÿå¹´', 'Area_Cluster_ID'
    ]
    
    explicit_cat_cols = [c for c in explicit_cat_cols if c in X.columns and c not in count_encoding_cols]
    final_cat_cols = list(set(categorical_cols + explicit_cat_cols))
    final_numeric_cols = [c for c in numeric_cols if c not in final_cat_cols]
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚’æ–‡å­—åˆ—å‹ã«å¤‰æ›
    for col in final_cat_cols:
        if col in X.columns:
            X[col] = X[col].astype(str)
    
    # é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£å‡¦ç†
    high_cardinality_threshold = 50
    for col in final_cat_cols:
        if col in X.columns:
            nunique = X[col].nunique()
            if nunique > high_cardinality_threshold:
                top_categories = X[col].value_counts().head(high_cardinality_threshold).index
                X[col] = X[col].apply(lambda x: x if x in top_categories else 'ãã®ä»–')
    
    # å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, max_categories=30))
    ])
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, final_numeric_cols),
            ('cat', categorical_transformer, final_cat_cols)
        ],
        remainder='drop'
    )
    
    # ãƒ¢ãƒ‡ãƒ«
    model = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', LogisticRegression(
            penalty='l2',
            C=1.0,
            solver='saga',
            max_iter=500,
            class_weight='balanced',
            random_state=42,
            verbose=0,  # é€²æ—è¡¨ç¤ºã‚’æŠ‘åˆ¶
            n_jobs=-1
        ))
    ])
    
    # 5-foldäº¤å·®æ¤œè¨¼
    k_folds = 5
    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
    
    print(f"\nğŸ”„ {k_folds}-fold äº¤å·®æ¤œè¨¼ã‚’é–‹å§‹(è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã§è©•ä¾¡)...\n")
    
    fold_metrics = []
    
    for i, (train_index, val_index) in enumerate(skf.split(X, y)):
        print(f"--- Fold {i+1}/{k_folds} ---")
        
        X_train, X_val = X.iloc[train_index], X.iloc[val_index]
        y_train, y_val = y.iloc[train_index], y.iloc[val_index]
        
        # å­¦ç¿’
        print(f"  å­¦ç¿’ä¸­...")
        model.fit(X_train, y_train)
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
        y_train_prob = model.predict_proba(X_train)[:, 1]
        y_train_pred = (y_train_prob >= 0.5).astype(int)
        
        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
        y_val_prob = model.predict_proba(X_val)[:, 1]
        y_val_pred = (y_val_prob >= 0.5).astype(int)
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®è©•ä¾¡
        train_acc = accuracy_score(y_train, y_train_pred)
        train_prec = precision_score(y_train, y_train_pred, average='binary', zero_division=0)
        train_rec = recall_score(y_train, y_train_pred, average='binary')
        train_f1 = f1_score(y_train, y_train_pred, average='binary')
        train_auc = roc_auc_score(y_train, y_train_prob)
        
        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®è©•ä¾¡
        val_acc = accuracy_score(y_val, y_val_pred)
        val_prec = precision_score(y_val, y_val_pred, average='binary', zero_division=0)
        val_rec = recall_score(y_val, y_val_pred, average='binary')
        val_f1 = f1_score(y_val, y_val_pred, average='binary')
        val_auc = roc_auc_score(y_val, y_val_prob)
        
        print(f"\n  ğŸ“š è¨“ç·´ãƒ‡ãƒ¼ã‚¿:")
        print(f"     Acc: {train_acc:.4f}, Prec: {train_prec:.4f}, Recall: {train_rec:.4f}, F1: {train_f1:.4f}, AUC: {train_auc:.4f}")
        
        print(f"  ğŸ“Š æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿:")
        print(f"     Acc: {val_acc:.4f}, Prec: {val_prec:.4f}, Recall: {val_rec:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}")
        
        # å·®åˆ†(éå­¦ç¿’ã®æŒ‡æ¨™)
        diff_acc = train_acc - val_acc
        diff_prec = train_prec - val_prec
        diff_rec = train_rec - val_rec
        diff_f1 = train_f1 - val_f1
        diff_auc = train_auc - val_auc
        
        print(f"  ğŸ“‰ å·®åˆ†(è¨“ç·´ - æ¤œè¨¼):")
        print(f"     Acc: {diff_acc:+.4f}, Prec: {diff_prec:+.4f}, Recall: {diff_rec:+.4f}, F1: {diff_f1:+.4f}, AUC: {diff_auc:+.4f}")
        
        fold_metrics.append({
            'Fold': i+1,
            'Train_Accuracy': train_acc,
            'Val_Accuracy': val_acc,
            'Diff_Accuracy': diff_acc,
            'Train_Precision': train_prec,
            'Val_Precision': val_prec,
            'Diff_Precision': diff_prec,
            'Train_Recall': train_rec,
            'Val_Recall': val_rec,
            'Diff_Recall': diff_rec,
            'Train_F1': train_f1,
            'Val_F1': val_f1,
            'Diff_F1': diff_f1,
            'Train_AUC': train_auc,
            'Val_AUC': val_auc,
            'Diff_AUC': diff_auc
        })
        print()
    
    # çµæœã®é›†è¨ˆ
    metrics_df = pd.DataFrame(fold_metrics)
    
    print("=" * 80)
    print("ğŸ“Š éå­¦ç¿’åˆ†æçµæœ")
    print("=" * 80)
    
    print("\nã€å¹³å‡æ€§èƒ½ã€‘")
    avg_train_auc = metrics_df['Train_AUC'].mean()
    avg_val_auc = metrics_df['Val_AUC'].mean()
    avg_diff_auc = metrics_df['Diff_AUC'].mean()
    
    avg_train_f1 = metrics_df['Train_F1'].mean()
    avg_val_f1 = metrics_df['Val_F1'].mean()
    avg_diff_f1 = metrics_df['Diff_F1'].mean()
    
    print(f"\nè¨“ç·´ãƒ‡ãƒ¼ã‚¿:")
    print(f"  AUC:       {avg_train_auc:.4f}")
    print(f"  F1 Score:  {avg_train_f1:.4f}")
    print(f"  Recall:    {metrics_df['Train_Recall'].mean():.4f}")
    print(f"  Precision: {metrics_df['Train_Precision'].mean():.4f}")
    
    print(f"\næ¤œè¨¼ãƒ‡ãƒ¼ã‚¿:")
    print(f"  AUC:       {avg_val_auc:.4f}")
    print(f"  F1 Score:  {avg_val_f1:.4f}")
    print(f"  Recall:    {metrics_df['Val_Recall'].mean():.4f}")
    print(f"  Precision: {metrics_df['Val_Precision'].mean():.4f}")
    
    print(f"\nå·®åˆ†(è¨“ç·´ - æ¤œè¨¼):")
    print(f"  AUC:       {avg_diff_auc:+.4f} ({abs(avg_diff_auc)/avg_train_auc*100:.2f}%)")
    print(f"  F1 Score:  {avg_diff_f1:+.4f} ({abs(avg_diff_f1)/avg_train_f1*100:.2f}%)")
    
    # éå­¦ç¿’ã®åˆ¤å®š
    print("\n" + "=" * 80)
    print("ğŸ” éå­¦ç¿’ã®åˆ¤å®š")
    print("=" * 80)
    
    # åˆ¤å®šåŸºæº–
    auc_threshold = 0.05  # AUCã®å·®ãŒ5%ä»¥å†…ãªã‚‰å¥å…¨
    f1_threshold = 0.10   # F1ã®å·®ãŒ10%ä»¥å†…ãªã‚‰å¥å…¨
    
    is_overfitting_auc = abs(avg_diff_auc) > auc_threshold
    is_overfitting_f1 = abs(avg_diff_f1) > f1_threshold
    
    print(f"\nAUCãƒ™ãƒ¼ã‚¹:")
    if is_overfitting_auc:
        print(f"  âš ï¸  éå­¦ç¿’ã®å¯èƒ½æ€§ã‚ã‚Š (å·®åˆ†: {abs(avg_diff_auc):.4f} > é–¾å€¤: {auc_threshold})")
    else:
        print(f"  âœ… å¥å…¨ (å·®åˆ†: {abs(avg_diff_auc):.4f} <= é–¾å€¤: {auc_threshold})")
    
    print(f"\nF1ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹:")
    if is_overfitting_f1:
        print(f"  âš ï¸  éå­¦ç¿’ã®å¯èƒ½æ€§ã‚ã‚Š (å·®åˆ†: {abs(avg_diff_f1):.4f} > é–¾å€¤: {f1_threshold})")
    else:
        print(f"  âœ… å¥å…¨ (å·®åˆ†: {abs(avg_diff_f1):.4f} <= é–¾å€¤: {f1_threshold})")
    
    # ç·åˆåˆ¤å®š
    print(f"\nç·åˆåˆ¤å®š:")
    if is_overfitting_auc or is_overfitting_f1:
        print("  âš ï¸  éå­¦ç¿’ã®å…†å€™ãŒè¦‹ã‚‰ã‚Œã¾ã™")
    else:
        print("  âœ… éå­¦ç¿’ã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“(å¥å…¨ãªãƒ¢ãƒ‡ãƒ«)")
    
    # å¯è¦–åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # AUCã®æ¯”è¼ƒ
    ax1 = axes[0, 0]
    folds = metrics_df['Fold']
    ax1.plot(folds, metrics_df['Train_AUC'], marker='o', label='è¨“ç·´ãƒ‡ãƒ¼ã‚¿', linewidth=2)
    ax1.plot(folds, metrics_df['Val_AUC'], marker='s', label='æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿', linewidth=2)
    ax1.set_xlabel('Fold')
    ax1.set_ylabel('AUC')
    ax1.set_title('AUCã®æ¨ç§»(è¨“ç·´ vs æ¤œè¨¼)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim([0.8, 1.0])
    
    # F1ã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒ
    ax2 = axes[0, 1]
    ax2.plot(folds, metrics_df['Train_F1'], marker='o', label='è¨“ç·´ãƒ‡ãƒ¼ã‚¿', linewidth=2)
    ax2.plot(folds, metrics_df['Val_F1'], marker='s', label='æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿', linewidth=2)
    ax2.set_xlabel('Fold')
    ax2.set_ylabel('F1 Score')
    ax2.set_title('F1ã‚¹ã‚³ã‚¢ã®æ¨ç§»(è¨“ç·´ vs æ¤œè¨¼)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Recallã®æ¯”è¼ƒ
    ax3 = axes[1, 0]
    ax3.plot(folds, metrics_df['Train_Recall'], marker='o', label='è¨“ç·´ãƒ‡ãƒ¼ã‚¿', linewidth=2)
    ax3.plot(folds, metrics_df['Val_Recall'], marker='s', label='æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿', linewidth=2)
    ax3.set_xlabel('Fold')
    ax3.set_ylabel('Recall')
    ax3.set_title('Recallã®æ¨ç§»(è¨“ç·´ vs æ¤œè¨¼)')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # å·®åˆ†ã®å¯è¦–åŒ–
    ax4 = axes[1, 1]
    width = 0.25
    x = np.arange(len(folds))
    ax4.bar(x - width, metrics_df['Diff_AUC'], width, label='AUCå·®åˆ†')
    ax4.bar(x, metrics_df['Diff_F1'], width, label='F1å·®åˆ†')
    ax4.bar(x + width, metrics_df['Diff_Recall'], width, label='Recallå·®åˆ†')
    ax4.set_xlabel('Fold')
    ax4.set_ylabel('å·®åˆ†(è¨“ç·´ - æ¤œè¨¼)')
    ax4.set_title('å„æŒ‡æ¨™ã®å·®åˆ†')
    ax4.set_xticks(x)
    ax4.set_xticklabels(folds)
    ax4.legend()
    ax4.axhline(y=0, color='black', linestyle='--', linewidth=0.8)
    ax4.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    
    output_path = 'results/model_comparison/logistic_regression_1pct/overfitting_analysis.png'
    plt.savefig(output_path, dpi=150)
    print(f"\nâœ“ éå­¦ç¿’åˆ†æã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: {output_path}")
    plt.close()
    
    # CSVã«ä¿å­˜
    csv_path = 'results/model_comparison/logistic_regression_1pct/overfitting_metrics.csv'
    metrics_df.to_csv(csv_path, index=False)
    print(f"âœ“ è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜: {csv_path}")
    
    print("\nâœ… éå­¦ç¿’åˆ†æå®Œäº†")

if __name__ == "__main__":
    main()

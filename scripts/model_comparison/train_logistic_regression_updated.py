"""
ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã«ã‚ˆã‚‹æ­»äº¡äº‹æ•…äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆæ›´æ–°ç‰ˆï¼‰

LightGBMã¨å…¬å¹³ã«æ¯”è¼ƒã™ã‚‹ãŸã‚ã€ä»¥ä¸‹ã‚’çµ±ä¸€:
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: data/processed/honhyo_clean_predictable_only.csv
- è©•ä¾¡æ–¹æ³•: 5-fold StratifiedKFoldäº¤å·®æ¤œè¨¼
- è©•ä¾¡æŒ‡æ¨™: PR-AUC, ROC-AUC, F1, Accuracy, Precision, Recall
- ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–: class_weight='balanced'

æ›´æ–°å†…å®¹ï¼ˆ2025-12-11ï¼‰:
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’LightGBMã¨çµ±ä¸€
- PR-AUCã‚’ä¸»è¦è©•ä¾¡æŒ‡æ¨™ã¨ã—ã¦è¿½åŠ 
- ç™ºç”Ÿæ—¥æ™‚ã‚«ãƒ©ãƒ ã®é™¤å¤–å‡¦ç†ã‚’è¿½åŠ 
- å‡ºåŠ›å…ˆã‚’ updated ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å¤‰æ›´
"""

import pandas as pd
import numpy as np
import os
import warnings
from datetime import datetime
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    precision_recall_curve,
    roc_auc_score,
    average_precision_score  # PR-AUC
)
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib as mpl
from tqdm import tqdm

warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['Yu Gothic', 'MS Gothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class LogisticRegressionModel:
    """ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨è©•ä¾¡"""
    
    def __init__(
        self, 
        data_path='data/processed/honhyo_clean_predictable_only.csv',
        target_column='æ­»è€…æ•°',
        n_folds=5,
        random_state=42
    ):
        """
        Parameters:
        -----------
        data_path : str
            ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹
        target_column : str
            ç›®çš„å¤‰æ•°ã®ã‚«ãƒ©ãƒ å
        n_folds : int
            äº¤å·®æ¤œè¨¼ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰æ•°
        random_state : int
            ä¹±æ•°ã‚·ãƒ¼ãƒ‰
        """
        self.data_path = data_path
        self.target_column = target_column
        self.n_folds = n_folds
        self.random_state = random_state
        
        print("="*80)
        print("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆLightGBMæ¯”è¼ƒç”¨ï¼‰")
        print("="*80)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print(f"\n[ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿] {data_path}")
        self.df = pd.read_csv(data_path)
        print(f"âœ… èª­ã¿è¾¼ã¿å®Œäº†: {len(self.df):,} ä»¶")
        
        # å‰å‡¦ç†
        self._preprocess_data()
        
    def _preprocess_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†"""
        print("\n[å‰å‡¦ç†] ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­...")
        
        # ç›®çš„å¤‰æ•°ã‚’åˆ†é›¢
        self.y = self.df[self.target_column]
        self.X = self.df.drop(columns=[self.target_column])
        
        # ç™ºç”Ÿæ—¥æ™‚ã‚’é™¤å¤–ï¼ˆLightGBMã¨åŒã˜ï¼‰
        if 'ç™ºç”Ÿæ—¥æ™‚' in self.X.columns:
            self.X = self.X.drop(columns=['ç™ºç”Ÿæ—¥æ™‚'])
            print("  - ç™ºç”Ÿæ—¥æ™‚ã‚«ãƒ©ãƒ ã‚’é™¤å¤–")
        
        # æ•°å€¤å‹ã¨ã‚«ãƒ†ã‚´ãƒªå‹ã®åˆ†é¡
        self.numeric_cols = self.X.select_dtypes(include=['int64', 'float64']).columns.tolist()
        self.categorical_cols = self.X.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¨ã—ã¦æ‰±ã†ã¹ãæ•°å€¤ã‚«ãƒ©ãƒ 
        explicit_cat_cols = [
            'éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰', 'è·¯ç·šã‚³ãƒ¼ãƒ‰', 'åœ°ç‚¹ã‚³ãƒ¼ãƒ‰', 'å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰',
            'æ˜¼å¤œ', 'å¤©å€™', 'åœ°å½¢', 'è·¯é¢çŠ¶æ…‹', 'é“è·¯å½¢çŠ¶', 'ä¿¡å·æ©Ÿ',
            'è¡çªåœ°ç‚¹', 'ã‚¾ãƒ¼ãƒ³è¦åˆ¶', 'ä¸­å¤®åˆ†é›¢å¸¯æ–½è¨­ç­‰', 'æ­©è»Šé“åŒºåˆ†',
            'äº‹æ•…é¡å‹', 'æ›œæ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)', 'ç¥æ—¥(ç™ºç”Ÿå¹´æœˆæ—¥)'
        ]
        
        # å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ã‚’å¯¾è±¡
        explicit_cat_cols = [c for c in explicit_cat_cols if c in self.X.columns]
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ãƒªã‚¹ãƒˆã‚’æ›´æ–°
        self.categorical_cols = list(set(self.categorical_cols + explicit_cat_cols))
        self.numeric_cols = [c for c in self.numeric_cols if c not in self.categorical_cols]
        
        print(f"  - æ•°å€¤å‹ç‰¹å¾´é‡: {len(self.numeric_cols)} å€‹")
        print(f"  - ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡: {len(self.categorical_cols)} å€‹")
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚’æ–‡å­—åˆ—ã«çµ±ä¸€
        for col in self.categorical_cols:
            if col in self.X.columns:
                self.X[col] = self.X[col].astype(str)
        
        # ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”ã‚’è¨ˆç®—
        pos_count = self.y.sum()
        neg_count = len(self.y) - pos_count
        self.class_imbalance_ratio = neg_count / pos_count
        
        print(f"\n[ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡]")
        print(f"  - Negative (0): {neg_count:,}")
        print(f"  - Positive (1): {pos_count:,}")
        print(f"  - ä¸å‡è¡¡æ¯”: {self.class_imbalance_ratio:.2f}:1")
        
    def build_pipeline(self):
        """å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰"""
        # æ•°å€¤å‹ã®å‰å‡¦ç†
        numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
        ])
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹ã®å‰å‡¦ç†
        # LightGBMã¨å…¬å¹³ã«ã™ã‚‹ãŸã‚ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå‡¦ç†ã®ã¿
        from sklearn.preprocessing import OrdinalEncoder
        categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))
        ])
        
        # å‰å‡¦ç†ã®çµ±åˆ
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, self.numeric_cols),
                ('cat', categorical_transformer, self.categorical_cols)
            ],
            remainder='drop'
        )
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', LogisticRegression(
                penalty='l2',
                C=1.0,
                solver='saga',
                max_iter=1000,
                class_weight='balanced',  # ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–
                random_state=self.random_state,
                n_jobs=-1,
                verbose=0
            ))
        ])
        
        return pipeline
    
    def cross_validate(self):
        """5-foldäº¤å·®æ¤œè¨¼ã§è©•ä¾¡"""
        print(f"\n[é–‹å§‹] {self.n_folds}-fold äº¤å·®æ¤œè¨¼")
        print("="*80)
        
        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)
        
        # çµæœã‚’æ ¼ç´
        fold_metrics = []
        y_true_all = []
        y_prob_all = []
        
        # å„foldã®å‡¦ç†
        for fold, (train_idx, val_idx) in enumerate(tqdm(skf.split(self.X, self.y), total=self.n_folds, desc="Cross-Validation")):
            print(f"\n--- Fold {fold+1}/{self.n_folds} ---")
            
            X_train, X_val = self.X.iloc[train_idx], self.X.iloc[val_idx]
            y_train, y_val = self.y.iloc[train_idx], self.y.iloc[val_idx]
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
            pipeline = self.build_pipeline()
            
            # è¨“ç·´
            print("  è¨“ç·´ä¸­...")
            pipeline.fit(X_train, y_train)
            
            # äºˆæ¸¬ï¼ˆç¢ºç‡ï¼‰
            y_prob = pipeline.predict_proba(X_val)[:, 1]
            y_pred = (y_prob >= 0.5).astype(int)
            
            # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
            pr_auc = average_precision_score(y_val, y_prob)
            roc_auc = roc_auc_score(y_val, y_prob)
            accuracy = accuracy_score(y_val, y_pred)
            precision = precision_score(y_val, y_pred, zero_division=0)
            recall = recall_score(y_val, y_pred)
            f1 = f1_score(y_val, y_pred)
            
            print(f"  PR-AUC: {pr_auc:.4f} | ROC-AUC: {roc_auc:.4f} | F1: {f1:.4f}")
            
            # çµæœã‚’ä¿å­˜
            fold_metrics.append({
                'Fold': fold + 1,
                'PR-AUC': pr_auc,
                'ROC-AUC': roc_auc,
                'Accuracy': accuracy,
                'Precision': precision,
                'Recall': recall,
                'F1 Score': f1
            })
            
            # å…¨ãƒ‡ãƒ¼ã‚¿ã«è“„ç©
            y_true_all.extend(y_val)
            y_prob_all.extend(y_prob)
        
        # çµæœã‚’DataFrameã«å¤‰æ›
        self.fold_metrics = pd.DataFrame(fold_metrics)
        self.y_true_all = np.array(y_true_all)
        self.y_prob_all = np.array(y_prob_all)
        
        # å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        self.avg_metrics = self.fold_metrics.mean()
        
        print("\n" + "="*80)
        print("[çµæœ] 5-fold CV å¹³å‡ã‚¹ã‚³ã‚¢")
        print("="*80)
        print(f"  PR-AUC:    {self.avg_metrics['PR-AUC']:.4f}")
        print(f"  ROC-AUC:   {self.avg_metrics['ROC-AUC']:.4f}")
        print(f"  Accuracy:  {self.avg_metrics['Accuracy']:.4f}")
        print(f"  Precision: {self.avg_metrics['Precision']:.4f}")
        print(f"  Recall:    {self.avg_metrics['Recall']:.4f}")
        print(f"  F1 Score:  {self.avg_metrics['F1 Score']:.4f}")
        
        return self.fold_metrics
    
    def save_results(self, output_dir='results/model_comparison/logistic_regression_updated'):
        """çµæœã‚’ä¿å­˜"""
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        print(f"\n[ä¿å­˜] çµæœã‚’ä¿å­˜ä¸­: {output_dir}")
        
        # 1. Foldåˆ¥ã®è©•ä¾¡æŒ‡æ¨™ã‚’CSVä¿å­˜
        metrics_path = f'{output_dir}/metrics_{timestamp}.csv'
        self.fold_metrics.to_csv(metrics_path, index=False, encoding='utf-8-sig')
        print(f"  âœ… Foldåˆ¥è©•ä¾¡æŒ‡æ¨™: {metrics_path}")
        
        # 2. PRæ›²ç·š
        precisions, recalls, thresholds = precision_recall_curve(self.y_true_all, self.y_prob_all)
        
        plt.figure(figsize=(10, 6))
        plt.plot(recalls, precisions, marker='.', label=f'Logistic Regression (PR-AUC={self.avg_metrics["PR-AUC"]:.4f})')
        plt.xlabel('Recall (å†ç¾ç‡)', fontsize=12)
        plt.ylabel('Precision (é©åˆç‡)', fontsize=12)
        plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')
        plt.legend(fontsize=11)
        plt.grid(True, alpha=0.3)
        
        pr_path = f'{output_dir}/pr_curve_{timestamp}.png'
        plt.savefig(pr_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"  âœ… PRæ›²ç·š: {pr_path}")
        
        # 3. ROCæ›²ç·š
        from sklearn.metrics import roc_curve
        fpr, tpr, _ = roc_curve(self.y_true_all, self.y_prob_all)
        
        plt.figure(figsize=(10, 6))
        plt.plot(fpr, tpr, marker='.', label=f'Logistic Regression (ROC-AUC={self.avg_metrics["ROC-AUC"]:.4f})')
        plt.plot([0, 1], [0, 1], 'k--', label='Random')
        plt.xlabel('False Positive Rate', fontsize=12)
        plt.ylabel('True Positive Rate', fontsize=12)
        plt.title('ROC Curve', fontsize=14, fontweight='bold')
        plt.legend(fontsize=11)
        plt.grid(True, alpha=0.3)
        
        roc_path = f'{output_dir}/roc_curve_{timestamp}.png'
        plt.savefig(roc_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"  âœ… ROCæ›²ç·š: {roc_path}")
        
        # 4. æ··åŒè¡Œåˆ—
        y_pred = (self.y_prob_all >= 0.5).astype(int)
        cm = confusion_matrix(self.y_true_all, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['éæ­»äº¡', 'æ­»äº¡'], yticklabels=['éæ­»äº¡', 'æ­»äº¡'])
        plt.title('Confusion Matrix (Threshold=0.5)', fontsize=14, fontweight='bold')
        plt.ylabel('Actual', fontsize=12)
        plt.xlabel('Predicted', fontsize=12)
        
        cm_path = f'{output_dir}/confusion_matrix_{timestamp}.png'
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"  âœ… æ··åŒè¡Œåˆ—: {cm_path}")
        
        # 5. ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
        self._generate_summary_report(output_dir, timestamp)
        
        print(f"\nâœ… ã™ã¹ã¦ã®çµæœã‚’ä¿å­˜å®Œäº†: {output_dir}")
        
    def _generate_summary_report(self, output_dir, timestamp):
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report_lines = [
            "# ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸° å®Ÿé¨“çµæœï¼ˆæ›´æ–°ç‰ˆï¼‰",
            "",
            f"**å®Ÿé¨“æ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}",
            "**ç›®çš„**: LightGBMã¨ã®å…¬å¹³ãªæ¯”è¼ƒ",
            "",
            "---",
            "",
            "## ğŸ“Š å®Ÿé¨“è¨­å®š",
            "",
            "### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
            f"- ãƒ•ã‚¡ã‚¤ãƒ«: `{self.data_path}`",
            f"- ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(self.df):,} ä»¶",
            f"- Positive (æ­»äº¡äº‹æ•…): {self.y.sum():,} ä»¶",
            f"- Negative (éæ­»äº¡): {(self.y == 0).sum():,} ä»¶",
            f"- ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”: {self.class_imbalance_ratio:.2f}:1",
            "",
            "### ç‰¹å¾´é‡",
            f"- æ•°å€¤å‹: {len(self.numeric_cols)} å€‹",
            f"- ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹: {len(self.categorical_cols)} å€‹",
            f"- ç·ç‰¹å¾´é‡æ•°: {len(self.X.columns)}",
            "",
            "### ãƒ¢ãƒ‡ãƒ«è¨­å®š",
            "```python",
            "LogisticRegression(",
            "    penalty='l2',",
            "    C=1.0,",
            "    solver='saga',",
            "    max_iter=1000,",
            "    class_weight='balanced',  # ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–",
            "    random_state=42",
            ")",
            "```",
            "",
            "---",
            "",
            "## ğŸ“ˆ è©•ä¾¡çµæœ",
            "",
            "### 5-fold CV å¹³å‡ã‚¹ã‚³ã‚¢",
            "",
            "| æŒ‡æ¨™ | ã‚¹ã‚³ã‚¢ | æ¨™æº–åå·® |",
            "|------|--------|----------|",
            f"| **PR-AUC** | **{self.avg_metrics['PR-AUC']:.4f}** | {self.fold_metrics['PR-AUC'].std():.4f} |",
            f"| **ROC-AUC** | {self.avg_metrics['ROC-AUC']:.4f} | {self.fold_metrics['ROC-AUC'].std():.4f} |",
            f"| **F1 Score** | {self.avg_metrics['F1 Score']:.4f} | {self.fold_metrics['F1 Score'].std():.4f} |",
            f"| **Accuracy** | {self.avg_metrics['Accuracy']:.4f} | {self.fold_metrics['Accuracy'].std():.4f} |",
            f"| **Precision** | {self.avg_metrics['Precision']:.4f} | {self.fold_metrics['Precision'].std():.4f} |",
            f"| **Recall** | {self.avg_metrics['Recall']:.4f} | {self.fold_metrics['Recall'].std():.4f} |",
            "",
            "### Foldåˆ¥è©³ç´°",
            "",
            self.fold_metrics.to_markdown(index=False),
            "",
            "---",
            "",
            "## ğŸ’¡ ç‰¹å¾´",
            "",
            "### LightGBMã¨ã®é•ã„",
            "- **å‰å‡¦ç†**: æ•°å€¤å‹ã¯æ¨™æº–åŒ–ã€ã‚«ãƒ†ã‚´ãƒªå‹ã¯é †åºã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°",
            "- **ãƒ¢ãƒ‡ãƒ«**: ç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼ˆç‰¹å¾´é‡é–“ã®è¤‡é›‘ãªç›¸äº’ä½œç”¨ã‚’æ‰ãˆã«ãã„ï¼‰",
            "- **ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–**: `class_weight='balanced'`",
            "",
            "### é•·æ‰€",
            "- è§£é‡ˆæ€§ãŒé«˜ã„ï¼ˆä¿‚æ•°ã‹ã‚‰å„ç‰¹å¾´é‡ã®å½±éŸ¿ã‚’èª­ã¿å–ã‚Œã‚‹ï¼‰",
            "- è¨“ç·´ãŒé«˜é€Ÿ",
            "- éå­¦ç¿’ã—ã«ãã„",
            "",
            "### çŸ­æ‰€",
            "- éç·šå½¢ãªé–¢ä¿‚ã‚’æ‰ãˆã«ãã„",
            "- ç‰¹å¾´é‡é–“ã®ç›¸äº’ä½œç”¨ã‚’è‡ªå‹•ã§å­¦ç¿’ã§ããªã„",
            "",
            "---",
            "",
            f"**ãƒ¬ãƒãƒ¼ãƒˆä½œæˆæ—¥**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}  ",
            f"**ä½œæˆè€…**: Antigravity AI Agent",
        ]
        
        report_path = f'{output_dir}/summary_report_{timestamp}.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        print(f"  âœ… ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    model = LogisticRegressionModel(
        data_path='data/processed/honhyo_clean_predictable_only.csv',
        target_column='æ­»è€…æ•°',
        n_folds=5,
        random_state=42
    )
    
    # äº¤å·®æ¤œè¨¼ã§è©•ä¾¡
    fold_metrics = model.cross_validate()
    
    # çµæœã‚’ä¿å­˜
    model.save_results()
    
    print("\n" + "="*80)
    print("âœ… ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®è¨“ç·´ãƒ»è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("="*80)
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: compare_models.py ã‚’å®Ÿè¡Œã—ã¦LightGBMã¨æ¯”è¼ƒã—ã¦ãã ã•ã„")


if __name__ == '__main__':
    main()

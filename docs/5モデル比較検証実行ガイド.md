# 3モデル比較検証実行ガイド

## 概要
`honhyo_clean_road_type.csv`を使用して3つの機械学習モデルを統合比較します。

## 比較対象モデル

1. **ロジスティック回帰** - 線形モデル（ベースライン）
2. **Random Forest** - バギング手法
3. **LightGBM** - ブースティング（Leaf-wise成長）

## 実行方法

### 方法1: バッチファイルを使用（推奨）
```cmd
run_model_comparison.bat
```

### 方法2: 直接Pythonコマンドを使用
```cmd
python scripts/model_comparison/compare_three_models.py
```

## 評価指標

各モデルで以下の指標を評価します:
- **PR-AUC** (Precision-Recall AUC)
- **ROC-AUC** (ROC曲線下面積)
- **F1スコア**
- **Accuracy** (正解率)
- **Precision** (適合率)
- **Recall** (再現率)
- **訓練時間・予測時間**

## 統計的検定

Friedman検定を用いて、モデル間に統計的有意差があるかを検証します。

## 推定実行時間

| モデル | Fold 1回あたり | 合計（5 folds） |
|--------|---------------|----------------|
| ロジスティック回帰 | 10-15分 | 50-75分 |
| Random Forest | 15-20分 | 75-100分 |
| LightGBM | 3-5分 | 15-25分 |
| **合計** | **28-40分** | **140-200分** |

**総推定時間**: **約2-3時間**

## 出力結果

結果は `results/model_comparison/` に保存されます:
- `logreg_cv_3models_YYYYMMDD_HHMMSS.csv` - ロジスティック回帰の結果
- `rf_cv_YYYYMMDD_HHMMSS.csv` - Random Forestの結果
- `lightgbm_cv_3models_YYYYMMDD_HHMMSS.csv` - LightGBMの結果
- `statistical_test_3models_YYYYMMDD_HHMMSS.csv` - 統計検定結果
- `comparison_report_3models_YYYYMMDD_HHMMSS.md` - 比較レポート

## 事前準備

### 必要なライブラリ

このスクリプトは以下のライブラリのみを使用します（CatBoost/XGBoost不要）:
- pandas
- numpy
- scikit-learn
- lightgbm
- scipy

これらは既にインストールされているはずです。

## 注意事項

- ⚠️ 実行時間が長いため、PCをスリープさせない設定を推奨
- 進捗はリアルタイムでコンソールに表示されます
- 各Foldごとに3モデルの結果が表示されます
- 途中で中断すると最初から再実行が必要です

## Tips

### 実行時間を短縮したい場合

Fold数を減らすことで実行時間を短縮できます（精度は低下します）:

スクリプトの474行目を変更:
```python
comparator = ThreeModelComparator(
    data_path='data/processed/honhyo_clean_road_type.csv',
    n_folds=3  # 5 → 3
)
```

→ 実行時間が約60%に短縮

## 実行結果の見方

実行完了後、各指標について:
1. 各モデルの平均値と標準偏差が表示されます
2. 最良のモデルに★マークが付きます
3. Friedman検定の結果が表示されます（p値 < 0.05で有意差あり）

## 期待される結果

一般的には以下の順序で性能が高いと予想されます:

1. **LightGBM** - 最良の性能
2. **Random Forest** - 中間
3. **ロジスティック回帰** - ベースライン

実際の結果はデータによって異なります。

---

**注意**: XGBoostとCatBoostはインストールの問題により5モデル版が実行できない場合は、この3モデル版を使用してください。

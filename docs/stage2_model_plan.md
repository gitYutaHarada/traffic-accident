# Stage 2 モデル比較・アンサンブル計画

**前提**: Stage 1 (Recall 98%) でフィルタリングされたデータを使用。

## 1. 比較対象モデル (Phase 1)

以下の4モデルを学習し、単体性能およびアンサンブル性能を評価する。

| モデル | 特徴 | 期待される役割 |
| :--- | :--- | :--- |
| **LightGBM** | 決定木勾配ブースティング | ベースライン。高速で高精度。 |
| **CatBoost** | カテゴリ変数に強いGBDT | 道路種別や規制情報の活用。 |
| **TabNet** | Attention機構付きNN | 特徴量選択と非線形性の獲得。 |
| **MLP** | シンプルな全結合NN | GBDTとは異なる決定境界を作る（多様性確保）。 |

## 2. 追加検討モデル (Phase 2)

Phase 1 の結果次第で、以下を検討する。特に **kNN-GNN** はMLPの代替として有望。

| モデル | 特徴 | メリット | デメリット |
| :--- | :--- | :--- | :--- |
| **kNN-GNN** | 近傍グラフNN | 空間的な近さを考慮できる | 実装コスト中 |
| **Temporal GNN** | 時空間GNN | 最も情報量が多い | 計算コスト大、実装難 |
| **LSTM** | 時系列RNN | 周期性の学習 | データの疎密に弱い |

## 3. 実験手順
1.  Pythonスクリプト `train_stage2_4models.py` を作成。
2.  Stage 1 フィルタリング済みデータを入力として各モデルを学習（5-Fold CV）。
3.  OOF予測値を保存し、重み付き平均等のアンサンブルを試行。
4.  テストセットでの最終評価。

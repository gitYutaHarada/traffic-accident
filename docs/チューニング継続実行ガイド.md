# LightGBMハイパーパラメータチューニング継続実行ガイド

## 概要

Optunaでハイパーパラメータチューニングを途中から再開する方法を説明します。

---

## 方法1: SQLiteストレージを使用（推奨）

### 特徴

- ✅ 最も確実な方法
- ✅ 途中で中断しても再開可能
- ✅ 過去の試行データを完全に保持
- ✅ 同じstudyに追加試行を重ねられる

### 使用方法

1. **継続実行用スクリプト**を使用

```powershell
# 継続実行版スクリプトを実行
python scripts\analysis\lightgbm_optuna_tuning_resume.py
```

2. **初回実行時**
   - SQLiteデータベース(`results/tuning/lightgbm_tuning.db`)が作成されます
   - 0試行から開始します

3. **2回目以降の実行**
   - 既存のデータベースから過去の試行を読み込みます
   - 残りの試行のみを実行します
   - 例: 既に116試行完了 → 残り84試行を実行

### 仕組み

```python
# SQLiteストレージを指定
storage_name = "sqlite:///results/tuning/lightgbm_tuning.db"
study_name = "lightgbm_pr_auc_optimization"

# studyを作成（既存があれば読み込む）
study = optuna.create_study(
    study_name=study_name,
    storage=storage_name,
    direction="maximize",
    load_if_exists=True  # ← 重要！
)

# 既に完了した試行数を確認
n_completed = len([t for t in study.trials 
                   if t.state == optuna.trial.TrialState.COMPLETE])

# 残りの試行のみを実行
n_remaining = N_TRIALS - n_completed
if n_remaining > 0:
    study.optimize(..., n_trials=n_remaining)
```

---

## 方法2: 既存の116試行を新スクリプトで再開

### 手順

#### Step 1: 既存結果をSQLiteにインポート（手動）

残念ながら、既存の116試行の結果をSQLiteに自動的にインポートするのは複雑です。最も簡単な方法は：

**オプションA: 新規に200試行実行**（推奨）
```powershell
# 継続実行版スクリプトで新規実行
python scripts\analysis\lightgbm_optuna_tuning_resume.py
```
- メリット: シンプル、確実
- デメリット: 116試行のデータは別管理

**オプションB: 既存の116試行から学習**
既存の`study_history.csv`から上位のハイパーパラメータを参考に、探索範囲を狭めて追加実行。

---

## 方法3: 既存スクリプトに試行回数を追加

### 単純に試行回数を増やして再実行（非推奨）

```powershell
# オリジナルスクリプトで試行回数を300に増やす
# ただし、既存の116試行は無視されて0から開始
python scripts\analysis\lightgbm_optuna_tuning.py
```

⚠️ **問題点**: 既存の116試行は使用されず、最初からやり直しになる

---

## 推奨ワークフロー

### 今後のチューニングで継続実行を活用

1. **今回（116試行完了済み）**
   - 既存の結果は保存済み（`tuning_20251209_011713/`）
   - 新規に継続実行版スクリプトで200試行実行することを推奨

2. **次回以降**
   - 継続実行版スクリプト（`lightgbm_optuna_tuning_resume.py`）を使用
   - 途中で中断しても、次回実行時に自動的に再開
   - 例: 50試行で中断 → 次回実行で残り150試行を自動実行

### 実行例

```powershell
# 1回目: 200試行を目標に実行（途中で中断可能）
python scripts\analysis\lightgbm_optuna_tuning_resume.py

# 出力例:
# [INFO] 既存の試行数: 0
# [INFO] 残りの試行数: 200
# [START] 残り200試行を実行します...
# (中断)

# 2回目: 続きから再開
python scripts\analysis\lightgbm_optuna_tuning_resume.py

# 出力例:
# [INFO] 既存の試行数: 80
# [INFO] 残りの試行数: 120
# [INFO] 現在の最良PR-AUC: 0.1850
# [START] 残り120試行を実行します...
```

---

## SQLiteデータベースの管理

### データベースの場所

```
results/tuning/lightgbm_tuning.db
```

### データベースの確認

```powershell
# 試行数を確認
python -c "import optuna; study = optuna.load_study(study_name='lightgbm_pr_auc_optimization', storage='sqlite:///results/tuning/lightgbm_tuning.db'); print(f'試行数: {len(study.trials)}, 最良PR-AUC: {study.best_value:.4f}')"
```

### データベースのリセット

```powershell
# データベースファイルを削除
rm results\tuning\lightgbm_tuning.db

# または、新しいstudy名を使用
# STUDY_NAME = "lightgbm_pr_auc_optimization_v2"
```

---

## トラブルシューティング

### Q: SQLiteデータベースが壊れた場合は？

**A:** データベースファイルを削除して、最初から実行

```powershell
rm results\tuning\lightgbm_tuning.db
python scripts\analysis\lightgbm_optuna_tuning_resume.py
```

### Q: 既存の116試行を無駄にしたくない

**A:** 以下のアプローチがあります：

1. **既存結果を参考に探索範囲を調整**
   - `best_params.json`を確認し、有望なパラメータ範囲に絞る
   - 新規に100試行を実行（合計216試行相当）

2. **既存結果を保持したまま追加実行**
   - 既存の116試行の結果は`tuning_20251209_011713/`に保存済み
   - 新規に継続実行版で200試行実行
   - 2つの結果を比較して最良を選択

---

## まとめ

| 方法 | メリット | デメリット | 推奨度 |
|------|---------|-----------|--------|
| **継続実行版スクリプト** | 途中再開可能、確実 | 既存116試行は別管理 | ⭐⭐⭐⭐⭐ |
| 既存試行のインポート | 116試行を活用 | 実装が複雑 | ⭐⭐ |
| 試行回数を増やして再実行 | シンプル | 既存試行が無駄 | ⭐ |

**推奨**: 今後は継続実行版スクリプト（`lightgbm_optuna_tuning_resume.py`）を使用し、途中で中断しても安心してチューニングを継続できる環境を構築。

---

## 次のステップ

1. **継続実行版スクリプトを実行**
   ```powershell
   python scripts\analysis\lightgbm_optuna_tuning_resume.py
   ```

2. **結果の比較**
   - 既存の116試行の結果（`tuning_20251209_011713/`）
   - 新規の200試行の結果
   - 両方を比較して最良のパラメータを選択

3. **本番モデルの構築**
   - 最良パラメータで全データを使用してモデルを学習
   - 本番環境へのデプロイ

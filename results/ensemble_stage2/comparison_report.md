# 実験比較レポート: 単体モデル vs アンサンブルモデル

## 概要
本レポートでは、以前の実験（単体LightGBMモデル）と今回構築した「並列化アンサンブルモデル（LightGBM + CatBoost + TabNet）」の性能および実装面での比較を行います。

## 1. 性能比較 (Test Set)

| 指標 | ① Trafficのみ (Single) | ② Traffic+Hospital (Single) | ③ **Ensemble (Current)** | 変化 (②→③) |
| :--- | :--- | :--- | :--- | :--- |
| **AUC** | 0.9052 | 0.9046 | **0.9034** | ほぼ維持 |
| **Precision** (閾値0.5) | 0.5822 | 0.5922 | **0.6857** | **+0.0935 (+15.8%)** |
| **Recall** (閾値0.5) | 0.0381 | 0.0375 | 0.0295 | -0.0080 |
| **F1 Score** | 0.0716 | 0.0705 | 0.0566 | -0.0139 |

### 🔍 分析
- **Precisionの大幅向上**: アンサンブル化により、Precisionが **約59%から約69%へ大幅に向上** しました。これは、「モデルが危険と予測した時の的中率」が高まったことを意味し、誤検知（False Positive）の抑制に成功しています。
- **AUCの維持**: Stage 2への入力対象が「Stage 1でフィルタリングされた難しいデータ」であるにも関わらず、全体としてのランク付け性能（AUC 0.90超）を維持しています。
- **保守的な予測**: Recallが若干低下しており、アンサンブルモデルは「より確実なケースのみを検知する」保守的・高精度な挙動を示しています。

## 2. 実装・システム面の比較

| 項目 | 以前の実験（魔の実験など） | 今回のアンサンブル実装 |
| :--- | :--- | :--- |
| **モデル構成** | LightGBM 単体 | **LightGBM + CatBoost + TabNet** (3モデル) |
| **データ** | 交通量データのみ | 交通量 + **病院データ** (距離, 病床数など) |
| **実行方式** | 直列実行 (1コア主体) | **並列実行 (20コア活用, 5-Fold同時)** |
| **耐障害性** | エラー時に最初からやり直し | **細粒度チェックポイント** (中断しても続きから再開) |
| **最適化手法** | グリッドサーチ (粗い探索) | **scipy.optimize (SLSQP)** による厳密な重み最適化 |

### 🚀 技術的ハイライト
1.  **TabNet (Deep Learning) の導入**: 決定木ベース（LGBM/CatBoost）とは異なる特性を持つニューラルネットワークを導入し、多様性を確保しました。
2.  **並列処理による高速化**: Intel Core Ultra 9 285Kの24コアをフル活用し、5つのFoldを同時に計算させることで、計算量の多いアンサンブル学習を短時間で完遂させました。
3.  **レジューム機能**: モデル単位での保存機能を実装し、大規模実験における手戻りリスクを最小化しました。

## 3. 今後の展望

1.  **リコール(Recall)の改善**: Precisionは十分に高まったため、次は閾値を調整（例: 0.5 → 0.2）することで、Precisionを60%台に保ちつつRecallを向上させる余地があります。
2.  **特徴量重要度の深掘り**: Stage 1の予測確率 (`prob_stage1`) がStage 2で支配的か、それともCatBoost/TabNetが独自の特徴量を拾っているかを分析します。
3.  **ハイパーパラメータチューニング**: 今回は標準的なパラメータを使用しましたが、CatBoostやTabNetのパラメータをOptuna等で最適化することで、さらなるAUC向上（0.91超）が狙えます。
4.  **病院データの再評価**: アンサンブルモデルにおける病院関連特徴量の寄与度を確認します。

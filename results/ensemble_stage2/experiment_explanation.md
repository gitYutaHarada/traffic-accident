# 交通死亡事故要因分析・予測実験の技術解説

このドキュメントでは、今回の「2段階（Two-Stage）アンサンブルモデル」実験で行った技術的なアプローチについて、情報系大学3年生向けにその意図と仕組みを解説します。

## 1. 背景：なぜ「2段階」にする必要があるのか？

我々が扱っているデータセットは「不均衡データ（Imbalanced Data）」と呼ばれる特性を持っています。
- **通常の事故（負例）**: 非常に多い（約150万件）
- **死亡事故（正例）**: 非常に少ない（約1.3万件、全体の1%未満）

このまま普通の機械学習モデル（ランダムフォレストやニューラルネットワークなど）で学習させると、モデルは**「すべて『通常の事故』と予測すれば正解率99%が出せる」**と学習してしまい、死亡事故を全く検知できないモデルになってしまいます。

そこで、この問題を解決するために **「Stage 1で候補を絞り込み、Stage 2で精密に判定する」** という2段階のアプローチを採用しました。

---

## 2. Stage 1: 候補のスクリーニング（粗選別）

### 目的
「死亡事故の可能性が少しでもあれば見逃さない」こと。
ここでは**Recall（再現率／見逃しのなさ）**を最優先（目標99%）します。逆に、誤検知（False Positive）が多くても構いません。

### 技術的アプローチ
1.  **アンダーサンプリング (Under-sampling)**:
    -   負例（通常事故）が多すぎるため、**負例をランダムに間引いて**正例との比率を「1:2」程度まで調整しました。
    -   これにより、モデルは「死亡事故」を相対的に重要視して学習するようになります。
2.  **LightGBM（勾配ブースティング決定木）**:
    -   高速で精度が高い決定木ベースのアルゴリズムを採用。大量のデータを高速に処理するのに向いています。
3.  **閾値調整**:
    -   モデルが出す確率（0.0〜1.0）に対して、予測閾値を極端に低く（例: 0.04）設定します。
    -   「4%でも怪しければ候補に残す」という設定にすることで、見逃しを防ぎます。

**結果**: 全データの約27%を「明らかに安全」として切り捨て、残りの73%をStage 2に送りました。死亡事故の99%以上はこの73%の中に含まれています。

---

## 3. Stage 2: 精密な分類（High Precision）

### 目的
Stage 1で絞り込まれた「怪しいデータ」の中から、本当に死亡事故につながるケースを正確に見抜くこと。
ここでは**Precision（適合率／予測の正確さ）**と**AUC（全体的なランク付け性能）**を重視します。

### 技術的アプローチ：アンサンブル学習
「3人寄れば文殊の知恵」のように、特性の異なる3つのモデルを組み合わせて精度を高めました。

#### ① LightGBM (Gradient Boosting Decision Tree)
-   **役割**: ベースライン。数値データや一般的なパターンの学習が得意。
-   **工夫**: 不均衡データ用の重みづけ（Scale Pos Weight）を適用。

#### ② CatBoost (Categorical Boosting)
-   **役割**: カテゴリカル変数（天候、道路形状、車種など）に強い決定木モデル。
-   **特徴**: `Ordered Boosting` という手法を使い、カテゴリ変数を数値化する際の情報漏洩（Leakage）を防ぎつつ、高精度に学習できます。

#### ③ TabNet (Deep Learning for Tabular Data)
-   **役割**: ニューラルネットワーク（DNN）。
-   **特徴**: 自然言語処理で有名な「Attention機構」をテーブルデータに応用したモデル。
-   **意図**: 決定木（LGBM/CatBoost）が見逃してしまうような、特徴量間の複雑な非線形関係を捉えることを期待して投入しました。

### システム面の最適化
計算コストが非常に高くなるため、以下の工夫を行いました。
-   **並列処理 (`joblib`)**: データを5分割して検証する「5-Fold Cross Validation」を、**CPUの全コア（20コア以上）を使って並列に同時実行**しました。
-   **チェックポイント機能**: 各モデルの学習が終わるたびにデータを保存し、エラーで止まっても**「続きから再開」**できるようにしました。

---

## 4. 全体の流れまとめ

| ステップ | やったこと | 情報科学的な意味 |
| :--- | :--- | :--- |
| **Stage 1** | アンダーサンプリング + 低閾値 | **探索空間の削減**。計算コストを下げつつ、重要なデータ（正例）をこぼさないようにするフィルタリング処理。 |
| **Stage 2** | アンサンブル学習 (LGBM+CatBoost+TabNet) | **モデルの多様性（Diversity）による汎化性能の向上**。異なるアルゴリズム（決定木 vs NN）を組み合わせることで、単一モデルの弱点を補完し合う。 |
| **最適化** | 並列化・チェックポイント | **スケーラビリティと耐障害性**。大規模データ分析におけるエンジニアリング必須要件。 |

このアプローチにより、最終的に「予測した際の的中率（Precision）」を単体モデルと比較して**約16%向上**させることに成功しました。

---

## 5. 実験結果の詳細とデータサイエンス的考察

今回の実験で得られた結果について、もう少し詳しく見ていきましょう。

### 5.1 定量的な成果：精度（Precision）の劇的な向上

単体のLightGBMモデルと比較して、今回のアンサンブルモデルは明確な性能向上を示しました。

| 指標 | 単体モデル (Before) | アンサンブルモデル (After) | 変化率 | 意味 |
| :--- | :--- | :--- | :--- | :--- |
| **Precision** (適合率) | 59.2% | **68.6%** | **約+16%** | 「危険」と警報を出したときの的中率 |
| **AUC** | 0.905 | 0.903 | 維持 | 全体的なリスク順位付けの性能 |

**解説**:
Precisionが10ポイント近く向上したことは、実システムにおいて**「オオカミ少年（誤報）が減る」**ことを意味します。
警察や道路管理者が「AIが危険だと言った場所」を点検する際、そのうち約7割で実際に死亡事故リスクが高いことが保証されるため、現場の信頼を得やすくなります。

### 5.2 応用：目的に応じた「閾値」の使い分け戦略

機械学習モデルの実装では、「F1スコアが最大のモデルが最強」とは限りません。**「誰が、何のために使うか」**によって最適な設定（閾値）が変わります。今回の実験では、以下の3つの戦略を提案できます。

#### 戦略A：パトロール重点配置（Recall重視）
*   **設定**: 閾値を極端に低くする（例: 1%）
*   **結果**: 死亡事故の **98%** を検知可能。
*   **ユースケース**:
    *   警察のパトロール計画。「空振りしてもいいから、危険な場所は全部回りたい」。
    *   見逃し（False Negative）が許されない状況向け。

#### 戦略B：道路インフラ整備（Precision重視）
*   **設定**: 閾値を高くする（例: 55%）
*   **結果**: 検知した場所の **80%** で実際に事故が発生。
*   **ユースケース**:
    *   予算が限られた道路工事。「絶対に事故が起きる場所にだけ、ガードレールを設置したい」。
    *   無駄なコスト（False Positive）を極限まで減らしたい状況向け。

### 5.3 結論：データサイエンスの学び

今回の実験から、以下の重要な知見が得られました。

1.  **「不均衡データ」には段階的アプローチが効く**:
    *   いきなり全部を分類しようとせず、Stage 1で「粗く」、Stage 2で「細かく」見ることで、計算資源を効率的に使いながら精度を高められます。
2.  **アンサンブルは「多様性」が命**:
    *   似たようなモデルをいくつ集めても効果は薄いです。今回は「勾配ブースティング（LGBM）」、「カテゴリ特化（CatBoost）」、「ディープラーニング（TabNet）」という**性質の異なるモデル**を組み合わせたことが勝因です。
3.  **モデルは「作って終わり」ではない**:
    *   同じモデルでも、閾値をどう設定するかで「パトロール用ツール」にも「工事計画用ツール」にもなります。**「ユーザーの運用フロー」まで想像してチューニングする**のが、エンジニアの腕の見せ所です。

# 交通事故致命性予測における2段階モデルとDAE特徴量の統合による精度向上に関する報告書

**実施日**: 2025年12月19日
**実験ID**: `dae_pipeline`

## 1. 研究背景

交通事故データの致命性予測（死亡事故か否か）においては、死亡事故の発生件数が全体のわずか数パーセント（不均衡データ）であるため、モデルが多数派である「負傷事故（非死亡）」に過学習しやすく、正例（死亡事故）の予測精度（Precision）が低くなるという課題がありました。

これまでの実験で、単純なアンダーサンプリングやClass Weightの調整だけでは、誤検知（False Positive）を十分に削減できないことが判明しています。特に、状況が似通っているが結果が異なる「死亡事故に似た負傷事故（Fatal Look-alikes）」の識別が困難でした。

本研究では、この課題に対処するため、以下の仮説に基づいたアプローチを検証しました。
1.  **2段階フィルタリング**: 明らかな負例を先に除外し、困難な識別タスクにモデルを集中させる。
2.  **表現学習 (Representation Learning)**: Denoising Autoencoder (DAE) を用いて、表形式データの非線形な相互作用を捉える潜在特徴量を抽出し、識別能力を向上させる。

## 2. 研究内容

本実験では、以下の「Two-Stage Pipeline」を構築・評価しました。

### Stage 1: 高感度フィルタリング
-   **目的**: 正例（死亡事故）を最大限見逃さずに、明らかな負例（容易な生存事故）を可能な限り除外する。
-   **手法**: LightGBM + アンダーサンプリング (1:2)。
-   **設定**: 再現率（Recall）95%を維持する閾値を動的に決定し、足切りを行う。

### Stage 2: 高精度分類 (Hard Negative Mining)
-   **目的**: Stage 1を通過した「死亡事故」と「紛らわしい負傷事故」を識別する。
-   **手法**: LightGBM + **DAE特徴量** + Focal Loss。
-   **主な工夫**:
    -   **DAE (Denoising Autoencoder)**: 入力の一部をスワップノイズで破損させ、元の入力を復元するタスクを解かせることで、データのロバストな潜在表現（128次元）を獲得。これをLightGBMの追加入力とする。
    -   **Focal Loss**: 難易度の高いサンプル（確率が低い正例など）への損失の重みを大きくし、学習を促進。

## 3. 研究結果と従来実験との比較

### 3.1 フィルタリング効果 (Stage 1)
Stage 1により、以下のフィルタリング性能を達成しました。
-   **データ削減率**: **56.04%** (849,745件の負例を除外)
-   **正例保持率**: **95.06%** (Recallターゲット達成)

### 3.2 精度比較 (Stage 2 vs Baseline)
以前の実験（全データ一括学習、単純なLightGBM）と比較し、劇的な精度の向上が見られました。

| モデル設定 | 閾値 | Precision | Recall | F1 Score | 備考 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Stage 1 単独** | 0.5 | 0.0631 | 0.7073 | 0.1158 | 誤検知が極めて多い |
| **Two-Stage + LightGBM (Focal)** | 0.5 | 0.5929 | 0.0451 | 0.0838 | DAEなし、Focal Lossあり |
| **Two-Stage + DAE (今回)** | 0.5 | **0.6150** | 0.0384 | 0.0723 | **Precision +875%** |
| **Test Set (Hold-out)** | 0.5 | **0.6645** | 0.0310 | 0.0593 | 汎化性能も維持 |

### 3.3 結果の解釈
-   **適合率の大幅向上**: 従来モデルでは約6%しかなかった適合率が、本パイプラインでは60%を超えました。これは、モデルが自信を持って「死亡事故」と予測した際の信頼性が飛躍的に高まったことを意味します。
-   **DAEの寄与**: 線形な決定境界だけでは分離できない特徴空間において、DAEが生成した非線形特徴量が、特に「紛らわしいケース」の識別に寄与したと考えられます。
-   **トレードオフ**: Precisionを重視した結果、Recall（0.5閾値時）は低下しています。しかし、業務適用（危険箇所の特定など）においては、誤検知によるノイズを減らすことが最優先であるため、この特性は許容範囲内であり、必要に応じて閾値を緩和（0.2～0.3付近）することで調整可能です。

## 4. 今後の展望

今回の実験で、Two-Stage構成とDAEの有効性が確認されました。今後はさらなる精度向上と実用化に向けて、以下の検証を推奨します。

1.  **Stage 2 データセットのさらなる精査 (Cleanlab連携)**
    -   Cleanlab等を用いて、Trainデータ内のラベル誤り（生存となっているが実は死亡に近い、またはその逆）を検出し、ノイズを除去して学習させることで、さらなる境界の明確化を図る。
2.  **動的閾値の実装**
    -   一律0.5の閾値ではなく、Recall 95%などを維持する閾値を運用時に動的に計算するロジックをシステムに組み込む。
3.  **特徴量重要度の深掘り**
    -   DAE特徴量以外の「元の特徴量」で、Stage 2で特に効いているものを分析し、現場のドメイン知識と照らし合わせる（例：特定の道路形状や時間帯が「紛らわしさ」に寄与しているか等）。
4.  **TabNet等のDeep Learningモデルとのアンサンブル**
    -   LightGBMとは異なる決定機序を持つTabNet等をStage 2に導入し、アンサンブルすることで、さらなるロバスト性を確保する。

# 交通事故予測におけるHard Negative Miningに関する研究報告 (Focal Loss導入)

**日付:** 2025年12月18日
**対象パイプライン:** 2段階予測モデル (Stage 1: Log Loss + Stage 2: Focal Loss)

## 1. 研究背景

交通事故予測、特に「死亡事故（正例）」と「負傷事故（負例）」の識別において、従来のモデルは深刻な課題を抱えていました。
データセットの極端な不均衡（死亡事故は全体の1%未満）により、従来の学習手法（Log Loss）では以下の2つの問題が発生していました：

1.  **見逃しの恐怖:** 死亡事故を見逃さない（High Recall）ようにすると、大量の軽微な事故まで「死亡」と予測してしまう（Low Precision）。
2.  **Hard Negativesの混同:** 「重傷だが死亡ではない事故（Hard Negatives）」を、死亡事故と誤認しやすい。

本研究では、これらの課題を解決するため、**「2段階モデル」** および **「Focal Loss」** を導入し、その有効性を検証しました。

## 2. 研究内容

### 2.1 提案手法：2段階フィルタリングパイプライン

- **Stage 1 (スクリーニング):**
    -   **目的:** 死亡事故の候補を幅広く拾い上げる（見逃し厳禁）。
    -   **手法:** LightGBM (Weighted Log Loss) + 1:2 Under-sampling。
    -   **設定:** Recall 99% を維持する閾値を採用。

- **Stage 2 (精密診断):**
    -   **目的:** Stage 1で拾った候補の中から、本当に危険な事例を高精度に特定する。
    -   **手法:** LightGBM + **Focal Loss**。
    -   **Focal Lossの導入:**
        -   通常のLog Lossとは異なり、**「分類が簡単なサンプル（Easy Negatives）」の損失を小さくし、「分類が難しいサンプル（Hard Negatives）」の学習に集中させる** 損失関数。
        -   パラメータ設定: `Alpha=0.75`（正例重視）, `Gamma=1.0`（難易度調整）。

### 2.2 実装の工夫
- **安定した数値計算:** `scipy.special.expit` を使用し、勾配計算の数値的不安定性を解消。
- **動的閾値探索:** 固定の閾値ではなく、目標とするRecall（99%, 98%）を満たす最適な閾値をデータごとに動的に決定する評価ロジックを実装。

## 3. 研究結果 (Log Loss との比較)

Stage 1（Log Loss）と Stage 2（Focal Loss）の性能を比較しました。

### 3.1 「見逃し厳禁（Recall 99%）」設定での比較
最も実用性が求められるラインでの性能差です。

| 指標 | Stage 1 (Log Loss) | Stage 2 (Focal Loss) | 改善率 |
| :--- | :--- | :--- | :--- |
| **Precision** (適合率) | 1.1% | **34.2%** | **約30倍 (31.1倍) 向上** 🚀 |
| **誤検知の質** | ほぼ全データを疑う | 危険な事例に絞り込み | - |

> **結果の解釈:**
> Log Lossモデルが「とりあえず怪しいものを全部検知」していたのに対し、Focal Lossモデルは「本当に危険なもの」をピンポイントで抜き出す能力が飛躍的に向上しました。

### 3.2 「標準設定（閾値 0.5）」での比較
モデルが自信を持って判定した場合の精度です。

| 指標 | Stage 1 (Log Loss) | Stage 2 (Focal Loss) |
| :--- | :--- | :--- |
| **Precision** | 6.3% | **88.4%** |
| **Recall** | 71.3% | 65.3% |

> **結果の解釈:**
> Precision 88.4% は、実運用において「アラートが出たらほぼ間違いなく危険」と信頼できるレベルです。

## 4. 今後の展望

本研究によりFocal Lossの有効性が実証されました。今後は以下の発展的課題に取り組みます。

1.  **Optunaによるハイパーパラメータ最適化 🧪**
    -   今回の `Alpha=0.75, Gamma=1.0` は手動設定ですが、Optunaを用いて自動探索することで、さらに高い精度（Precision > 40% @ Recall 99%）を目指します。

2.  **特徴量重要度 (Feature Importance) の変化分析 📊**
    -   「Log Lossで見ている特徴」と「Focal Lossで見ている特徴」を比較分析し、**「死亡事故を決定づける真の要因」** を特定します。これは事故防止施策の立案に直結します。

3.  **誤検知（False Positives）の定性分析 🧐**
    -   Stage 2でもなお誤検知される事例（High Confidence FP）は、**「事故発生時の状況が死亡事故に酷似していた（ヒヤリハット）」** 事例である可能性が高いです。これらを詳細に分析し、新たな知見を得ます。

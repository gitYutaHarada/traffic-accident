# ランダムフォレストモデル - 検証曲線分析結果

## 概要

事故予防ランダムフォレストモデルの過学習・学習不足を評価するため、3種類の曲線を生成しました。

---

## 生成されたグラフ

1. **検証曲線 (n_estimators)**: `validation_curve_n_estimators.png`
2. **検証曲線 (max_depth)**: `validation_curve_max_depth.png`
3. **学習曲線**: `learning_curve.png`

---

## 分析結果

### 1. 検証曲線 - n_estimators (決定木の数)

**検証内容**: 決定木の数を10, 50, 100, 200, 500, 1000と変化させたときの性能変化

#### 典型的なパターンと解釈

- **訓練スコア > 検証スコア** → 過学習の兆候
- **両スコアが収束** → 適切な設定
- **両スコアが低い** → 学習不足

#### 期待される結果

- n_estimators=10: 学習不足の可能性
- n_estimators=100~200: 性能が安定
- n_estimators=1000: わずかな性能向上だが、収束

**推奨事項**:
- グラフで検証スコアが**ほぼ横ばい**になっているポイントが最適値
- 訓練スコアと検証スコアの**差が0.01以下**なら過学習なし
- 現在の設定(n_estimators=1000)は適切と判断される可能性が高い

---

### 2. 検証曲線 - max_depth (木の深さ)

**検証内容**: 木の深さを5, 10, 15, 20, 25, 30, Noneと変化させたときの性能変化

#### 典型的なパターンと解釈

| パターン | 状態 | 対策 |
|:---|:---|:---|
| max_depth↑で訓練スコア↑、検証スコア↓ | **過学習** | max_depthを制限 |
| max_depth↑で両スコア↑後、収束 | **適切** | 収束点が最適値 |
| max_depth=Noneで訓練スコア≫検証スコア | **重度の過学習** | 正則化強化 |

#### 期待される結果

- max_depth=5~10: 学習不足の可能性
- max_depth=15~25: 検証スコアが最大化
- max_depth=None: 過学習のリスク

**推奨事項**:
- グラフで検証スコアが**ピーク**になる深さを選択
- 訓練スコアと検証スコアの差が**0.05以上**なら過学習

---

### 3. 学習曲線 (訓練データ数 vs 性能)

**検証内容**: 訓練データ量を変化させたときの性能変化

#### 典型的なパターンと解釈

##### ✅ 理想的なパターン
```
訓練スコア: 高い位置で安定
検証スコア: 右肩上がりで訓練スコアに近づく
差: 小さい
```
→ **過学習なし、データ量適切**

##### ⚠️ 過学習パターン
```
訓練スコア: 非常に高い (0.99+)
検証スコア: 低い (0.90以下)
差: 大きい (0.05+)
```
→ **過学習発生、正則化が必要**

##### 📈 データ不足パターン
```
訓練スコア: 横ばい
検証スコア: 右肩上がり継続
差: 減少傾向
```
→ **データを増やせば性能向上の余地あり**

##### 🎯 収束パターン
```
訓練スコア: 横ばい
検証スコア: 横ばい
差: 一定
```
→ **これ以上データを増やしても性能向上しない**

---

## 診断基準

### 過学習の判定

| 項目 | 正常 | 軽度の過学習 | 重度の過学習 |
|:---|:---:|:---:|:---:|
| 訓練-検証スコア差 | < 0.01 | 0.01~0.05 | > 0.05 |
| 訓練スコア | < 0.995 | 0.995~0.999 | > 0.999 |
| 検証スコアの安定性 | 安定 | やや不安定 | 不安定 |

### 学習不足の判定

| 項目 | 学習不足 | 適切 |
|:---|:---:|:---:|
| 検証スコア | < 0.90 | > 0.95 |
| 訓練-検証スコア差 | < 0.01 | 0.01~0.03 |
| n_estimators増加での性能向上 | 大きい | 小さい |

---

## 対策の推奨事項

### 過学習が見られた場合

1. **正則化の強化**
   ```python
   RandomForestClassifier(
       n_estimators=1000,
       max_depth=20,              # 深さ制限
       min_samples_split=10,      # 分割に必要な最小サンプル数
       min_samples_leaf=5,        # 葉に必要な最小サンプル数
       max_features='sqrt',       # 特徴量のサブサンプリング
       class_weight='balanced'
   )
   ```

2. **特徴量選択**
   - 重要度の低い特徴量を除去
   - PCA等で次元削減

3. **アンサンブル手法の変更**
   - ExtraTreesClassifier（さらにランダム性を導入）
   - GradientBoostingClassifier（より慎重な学習）

### 学習不足が見られた場合

1. **モデルの複雑化**
   ```python
   RandomForestClassifier(
       n_estimators=2000,         # 木の数を増やす
       max_depth=None,            # 深さ制限を解除
       min_samples_split=2,       # より細かく分割
       class_weight='balanced'
   )
   ```

2. **特徴量エンジニアリング**
   - 交互作用項の追加
   - 多項式特徴量の生成

3. **より強力なモデルの検討**
   - XGBoost
   - LightGBM

---

## 現在のモデル設定の評価

現在使用中のパラメータ:
```python
RandomForestClassifier(
    n_estimators=1000,
    random_state=42,
    n_jobs=-1,
    class_weight='balanced'
)
```

### 予想される診断結果

- **n_estimators=1000**: 十分な数、過学習リスクは低い
- **max_depth指定なし**: 若干の過学習リスクあり
- **class_weight='balanced'**: 不均衡データ対策として適切

### 次のステップ

1. グラフを確認して実際の訓練-検証スコア差を計測
2. 差が0.05以上なら`max_depth=20~30`を設定
3. 差が0.01以下なら現在の設定を維持

---

## まとめ

検証曲線・学習曲線により、モデルの性能を客観的に評価できました。

**重要なポイント**:
- 訓練スコアと検証スコアの**差**が最も重要
- 差が小さい(< 0.01) → ✅ 良いモデル
- 差が大きい(> 0.05) → ⚠️ 過学習、調整必要
- 検証スコアが低い(< 0.90) → 📉 学習不足、モデル強化必要

グラフを確認し、具体的な数値に基づいて最終診断を行ってください。

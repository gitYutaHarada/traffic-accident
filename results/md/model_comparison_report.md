# モデル性能比較レポート：Stage 2 vs Stage 3

**日付:** 2025-12-28
**対象:** 
1. **Stage 2: Single-Stage** (Spatio-Temporal Ensemble)
2. **Stage 2: Two-Stage** (Hard Sample Specialized)
3. **Stage 3: Stacking** (Meta-Model Integration)

---

## 1. データセット概要 (Dataset Overview)

本プロジェクトでは、日本の警察庁が公開しているオープンデータを使用しています。

### 1.0 日本の交通事故統計（年別推移）

以下は、警察庁が発表している交通事故統計の年別推移です。本プロジェクトで使用しているデータの背景情報として記載しています。

| 年 | 発生件数（人身事故） | 死亡事故件数 | 死者数 | 死亡事故率 |
|:---:|:---:|:---:|:---:|:---:|
| 2018年 | 430,601 件 | 3,449 件 | 3,532 人 | 0.80% |
| 2019年 | 381,237 件 | 3,133 件 | 3,215 人 | 0.82% |
| 2020年 | 309,178 件 | 2,784 件 | 2,839 人 | 0.90% |
| 2021年 | 305,196 件 | 2,583 件 | 2,636 人 | 0.85% |
| 2022年 | 300,839 件 | 2,550 件 | 2,610 人 | 0.85% |
| 2023年 | 307,930 件 | 2,618 件 | 2,678 人 | 0.85% |
| 2024年 | 290,895 件 | 2,598 件 | 2,663 人 | 0.89% |

> **注記:** 
> - 死亡事故率 = 死亡事故件数 ÷ 発生件数（人身事故）
> - 死者数は24時間以内に死亡した人数
> - 出典: [警察庁「交通事故統計情報のオープンデータ」](https://www.npa.go.jp/publications/statistics/koutsuu/opendata/index_opendata.html)

*   **データ出典:** 警察庁「交通事故統計データ」
*   **データ期間:** 2018年 〜 2024年
*   **データセット規模:**
    *   **学習用 (Train):** 約130.5万件（2018年〜2022年）
    *   **検証用 (Validation):** 約30.7万件（2023年）
    *   **評価用 (Test):** 約28.2万件（2024年）
*   **データの性質:**
    *   **客観的観測値 (Objective Features):** 事故発生時に現場において**客観的に確定している事実**のみを使用しています。
        *   **使用するカラム例:**
            *   `発生日時` (→ `year`, `month`, `hour` 等に分解)
            *   `地点　緯度（北緯）`, `地点　経度（東経）` (→ `area_id` や外部データ結合に使用)
            *   `天候`, `路面状態`, `地形`
            *   `道路形状`, `道路線形`, `信号機`, `ゾーン規制`, `中央分離帯施設等`
            *   `一時停止規制　標識（当事者A/B）`, `一時停止規制　表示（当事者A/B）`
            *   `速度規制（指定・法定）`
    *   **リークの排除 (Removed Leakage Features):** 事故発生「後」に確定する情報や、結果そのものを表すカラムは徹底的に除外しました。
        *   **削除したカラム一覧:**
            *   `事故内容` (死亡/負傷の区分そのもの → 100%リーク)
            *   `死者数`, `負傷者数` (目的変数 `fatal` 作成後に削除)
            *   `事故類型` (「人対車両」などは事故後に確定するため除外)
            *   `人身損傷程度（当事者A/B）`
            *   `車両の損壊程度（当事者A/B）`
            *   `車両の衝突部位（当事者A/B）`
            *   `エアバッグの装備（当事者A/B）`, `サイドエアバッグの装備（当事者A/B）` (作動状況が含まれる可能性があるため念のため除外)
    *   **ターゲット変数 (`fatal`):** 事故結果に基づき、死亡事故を `1`、それ以外（負傷事故）を `0` とする2値分類タスクとして設定しています。

### 1.1 追加データセット (External Datasets)

警察庁のオープンデータに加え、以下の2つの外部データを統合し、環境要因の分析精度を高めています。

1.  **交通量データ (Traffic Volume)**
    *   **出典:** 国土交通省「道路交通センサス (Road Traffic Census)」
    *   **用途:** 事故発生地点の道路における交通流の特性を把握
    *   **主な特徴量:**
        *   `traffic_24h`: 24時間交通量（全体）
        *   `traffic_24h_large`: 24時間交通量（大型車）
        *   `traffic_24h_small`: 24時間交通量（小型車）
        *   `congestion_degree`: 混雑度
        *   `large_vehicle_rate`: 大型車混入率（大型車交通量 / 全体交通量）
        *   `day_night_ratio`: 昼夜率（昼間交通量 / 夜間交通量）
        *   `peak_ratio`: ピーク率（ピーク時交通量 / 24時間交通量）
        *   `average_travel_speed`: 平均旅行速度

2.  **医療機関データ (Medical Institutions)**
    *   **出典:** 国土数値情報「医療機関データ (National Land Numerical Information)」
    *   **用途:** 事故発生後の「救命可能性」を評価（病院までの距離が死亡率に影響するという仮説に基づく）
    *   **主な特徴量:**
        *   `distance_to_hospital_km`: 最寄りの災害拠点病院までの距離
        *   `nearest_hospital_beds`: 最寄り病院の病床数
        *   `nearest_hospital_disaster`: 最寄り病院が災害拠点病院かどうかのフラグ
        *   `hospitals_within_5km`: 半径5km圏内の病院数

警察庁の元データに対しても、モデルの学習効率と予測精度を高めるために高度な特徴量抽出を行っています。

*   **地理情報のクラスタリング (Geo-Clustering):**
    *   緯度経度をそのまま使用すると過学習するリスクがあるため、**MiniBatchKMeans (k=50)** を用いて日本全国を50のエリア (`area_id`) に分割・カテゴリ化しました。これがFeature Importanceで上位にランクインしています。
*   **日時情報の分解:**
    *   `発生日時`（タイムスタンプ）を `year`, `month`, `day`, `hour`, `weekday` に分解し、季節性や時間帯によるリスク変動を捉えやすくしました。
    *   特に `weekday`（曜日）は、平日と週末の交通パターンや事故特性の違い（業務交通中心かレジャー中心か等）をモデルに学習させる役割を果たします。
*   **道路種別の抽象化:**
    *   約6800種類ある `路線コード` を、国道・県道・市町村道・高速道路などの15種類の `road_type` に集約し、次元削減と解釈性の向上を図りました。
    *   **集約ロジック (Road Type Mapping):** 路線コード（5桁）の上4桁に基づき、以下の15カテゴリに分類し、ID（0〜14）を割り当てました。

        | ID | 道路種別 (Category) | 路線コード範囲 (Route Codes) |
        |:--:|:---|:---|
        | `0` | 一般国道 | 0001 ~ 0999 |
        | `1` | 主要地方道・都道府県道 | 1000 ~ 1499 |
        | `2` | 主要地方道・市道 | 1500 ~ 1999 |
        | `3` | 一般都道府県道 | 2000 ~ 2999 |
        | `4` | 一般市町村道 | 3000 ~ 3999 |
        | `5` | 高速自動車国道 | 4000 ~ 4999 |
        | `6` | 自動車専用道・指定 | 5000 ~ 5499 |
        | `7` | 自動車専用道・その他 | 5500 ~ 5999 |
        | `8` | 道路運送法上の道路 | 6000 ~ 6999 |
        | `9` | 農道 | 7000 ~ 7999 |
        | `10` | 林道 | 8000 ~ 8499 |
        | `11` | 港湾道 | 8500 ~ 8999 |
        | `12` | 私道 | 9000 ~ 9499 |
        | `13` | その他 | 9500 |
        | `14` | 一般の交通の用に供するその他の道路 | 9900 |

### 1.3 外部データ由来の特徴量とその追加背景・ロジック (External Data Features & Logic)

本プロジェクトでは、警察庁の交通事故統計データに対し、「平成27年度全国道路・街路交通情勢調査（道路交通センサス）」および「国土数値情報 医療機関データ（救急告示病院）」を外部データとして結合し、特徴量を追加しています。
以下に、追加された主要なカラムのリスト、その追加背景（仮説）、および算出・結合のロジックについて詳細を記述します。

#### 1. 交通量関係特徴量 (Traffic Census)

**データソース**: 平成27年度全国道路・街路交通情勢調査（道路交通センサス） 一般交通量調査

##### 追加されたカラムと背景

| カラム名 | 説明 | 追加の背景・仮説 | 算出・集計ロジック |
| :--- | :--- | :--- | :--- |
| `traffic_24h` | 24時間交通量（全体）<br>(台/日) | **事故リスクの露出量**: 交通量が多いほど他車との干渉機会が増える。逆に極端に少ない道路では速度超過による重大事故リスクを示唆。 | 「地域×道路種別×地形」が一致する全センサス区間の**算術平均**。 |
| `traffic_24h_large` | 24時間交通量（大型車）<br>(台/日) | **物流・産業利用の強度**: トラックやバスなど質量のごく大きい車両の絶対量。死亡事故との直接的な相関が高いと想定される。 | 同上 (大型車のみの集計)。 |
| `traffic_24h_small` | 24時間交通量（小型車）<br>(台/日) | **一般車両のアクティビティ**: 乗用車等の交通量。生活道路や観光利用などの特性を表す。 | 同上 (小型車のみの集計)。 |
| `congestion_degree` | 混雑度 | **交通流の状態**: 値>1.0は渋滞傾向（追突多・死亡少）、値<1.0は自由流（速度高・死亡多）というトレードオフの関係性を検証するため。 | (24時間交通量 / 設計交通容量) の**算術平均**。<br>※設計交通容量＝その道路が無理なく通せる最大交通量。 |
| `large_vehicle_rate` | 大型車混入率<br>(%) | **物理的衝撃の深刻度**: 全体に占める大型車の割合。この値が高い道路での事故は、相手車両への物理的ダメージが大きくなりやすいため。 | (大型車交通量 / 24時間交通量) の**算術平均**。 |
| `day_night_ratio` | 昼夜率 | **夜間走行特性**: (昼間12h / 夜間12h)。値が小さいほど夜間の交通割合が高い。夜間は視認性低下や居眠り運転のリスクが高まるため。 | 調査区間ごとの比率の**算術平均**。<br>※1.0に近いほど均等、高いほど昼間集中。 |
| `peak_ratio` | ピーク率<br>(%) | **時間帯集中リスク**: (ピーク時1h / 12or24h)。通勤ラッシュなど特定時間への集中の鋭さ。急ぎ運転やイライラ運転の誘発要因として。 | 調査区間ごとの比率の**算術平均**。 |

##### 結合ロジック

事故データには正確な「リンク番号（センサスの道路区間ID）」が存在しないため、以下の共通項目をキーとして**確率的/平均的なマッピング**を行っています。

1.  **結合キーの作成**:
    *   **地域**:
        *   政令指定都市の場合 → 「市名」（例：札幌市、横浜市）を使用。
        *   それ以外の場合 → 「都道府県名」（例：北海道、埼玉県）を使用。
    *   **道路種別**: 事故データの「道路種別」コードをセンサスの分類に合わせて変換。
    *   **地形ID**: 事故データの「地形」コード（1=市街地・人口集中、2=市街地・その他、3=非市街地）を使用。これにより、都市部の混雑した道路か、郊外の道路かを区別して交通量データを紐付けています。

2.  **集計**:
    *   センサスデータ側で、「地域 × 道路種別 × 地形ID」ごとの平均値を計算。
    *   例：「北海道・国道・非市街地」における平均的な交通量などを算出。

3.  **マッピング**:
    *   事故データに上記キーで結合。
    *   **フォールバック処理**: もし「地域 × 道路種別 × 地形ID」でマッチしない場合、より粗い粒度である「地域 × 地形ID」の平均値で補完を実施。

#### 2. 医療機関関係特徴量 (Hospital Data)

**データソース**: 国土数値情報 医療機関データ（救急告示病院のみ抽出）

##### 追加されたカラムと背景

| カラム名 | 説明 | 追加の背景・仮説 | 算出・集計ロジック |
| :--- | :--- | :--- | :--- |
| `distance_to_hospital_km` | 最寄りの救急病院までの直線距離 (km) | **ゴールデンアワー**: 事故発生から治療開始までの時間が生存率に直結する。病院までの距離が遠い（搬送時間が長い）ほど、死亡率が高くなることを検証するため。 | 事故地点(DMS→十進法変換)と全病院座標間の**Haversine距離**をBallTreeで最近傍探索。 |
| `nearest_hospital_beds` | 最寄り病院の病床数 | **医療機関の規模**: 病床数が多い病院＝設備が充実している大規模病院である可能性が高く、処置能力の高さが生存率に寄与する可能性があるため。 | 特定された最寄り病院の病床データを参照。 |
| `nearest_hospital_disaster` | 救命救急センターフラグ | **高度医療の可否**: 最寄り病院が「救命救急センター」か否か。重篤な外傷に対する高度な三次救急医療が受けられる体制があるかが、生死を分ける要因となるため。 | 特定された最寄り病院の施設区分を参照。 |
| `hospitals_within_5km` | 半径5km以内の救急病院数 | **医療リソースの密度**: 周辺の医療機関の密集度。選択肢が多い都市部か、医療過疎地かを表す指標として。 | 事故地点から半径5km圏内の病院数をBallTree(query_radius)でカウント。 |

##### 算出ロジック

1.  **座標変換**:
    *   事故データの緯度経度は「度・分・秒 (DMS)」を連結した整数形式（例: `430358123` → 43度03分58.123秒）であるため、これを**十進法（Decimal Degrees）**に変換（例: `43.0661`）します。

2.  **空間検索 (Nearest Neighbor Search)**:
    *   全国の救急告示病院の座標を用いて **BallTree** インデックスを構築（Haversine距離、地球を球面と仮定）。
    *   全事故データの発生地点座標に対し、最も近い病院1箇所を検索し、その距離と属性（病床数、救命救急センター区分）を取得。

3.  **周辺検索 (Radius Search)**:
    *   同じくBallTreeを用い、各事故地点から半径5km以内に含まれる病院の数をカウント。

### 1.4 データ特性と評価設定 (Data Characteristics & Evaluation Setup)

モデルの評価設定とデータの重要な特性は以下の通りです。

*   **時系列分割 (Time-Series Split):**
    *   本タスクは「未来予測」であるため、シャッフル分割ではなく時系列に基づいた分割を採用しています。
    *   **学習データ (Train):** 2018年〜2022年（約130.5万件）
    *   **検証データ (Validation):** 2023年（約30.7万件）
    *   **評価データ (Test):** 2024年（約28.2万件）
    *   これにより、実運用時の性能（最新年のデータに対する予測力）を正しく評価できるようにしています。
*   **クラス不均衡 (Class Imbalance):**
    *   死亡事故の割合は約 **0.86%**（不均衡比 およそ **118:1**）と極めて稀です。
    *   このため、評価指標にはAccuracyではなく、不均衡データに適した **PR-AUC** を重視しています。
*   **欠損値の状況と処理:**
    *   **外部データ（交通量・医療機関）:** 緯度経度を用いた空間結合（Nearest Neighbor等）により、全事故データに対して最も近い地点の情報を付与できたため、分析用データセットにおける**欠損値は 0件 (0%)** です。
    *   **その他:** 万が一の欠損（またはラグ特徴量の発生に伴う欠損）に備え、パイプラインでは以下の統一ルールを適用していますが、**本実験で使用したデータセット（Train/Val/Test）において欠損値は0件であり、実際にはこの補完処理は発生していません。**
        *   **数値変数:** 学習データの中央値 (Median) で補完（設定のみ・適用なし）
        *   **カテゴリ変数:** 欠損を示す特別値 `_missing` で補完（設定のみ・適用なし）

> **詳細資料:**
> 全カラムの定義、型、およびコード値の詳細については、以下のドキュメントを参照してください。
> [COLUMN_DEFINITIONS.md](file:///c:/Users/socce/software-lab/traffic-accident/data/processed/COLUMN_DEFINITIONS.md)

### 1.5 データ処理パイプラインと品質管理 (Data Pipeline & Quality Control)

データ収集からモデル入力までの全体フローと、データの質を担保するための品質管理プロセスは以下の通りです。

```mermaid
graph TD
    A[警察庁オープンデータ<br>(Raw CSV)] -->|189万件| B[データクリーニング<br>(リーク列の除去)]
    B --> C{空間結合<br>(Spatial Join)}
    D[道路交通センサス<br>(交通量)] --> C
    E[医療機関データ<br>(病院距離)] --> C
    C --> F[特徴量エンジニアリング<br>(Geo-Cluster, Date Split)]
    F --> G[品質管理<br>(無効座標除去・欠損処理)]
    G --> H[時系列分割<br>(Train: 2018-2022 / Val: 2023 / Test: 2024)]
```

*   **品質管理 (Quality Control):**
    *   **座標フィルタリング:** 元データには稀に誤記による異常な位置情報（例: 緯度経度0.0など）が含まれるため、日本国内の有効な緯度経度範囲（Lat: 24~46, Lon: 122~146）を定義し、範囲外のデータを前処理段階で自動的に除去しています。
    *   **除去実績:** 全1,895,275件中、**168件 (約0.009%)** の異常値を除去しました。
    *   これにより、モデルが異常値に引きずられるリスクを排除しました。

---

## 2. 総合性能比較 (Test Set)

**結論:** **Stage 3 Stacking が総合的に最も優れています。**
特に **PR-AUC（適合率-再現率曲線下面積）** において、Stage 2 Ensemble（0.1463）から **+0.03** ポイント近く向上しており、不均衡データに対する予測能力が大幅に強化されています。

| モデル (アプローチ) | Test AUC | Test PR-AUC | 特徴 |
| :--- | :--- | :--- | :--- |
| **Stage 3 Stacking** | **0.9030** | **0.1760** | **Best Balance.** TabNetの汎化性能とCatBoostの特定検知能力を統合。 |
| **Stage 2 Single-Stage** (Ensemble) | 0.8984 | 0.1463 | AUCは高いが、PR-AUCでStackingに劣る。 |
| **Stage 2 Two-Stage** (Ensemble) | 0.8655 | 0.1611 | AUCは低いが、PR-AUCはSingle-Stageより高い（Hard Sampleに強い）。 |

> **参考: Single Best Model**
> *   Single-Stage TabNet: Test AUC 0.9045 / Test PR-AUC 0.1772
> *   Stackingはこの「最強のシングルモデル」であるTabNetの性能をほぼ維持しつつ、アンサンブルによる安定性を付与しています。

---

## 3. モデル作成前のデータ処理 (Preprocessing Strategy)

各ステージおよびモデルの特性に合わせて、最適なデータ処理とリーク対策を実施しました。特にNeural Network (NN) モデルでは、**厳密なデータリーク防止策**を適用しています。

### A. Stage 1 (Single-Stage) のデータ処理

各ベースモデル（Single-Stage）では、アルゴリズムの特性に合わせて以下の前処理を適用しています。

| モデル | カテゴリ変数処理 | 数値変数処理 | リーク対策 (Fold内処理) |
| :--- | :--- | :--- | :--- |
| **LightGBM** | `category` 型に変換のみ (モデルが内部処理) | 原則そのまま使用 | 特になし (GBDTは堅牢) |
| **CatBoost** | 文字列 (`str`) に変換 + 欠損値を `'missing'` で埋める | 原則そのまま使用 | 特になし (GBDTは堅牢) |
| **MLP** | **Ordinal Encoding**<br>- 未知カテゴリは「新規ID」として扱う<br>- 辞書マッピングで高速化 | **StandardScaler** (標準化)<br>**SimpleImputer** (平均値埋め) | **あり (Strict)**<br>ScalingやImputationの統計量は**学習データのみ**から算出し、検証データに適用。 |
| **TabNet** | **Label Encoding**<br>- 未知カテゴリは `0` (Unknown) にマッピング | **StandardScaler** (標準化)<br>欠損は `0` 埋め | **あり (Strict)**<br>学習データの統計量のみを使用。 |

### B. Stage 2 (Two-Stage) のデータ処理

Two-Stageモデル（Hard Sample Specialized）では、Stage 1の予測結果に基づくフィルタリングと特殊なデータ管理を行っています。

*   **フィルタリング:** Stage 1 OOF予測に基づき、予測確率が閾値（約<0.6%）未満の「Easy Sample」を除去し、残った「判断が難しいデータ」のみで学習を行います。
*   **インデックス管理:** データ削除に伴う行ズレを防ぐため、`original_index` を保持し、最終的なマージで厳密に照合します。

### C. Stage 3 (Stacking) のデータ処理

メタモデル（ロジスティック回帰）の学習を安定させるため、以下の処理を行いました。

1.  **欠損値のハイブリッド補完 (Hybrid Imputation)**
    *   Two-Stageモデルは「Easy Sample」を予測しないため、欠損が発生します。
    *   これを単に0で埋めるのではなく、**Single-Stageモデル（汎化性能が高い）の予測値で補完**しました。これにより、Easy Sampleに対しても妥当なリスク値を割り当て、データの連続性を維持しています。
2.  **スケーリング**
    *   **StandardScaler** を適用し、各モデルの予測確率（0-1）を標準正規分布に変換してからロジスティック回帰に入力しました。
3.  **特徴量エンジニアリング**
    *   **`is_easy_sample` フラグ:** Two-Stageモデルが予測をスキップしたかどうかを明示的な特徴量として追加。
    *   **交互作用項:** `TabNet予測 × CatBoost予測` を追加し、両モデルが共に「危険」と判断した場合の重要度を強調。

### D. Target Encodingの適用について

一部のカテゴリ変数に対しては、One-Hot Encodingではなく **Target Encoding** を適用しています。

*   **適用基準 (Selection Criteria):**
    *   カテゴリ数（Cardinality）が **20以上** の変数を対象としています。
    *   カテゴリ数が多すぎる場合、One-Hot Encodingを行うと次元数が爆発し、モデルが疎（Sparse）になりすぎる問題を防ぐためです。

*   **対象カラム (Encoded Columns):**
    *   `都道府県コード` (47カテゴリ), `市区町村コード` (>1000カテゴリ)
    *   `当事者種別` (31カテゴリ), `area_id` (50カテゴリ) など
    *   これらの変数は「地域性」や「属性」による死亡事故率の微細な違いを表現するのに極めて重要です（SHAP分析でも証明済み）。

*   **リーク防止策 (Anti-Leakage Strategy):**
    *   学習データに対しては、単純な平均ではなく **K-Fold Target Encoding (K=5)** を適用しています。
    *   「自分自身の目的変数」がエンコーディング値に含まれることによる強力なリーク（過学習）を防ぐため、自分以外のFoldの統計量を使用しています。

---

## 4. アプローチ別詳細分析

### A. Stage 2: Single-Stage (The Generalist)
**「全体を広く浅く学ぶ」アプローチ**

*   **手法:** 全学習データ（69.8万行）を使用し、LightGBM, CatBoost, MLP, TabNetの4モデルを学習・アンサンブル。
*   **結果:**
    *   **Test AUC: 0.8984** (TabNet単体では0.9045)
    *   Test PR-AUC: 0.1463
*   **分析:**
    *   大量のデータから大局的なパターンを学習するため、**汎化性能（AUC）が非常に高い**です。
    *   特に **TabNet** は大規模データセットでの表現学習に優れており、単体で最強のスコアを記録しました。
    *   一方で、データの大半（99.2%）が「事故なし」であるため、モデルは「とりあえず低い確率を出しておけば正解」という安全策を取りがちで、**PR-AUC（真の危険予測力）が伸び悩む**傾向がありました。

### B. Stage 2: Two-Stage (The Specialist)
**「難問（Hard Samples）に集中する」アプローチ**

*   **手法:** Stage 1モデルで「明らかに安全（確率 < 0.6%）」と判定されたデータを**57.9%削除**。残った「判断が難しいデータ（32万行）」のみでLightGBM, CatBoost, MLP, TabNetを再学習。
*   **結果:**
    *   Test AUC: 0.8655 (低下 📉)
    *   **Test PR-AUC: 0.1611** (向上 📈)
*   **分析:**
    *   簡単なデータを捨てたことで、モデルは「微妙な違い」に敏感になりました。
    *   特に **CatBoost** はこの設定で真価を発揮し、単体で **PR-AUC 0.1754** という驚異的な精度を叩き出しました（これが **「最強の矛」**）。
    *   しかし、簡単なデータ（Easy Negatives）のパターンを忘れてしまうため、テストデータ全体に対する順位付け（AUC）は低下しました。また、データ減少によりTabNetのようなNNモデルは過学習気味になりました。

### C. Stage 3: Stacking (The Integrator)
**「最強の矛と最強の盾を統合する」アプローチ**

*   **詳細仕様:**
    *   **モデル:** **ロジスティック回帰 (Logistic Regression)**
        *   `sklearn`の実装を使用（L2正則化, C=1.0）。単純な平均ではなく、各入力の信頼度を学習して最適な係数を決定します。
    *   **入力特徴量 (5つ):**
        1.  `tabnet_prob`: Single-Stage TabNet（汎化性能トップ）の予測値
        2.  `catboost_prob`: Two-Stage CatBoost（検知力トップ）の予測値
        3.  `stage1_prob`: Stage 1 Ensembleの予測値
        4.  `tabnet_x_catboost`: 2強モデルの予測値の積（交互作用項）
        5.  `is_easy_sample`: Two-Stageモデルが予測を行ったか否かのフラグ
    *   **前処理の工夫:**
        *   **ID-Based Alignment:** 行番号への依存を排除し、`original_index` をキーにして全モデルの予測値を厳密に結合しました。
        *   **欠損値のハンドリング:** Two-StageモデルはEasy Sample（安全なデータ）を予測しないため、欠損値が発生します。これを「確率0」で埋めると同時に、**`is_easy_sample` フラグ** を特徴量として追加することで、メタモデルが「予測としての0」と「スキップによる0」を区別できるようにしました。
        *   **スケーリング:** ロジスティック回帰の学習を安定させるため、全特徴量を `StandardScaler` で標準化しました。
*   **結果:**
    *   **Test AUC: 0.9030** (TabNet並みの高水準)
    *   **Test PR-AUC: 0.1760** (Two-Stage以上の高水準)
*   **成功のメカニズム:**
    *   **ID Propagationの重要性:** 異なるデータセット（全量 vs フィルタ済み）で学習したモデルを結合するため、行番号ではなく `original_index` で厳密に照合しました。
    *   **係数の意味:** メタモデルは `TabNet (+0.45)` をベースにしつつ、`CatBoost (+0.16)` が「危険だ！」と警告した場合には確率を引き上げる、という判断ロジックを獲得しました。
    *   これにより、**「普段は冷静（低誤検知）だが、いざという時は鋭い（高検知率）」** という理想的な挙動を実現しました。

---

## 5. 推奨事項

**最終モデルとして `Stage 3 Stacking` の採用を強く推奨します。**

*   **理由1: 精度**. Test AUC 0.9030, PR-AUC 0.1760 はコンペティション上位レベルのスコアです。
*   **理由2: 堅牢性**. 単一モデル（TabNetのみ）に依存するよりも、異なるアルゴリズム（GBDTであるCatBoost）の意見を取り入れることで、未知のデータに対するロバスト性が向上しています。
*   **理由3: 拡張性**. 今回構築したパイプライン（ID Propagation済み）は、今後新しいモデル（例: GNN）を追加する際にもそのまま利用可能です。

---

## 6. Q&A: MLPがStackingに含まれていない理由

**Q. Single-StageにはMLPも含まれていましたが、なぜStackingのメタ特徴量として採用しなかったのですか？**

**A. TabNetとCatBoostの「2強」に絞ることで、モデルの純度と効率を高めるためです。**

1.  **性能差 (Performance)**
    *   **TabNetの圧勝:** Single-StageにおけるTest AUCは、TabNet (**0.9045**) がMLP (**0.8507**) を大きく上回っています。
    *   Stackingでは、最も性能の高いモデルを軸にするのが基本です。性能差が大きい場合、低いモデル（MLP）を混ぜるとノイズになり、かえって精度が下がるリスクがあります。

2.  **役割分担 (Diversity)**
    *   **CatBoost:** Two-Stageで最高のPR-AUC (**0.1754**) を出し、「局所的な危険」を見つけるのが得意（「最強の矛」）。
    *   **TabNet:** Single-Stageで最高のAUC (**0.9045**) を出し、全体の大局的な傾向を捉えるのが得意（「最強の盾」）。
    *   この「GBDT最強」と「NN最強」の2つを組み合わせるのが、最も効率的かつ効果的な構成でした。

# Plan C: 閾値調整 (Threshold Tuning) 検証レポート

**実行日時**: 2025-12-19
**対象モデル**: Stage 2 Ensemble (TabNet 90% + LightGBM 10%)
**データ**: Cross Validation OOF Predictions (全データ学習モデル相当)

## 1. 概要
ユーザー提案の「Plan C: 閾値調整」を実行しました。
「AUC 0.89（高い識別能力）があるなら、閾値0.5が最適ではないだけで、閾値を動かせばF1が跳ね上がるはず」という仮説を検証します。
具体的には、閾値を `0.05` 〜 `0.95` の範囲で動かし、F1スコアが最大になるポイント（Optimal Threshold）を探索しました。

## 2. 検証結果

### 閾値別パフォーマンス推移 (Overview)

| Threshold | F1 Score | Precision | Recall | 備考 |
| :--- | :--- | :--- | :--- | :--- |
| 0.10 | 0.0376 | 0.0192 | 0.9949 | ほぼ全件をPositiveと予測 |
| 0.20 | 0.0552 | 0.0285 | 0.9301 | ユーザー提案値 (精度過小) |
| 0.30 | 0.0753 | 0.0394 | 0.8622 | ユーザー提案値 (精度過小) |
| **0.50** | **0.1293** | 0.0711 | 0.7100 | **Default (基準)** |
| 0.60 | 0.1589 | 0.0908 | 0.6341 | |
| 0.70 | 0.1976 | 0.1216 | 0.5266 | |
| 0.80 | 0.2414 | 0.1785 | 0.3729 | F1急上昇 |
| **0.83** | **0.2464** | **0.2077** | **0.3029** | **Optimal Threshold (F1 Max)** |
| 0.90 | 0.1119 | 0.3705 | 0.0659 | Recall激減 |

### 最適点詳細
**Best Threshold**: `0.83`
- **F1 Score**: `0.2464`
- **対 Default(0.5)比**: **約2倍 (1.9倍)** のスコア向上を確認。

## 3. 考察と結論

1.  **仮説は正しかったか？**: 
    - **Yes**: 閾値を0.5から動かすことで、F1スコアは `0.1293` -> `0.2464` と劇的に向上しました。モデル自体の識別能力（AUC）が高いという指摘通り、単にカットオフラインの問題でした。
    - **No (方向性)**: 提案にあった「0.2, 0.3...」といった低い閾値ではなく、**「0.83」という非常に高い閾値**が最適解でした。
    
2.  **なぜ高い閾値なのか？**:
    - データが極端に不均衡（死亡事故は少数）であるため、モデルは安全側に倒れて低い確率を出力しがち...ではなく、逆に多くのデータに対して「ある程度の確率」を出してしまっているようです（Precisionが低い）。
    - そのため、判定基準を `0.83` まで厳しく引き上げ、「絶対に死亡事故だ」と自信があるものだけを拾うことで、Precisionを劇的に改善（0.07 -> 0.20）し、結果としてF1を最大化できました。

3.  **アクション**:
    - 今後は予測時の閾値を `0.5` ではなく `0.83` (またはRecall要件に合わせて調整した値) をデフォルトとして採用すべきです。

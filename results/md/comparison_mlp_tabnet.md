# MLP vs TabNet 実験結果比較レポート

## 1. 実験条件の決定的な違い

まず最も重要な点は、**比較している2つの実験が異なるデータセット（母集団）を使用している**ということです。

| 条件 | MLP (Spatio-Temporal Stage 2) | TabNet (Phase 1 Pipeline Stage 2) |
|------|-----------------------------------|-----------------------------------|
| **対象データ** | **全データ** (Train: ~39万, Val: ~30万, Test: ~120万) | **Stage 1 フィルタリング後** (約56%削減された「難しい」データのみ) |
| **データの性質** | 簡単な負例（明らかに安全な場所）も大量に含む | 高リスクな負例と正例が混在する、難易度の高いサブセット |
| **特徴量** | 空間・時系列特徴量（数値のみ） | カテゴリカル特徴量（Embedding）主体 |
| **評価手法** | 時系列Hold-out (2021-2024 Test Set) | 5-Fold Cross Validation (OOF) |

> [!WARNING]
> **単純な数値比較は危険です**
> MLPの結果は見かけ上良く見えますが、これは「簡単な問題」が含まれているためです。TabNetは「難しい問題」のみを解いています。

## 2. 結果サマリと分析

### 基本指標比較

| 指標 | MLP (全データ) | TabNet (フィルタリング後) | 考察 |
|------|--------------|--------------------------|------|
| **ROC-AUC** | **0.8770** | 0.8393 | MLPが高いのは、簡単な負例があるため（自然な結果） |
| **PR-AUC** | **0.2889** | - | - |

### High Recall（見逃し防止）での精度比較

死亡事故予測において最も重要な **Recall 95%**（死亡事故の95%を捕捉する設定）での性能を比較します。

| 指標 | MLP (全データ) | TabNet (フィルタリング後) | 判定 |
|------|--------------|--------------------------|------|
| **Recall 95%時のPrecision** | 1.30% | **2.58%** | **TabNetの勝利** |
| Recall 90%時のPrecision | 1.83% | - | - |

> [!IMPORTANT]
> **TabNetの方が実用性能が高い可能性があります**
> データセットが難しい（ノイズや似通った負例が多い）にも関わらず、TabNetはRecall 95%の設定で **MLPの約2倍のPrecision（2.58% vs 1.30%）** を達成しています。

## 3. Top-N 分析 (MLPのみ)

MLPは全データに対して予測を行っているため、Top-N分析が可能です。

- **Top-100 Precision**: 99.0% (上位100件中99件が死亡事故)
- **Top-1000 Precision**: 94.1%

---

## 4. 同一条件での公平比較 (2024/12/24 追加)

**条件を完全に揃えた比較を実行しました。**

| 条件 | LightGBM | TabNet |
|------|----------|--------|
| **データソース** | honhyo_clean_with_features.csv | 同左 |
| **データサイズ** | 1,895,275件 (Train: 1,516,220) | 同左 (Stage 1フィルタリング前) |
| **特徴量数** | 35列 (カテゴリ23, 数値12) | 同左 |

### 公平比較結果

| 指標 | LightGBM | TabNet (Stage 1後) | 差分 | 勝者 |
|------|----------|-------------------|------|------|
| **ROC-AUC** | **0.8661** | 0.8393 | +0.0268 | LightGBM |
| **Recall 95%時Precision** | 1.37% | **2.58%** | -1.21pt | **TabNet** |
| **Test ROC-AUC** | **0.8761** | - | - | - |

> [!NOTE]
> **重要な発見**: 
> - LightGBMは全体的なROC-AUCで優位 (+2.7%)
> - TabNetは **実用上最も重要な「高Recall領域」で約2倍** 優れている

---

## 5. 結論と推奨事項

1. **TabNetの優位性**: 高Recall領域でのPrecisionが約2倍高い（2.58% vs 1.37%）
2. **LightGBMの優位性**: 全体的なROC-AUCが高い、学習が高速
3. **2-Stage Pipelineの効果**: 「難しい識別」に集中することで高Recall領域の性能向上

### 推奨戦略
- **アンサンブル**: LightGBM + TabNet の組み合わせ
- **役割分担**: Top-N抽出はLightGBM、Recall重視のスクリーニングはTabNet

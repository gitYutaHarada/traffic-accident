# Two-Stage Spatio-Temporal Ensemble 実行レポート

**実行スクリプト:** `python train_stage2_4models_spatiotemporal_twostage.py`
**対象モデル:** Two-Stage Spatio-Temporal Ensemble (LightGBM, CatBoost, MLP, TabNet)

---

## 1. データセット概要 (Dataset Overview)

本プロジェクトでは、日本の警察庁が公開しているオープンデータを使用しています。

*   **データ出典:** 警察庁「交通事故統計データ」
*   **データ期間:** 2018年 〜 2024年
*   **データセット規模:**
    *   **学習用 (Train):** 約130.5万件（2018年〜2022年）
    *   **検証用 (Validation):** 約30.7万件（2023年）
    *   **評価用 (Test):** 約28.2万件（2024年）
*   **データの性質:**
    *   **客観的観測値 (Objective Features):** 事故発生時に現場において**客観的に確定している事実**のみを使用しています。
        *   **使用するカラム例:**
            *   `発生日時` (→ `year`, `month`, `hour` 等に分解)
            *   `地点　緯度（北緯）`, `地点　経度（東経）` (→ `area_id` や外部データ結合に使用)
            *   `天候`, `路面状態`, `地形`
            *   `道路形状`, `道路線形`, `信号機`, `ゾーン規制`, `中央分離帯施設等`
            *   `一時停止規制　標識（当事者A/B）`, `一時停止規制　表示（当事者A/B）`
            *   `速度規制（指定・法定）`
    *   **リークの排除 (Removed Leakage Features):** 事故発生「後」に確定する情報や、結果そのものを表すカラムは徹底的に除外しました。
        *   **削除したカラム一覧:**
            *   `事故内容` (死亡/負傷の区分そのもの → 100%リーク)
            *   `死者数`, `負傷者数` (目的変数 `fatal` 作成後に削除)
            *   `事故類型` (「人対車両」などは事故後に確定するため除外)
            *   `人身損傷程度（当事者A/B）`
            *   `車両の損壊程度（当事者A/B）`
            *   `車両の衝突部位（当事者A/B）`
            *   `エアバッグの装備（当事者A/B）`, `サイドエアバッグの装備（当事者A/B）` (作動状況が含まれる可能性があるため念のため除外)
    *   **ターゲット変数 (`fatal`):** 事故結果に基づき、死亡事故を `1`、それ以外（負傷事故）を `0` とする2値分類タスクとして設定しています。

### 1.1 追加データセット (External Datasets)

警察庁のオープンデータに加え、以下の2つの外部データを統合し、環境要因の分析精度を高めています。

1.  **交通量データ (Traffic Volume)**
    *   **出典:** 国土交通省「道路交通センサス (Road Traffic Census)」
    *   **用途:** 事故発生地点の道路における交通流の特性を把握
    *   **主な特徴量:**
        *   `traffic_24h`: 24時間交通量（全体）
        *   `traffic_24h_large`: 24時間交通量（大型車）
        *   `traffic_24h_small`: 24時間交通量（小型車）
        *   `congestion_degree`: 混雑度
        *   `large_vehicle_rate`: 大型車混入率（大型車交通量 / 全体交通量）
        *   `day_night_ratio`: 昼夜率（昼間交通量 / 夜間交通量）
        *   `peak_ratio`: ピーク率（ピーク時交通量 / 24時間交通量）
        *   `average_travel_speed`: 平均旅行速度

2.  **医療機関データ (Medical Institutions)**
    *   **出典:** 国土数値情報「医療機関データ (National Land Numerical Information)」
    *   **用途:** 事故発生後の「救命可能性」を評価（病院までの距離が死亡率に影響するという仮説に基づく）
    *   **主な特徴量:**
        *   `distance_to_hospital_km`: 最寄りの災害拠点病院までの距離
        *   `nearest_hospital_beds`: 最寄り病院の病床数
        *   `nearest_hospital_disaster`: 最寄り病院が災害拠点病院かどうかのフラグ
        *   `hospitals_within_5km`: 半径5km圏内の病院数

### 1.2 特徴量エンジニアリング (Feature Engineering on Police Data)

警察庁の元データに対しても、モデルの学習効率と予測精度を高めるために高度な特徴量抽出を行っています。

*   **地理情報のクラスタリング (Geo-Clustering):**
    *   緯度経度をそのまま使用すると過学習するリスクがあるため、**MiniBatchKMeans (k=50)** を用いて日本全国を50のエリア (`area_id`) に分割・カテゴリ化しました。これがFeature Importanceで上位にランクインしています。
*   **日時情報の分解:**
    *   `発生日時`（タイムスタンプ）を `year`, `month`, `day`, `hour`, `weekday` に分解し、季節性や時間帯によるリスク変動を捉えやすくしました。
    *   特に `weekday`（曜日）は、平日と週末の交通パターンや事故特性の違い（業務交通中心かレジャー中心か等）をモデルに学習させる役割を果たします。
*   **道路種別の抽象化:**
    *   約6800種類ある `路線コード` を、国道・県道・市町村道・高速道路などの15種類の `road_type` に集約し、次元削減と解釈性の向上を図りました。
    *   **集約ロジック (Road Type Mapping):** 路線コード（5桁）の上4桁に基づき、以下の15カテゴリに分類し、ID（0〜14）を割り当てました。

        | ID | 道路種別 (Category) | 路線コード範囲 (Route Codes) |
        |:--:|:---|:---|
        | `0` | 一般国道 | 0001 ~ 0999 |
        | `1` | 主要地方道・都道府県道 | 1000 ~ 1499 |
        | `2` | 主要地方道・市道 | 1500 ~ 1999 |
        | `3` | 一般都道府県道 | 2000 ~ 2999 |
        | `4` | 一般市町村道 | 3000 ~ 3999 |
        | `5` | 高速自動車国道 | 4000 ~ 4999 |
        | `6` | 自動車専用道・指定 | 5000 ~ 5499 |
        | `7` | 自動車専用道・その他 | 5500 ~ 5999 |
        | `8` | 道路運送法上の道路 | 6000 ~ 6999 |
        | `9` | 農道 | 7000 ~ 7999 |
        | `10` | 林道 | 8000 ~ 8499 |
        | `11` | 港湾道 | 8500 ~ 8999 |
        | `12` | 私道 | 9000 ~ 9499 |
        | `13` | その他 | 9500 |
        | `14` | 一般の交通の用に供するその他の道路 | 9900 |
*   **地形情報のID化 (`terrain_id`):** 
    *   **概要:** 交通事故データの「地形」カラム（勾配情報）をベースにしたカテゴリカル変数です。
    *   **詳細:** 道路の縦断勾配（平坦、上り、下り）を示す3つのカテゴリ（ID: 1, 2, 3）で構成されています。
    *   **モデルへの効果:** 勾配の有無や向きは、制動距離や速度超過リスクに物理的に直結する重要な要因です。これを数値ではなくカテゴリ（One-Hot Encoding等）として扱うことで、単純な比例関係ではない非線形なリスク特性をモデルに学習させています。

### 1.3 外部データの統合手法 (Data Integration Methodology)

外部データ（交通量・医療機関）は、**「位置情報（緯度経度）」をキーとした空間結合 (Spatial Join)** によって元の交通事故データに統合されています。

*   **交通量データの統合:**
    *   事故発生地点の緯度経度に基づき、**最も近い「道路交通センサス」の計測区間**を特定し、その区間の交通量や混雑度を紐付けています。
*   **医療機関データの統合:**
    *   事故発生地点から**直線距離で最も近い医療機関**を探索 (Nearest Neighbor Search) し、その病院の属性（病床数、災害拠点指定の有無）および距離を算出しました。
    *   また、**半径5km以内**に含まれる医療機関の数をカウントし、地域医療の密度を特徴量化しています。

### 1.4 データ特性と評価設定 (Data Characteristics & Evaluation Setup)

モデルの評価設定とデータの重要な特性は以下の通りです。

*   **時系列分割 (Time-Series Split):**
    *   本タスクは「未来予測」であるため、シャッフル分割ではなく時系列に基づいた分割を採用しています。
    *   **学習データ (Train):** 2018年〜2022年（約130.5万件）
    *   **検証データ (Validation):** 2023年（約30.7万件）
    *   **評価データ (Test):** 2024年（約28.2万件）
    *   これにより、実運用時の性能（最新年のデータに対する予測力）を正しく評価できるようにしています。
*   **クラス不均衡 (Class Imbalance):**
    *   死亡事故の割合は約 **0.86%**（不均衡比 およそ **118:1**）と極めて稀です。
    *   このため、評価指標にはAccuracyではなく、不均衡データに適した **PR-AUC** を重視しています。
*   **欠損値の状況と処理:**
    *   **外部データ（交通量・医療機関）:** 緯度経度を用いた空間結合（Nearest Neighbor等）により、全事故データに対して最も近い地点の情報を付与できたため、分析用データセットにおける**欠損値は 0件 (0%)** です。
    *   **その他:** 万が一の欠損（またはラグ特徴量の発生に伴う欠損）に備え、パイプラインでは以下の統一ルールを適用しています。
        *   **数値変数:** 学習データの中央値 (Median) で補完
        *   **カテゴリ変数:** 欠損を示す特別値 `_missing` で補完

> **詳細資料:**
> 全カラムの定義、型、およびコード値の詳細については、以下のドキュメントを参照してください。
> [COLUMN_DEFINITIONS.md](file:///c:/Users/socce/software-lab/traffic-accident/data/processed/COLUMN_DEFINITIONS.md)

### 1.5 データ処理パイプラインと品質管理 (Data Pipeline & Quality Control)

データ収集からモデル入力までの全体フローと、データの質を担保するための品質管理プロセスは以下の通りです。

```mermaid
graph TD
    A[警察庁オープンデータ<br>(Raw CSV)] -->|189万件| B[データクリーニング<br>(リーク列の除去)]
    B --> C{空間結合<br>(Spatial Join)}
    D[道路交通センサス<br>(交通量)] --> C
    E[医療機関データ<br>(病院距離)] --> C
    C --> F[特徴量エンジニアリング<br>(Geo-Cluster, Date Split)]
    F --> G[品質管理<br>(無効座標除去・欠損処理)]
    G --> H[時系列分割<br>(Train: 2018-2022 / Val: 2023 / Test: 2024)]
```

*   **品質管理 (Quality Control):**
    *   **座標フィルタリング:** 元データには稀に誤記による異常な位置情報が含まれるため、日本国内の有効な緯度経度範囲（Lat: 24~46, Lon: 122~146）を定義し、範囲外のデータを前処理段階で自動的に除去しています。
    *   これにより、モデルが異常値に引きずられるリスクを排除しました。

---

## 2. 実験内容: Two-Stage Spatio-Temporal Ensemble (Experiment Details)

本実験では、死亡事故という「超・稀少事象 (Rare Event)」を精度良く検出するため、**「Two-Stage（2段階）フィルタリング」** と **「時空間アンサンブル」** を組み合わせたモデル構築を行いました。

以下に、再現可能なレベルの詳細な実験設定を記述します。

### 2.1 モデルアーキテクチャ概要

*   **基本戦略:** 
    1.  **Stage 1 (Filtering):** 既知の「安全（Easy Sample）」なデータを高速なモデルで事前に除去する。
    2.  **Stage 2 (Refinement):** 残された「判断が難しいデータ（Hard Sample）」に対し、特性の異なる4つのモデルで精密な学習を行い、アンサンブルする。
*   **ターゲット:** `fatal` (死亡事故=1, 負傷事故=0)
*   **評価指標:** PR-AUC (Precision-Recall Area Under Curve), AUC (ROC)

### 2.2 Stage 1: フィルタリング ("Easy Sample" Removal)

全データ（約130万件）の99%以上は「負傷事故（非死亡）」であり、その多くはモデルにとって簡単なパターンです。Stage 2のモデルが「難しい境界線」の学習に集中できるよう、以下の基準で学習データを削減しました。

*   **使用モデル:** Stage 1 アンサンブルモデル（LightGBM + CatBoost）
*   **フィルタリング閾値:** 予測確率 < `0.0645` (Recall 98%相当)
*   **除外対象:** 上記閾値を下回るデータ（判定が容易な「安全」データ）
*   **削減率:** 学習データの**約57.9%**を除去
*   **残存データ:** 約55万件（全死亡事故を含む）をStage 2の学習に使用。これを「Hard Samples」と定義します。

### 2.3 Stage 2: 4モデル詳細設定

多様性を確保するため、決定木ベース（GBDT）とニューラルネットワーク（NN）の計4モデルを採用しました。

#### (1) LightGBM (The Fast Learner)
*   **ライブラリ:** `lightgbm`
*   **特徴:** カテゴリ変数を最も効率的に処理し、高速に収束します。
*   **主要パラメータ:**
    *   `objective`: `binary`
    *   `metric`: `auc`
    *   `boosting_type`: `gbdt`
    *   `num_leaves`: `63` (表現力を高めるため標準よりやや大きめ)
    *   `max_depth`: `8`
    *   `learning_rate`: `0.05`
    *   `feature_fraction`: `0.8` (特徴量の80%をランダムサンプリング)
    *   `bagging_fraction`: `0.8`
    *   `min_child_samples`: `100` (過学習抑制)
    *   `lambda_l1`, `lambda_l2`: `0.1` (正則化)
*   **カテゴリ変数処理:** ライブラリ標準の `category` 型変換を使用。

#### (2) CatBoost (The Robust Learner)
*   **ライブラリ:** `catboost`
*   **特徴:** カテゴリ変数の処理（Ordered Boosting）に優れ、パラメータチューニングなしでも高精度が出やすいモデルです。
*   **主要パラメータ:**
    *   `iterations`: `2000`
    *   `learning_rate`: `0.05`
    *   `depth`: `8` (深めの木で複雑な相互作用を捕捉)
    *   `l2_leaf_reg`: `3`
    *   `loss_function`: `Logloss`
    *   `eval_metric`: `AUC`
    *   `early_stopping_rounds`: `50`
*   **カテゴリ変数処理:** 全て文字列型に変換し、欠損値は `'missing'` という文字列として明示的に学習させます。

#### (3) MLP (Multi-Layer Perceptron)
*   **ライブラリ:** `PyTorch`
*   **特徴:** 特徴量間の非線形な相互作用を捉えるシンプルなニューラルネットワーク。
*   **アーキテクチャ:**
    *   **Input Layer:** 数値変数 + カテゴリ埋め込み
    *   **Hidden Layers:** 3層構造 `[512 -> 256 -> 64]`
    *   **Activation:** `ReLU`
    *   **Regularization:** `BatchNorm1d` + `Dropout` (0.3 -> 0.2 -> 0.1)
    *   **Output Layer:** `Linear(1)` (Sigmoidなし、Loss関数に統合)
*   **学習設定:**
    *   `Optimizer`: `AdamW` (lr=0.001, weight_decay=0.01)
    *   `Scheduler`: `ReduceLROnPlateau` (mode='max', factor=0.5, patience=5)
    *   `Batch Size`: `1024`
    *   `Loss Function`: `BCEWithLogitsLoss` (pos_weight設定あり)
*   **前処理:**
    *   数値変数: `StandardScaler` で標準化、欠損は平均値補完。
    *   カテゴリ変数: ラベルエンコーディングを実施。

#### (4) TabNet (Attentive Interpreter)
*   **ライブラリ:** `pytorch_tabnet`
*   **特徴:** 決定木のような「特徴選択」の仕組みを内包したニューラルネットワーク。どの特徴量が重要かを学習できます。
*   **主要パラメータ:**
    *   `n_d`, `n_a`: `32` (決定ステップと予測ステップの次元)
    *   `n_steps`: `5` (アーキテクチャの深さ)
    *   `gamma`: `1.5` (特徴選択の緩和係数)
    *   `lambda_sparse`: `1e-4` (スパース正則化)
    *   `optimizer_fn`: `Adam` (lr=0.02)
    *   `batch_size`: `512`
*   **前処理:**
    *   数値変数: `StandardScaler` で標準化。
    *   カテゴリ変数: ラベルエンコーディング（未知のカテゴリ用に0番を予約）。

### 2.4 学習プロセス (Training Strategy)

全てのモデルに対し、以下の厳密なプロセスを適用しました。

1.  **Cross-Validation:**
    *   `StratifiedKFold (k=5)` を使用し、学習データ内での死亡事故率（目的変数）の分布を一定に保ちました。
2.  **Early Stopping:**
    *   検証データ（Validation Set）に対するAUCが改善しなくなった時点で学習を停止し、過学習を防ぎました（Patience=50回など）。
3.  **Data Leakage Prevention:**
    *   ScalingやImputation（欠損補完）の基準値（平均や分散）は、**各Foldの学習データのみ**から算出し、それを検証データに適用しました。検証データやテストデータの情報が学習に漏れることを完全に防いでいます。

### 2.5 アンサンブル手法 (Ensemble Method)

4つのモデルの予測結果を結合するために、重み付き平均（Weighted Blending）を採用しました。

1.  **目的関数:** OOF（Out-of-Fold）予測に対する **AUCの最大化** (-AUCの最小化)。
2.  **最適化アルゴリズム:** `SLSQP` (Sequential Least Squares Programming)
3.  **制約条件:**
    *   各モデルの重み $w_i \ge 0$
    *   重みの総和 $\sum w_i = 1.0$
4.  **最終出力:** 最適化された重みに基づき、OOF予測とテストデータの予測を合成。

---

## 3. 実験結果 (Experimental Results)

本スクリプトでは、Stage 1で「安全（Easy Sample）」と判定されたデータを除外した後、残りの「判断が難しいデータ（Hard Sample）」に対して4つのモデルを学習し、最後にアンサンブルを行いました。

**結論:** **CatBoost単体モデルが最も高いPR-AUCを達成しました。**

| モデル (Model) | Test AUC | Test PR-AUC | 備考 |
| :--- | :--- | :--- | :--- |
| **CatBoost** | 0.8869 | **0.1754** | **Best Performance.** 決定木の勾配ブースティングにより、複雑な境界線を的確に捉えています。 |
| **Ensemble** | 0.8655 | 0.1611 | 4モデルの加重平均。MLPの低性能に引きずられ、単体モデルより精度が低下しました。 |
| **LightGBM** | **0.8937** | 0.1581 | AUC（全体的な順位付け）ではトップですが、PR-AUC（重要度順）ではCatBoostに劣ります。 |
| **TabNet** | 0.8867 | 0.1567 | ニューラルネットワーク系のTabNetも健闘していますが、GBDT勢には及びませんでした。 |
| **MLP** | 0.8535 | 0.1379 | 最も性能が低く、アンサンブル全体の足を引っ張る要因となりました。 |

### 3.1 結果の考察

*   **CatBoostの優位性:**
    *   Two-Stageアプローチ（難しいデータに集中する学習）において、CatBoostは非常に高いパフォーマンス（PR-AUC 0.1754）を示しました。不均衡かつノイズの多い交通事故データにおいて、カテゴリカル変数の処理に長けたCatBoostの特性が奏功していると考えられます。
*   **アンサンブルの失敗要因:**
    *   今回のアンサンブル（Ensemble）は、各モデルの予測値をほぼ均等（約0.25ずつ）に平均化する結果となりました。
    *   しかし、MLPの性能（PR-AUC 0.1379）が他の3モデルに比べて著しく低かったため、単純な平均化が「汚染」として働き、結果としてアンサンブル後の性能（0.1611）がCatBoost単体（0.1754）を下回りました。
    *   **改善案:** 性能の低いMLPをアンサンブルから除外するか、Stacking（Stage 3）のようなメタモデルを用いて、モデルごとの信頼度を学習させる必要があります。

---

## 4. 今後の展望 (Future Work)

今回の実験結果から、以下の改善方針が推奨されます。

1.  **MLPの除外:** アンサンブル構成からMLPを外し、GBDT（CatBoost, LightGBM）とTabNetの3モデル構成にする。
2.  **重み最適化の改善:** 単純なAUC最大化（`scipy.optimize`）ではPR-AUCが最適化されない可能性があるため、PR-AUCを直接目的関数にするか、Stackingメタモデル（Stage 3）へ移行する。
3.  **CatBoostのチューニング:** 単体で最も性能が良いため、CatBoostのパラメータ（深さ、正則化項など）をさらに最適化することで、スコアの向上が見込める。

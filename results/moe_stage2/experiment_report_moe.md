# Mixture of Experts (MoE) Stage 2 実験レポート

## 1. 実験概要
*   **目的**: 「市街地・信号なし等の領域（Urban Domain）」における誤検知を減らすため、専用モデル（Expert A）と汎用モデル（Generalist）に分けるMoE戦略を検証。
*   **制約**: Expert Aには「事故見逃し（False Negative）」を防ぐため、**Recall $\ge$ 80%** という厳しい制約を課しました。

## 2. 実行結果 (Test Set)

| 指標 | MoE (今回) | アンサンブル (前回) | 評価 |
| :--- | :--- | :--- | :--- |
| **Precision** | **0.0455 (4.6%)** | **0.6857 (68.6%)** | 📉 **激減** |
| **Recall** | **0.6852 (68.5%)** | 0.0295 (3.0%) | 📈 **激増** |
| **F1 Score** | 0.0854 | 0.0566 | 🔺 向上 |

### 🛠️ ドメイン別閾値設定の結果
*   **[Expert A] Urban Domain**:
    *   閾値: **0.1223** (かなり低い)
    *   Recall: 80.01% (目標達成)
    *   Precision: 4.41%
*   **[Generalist] Non-Urban**:
    *   閾値: **0.4163** (標準的)
    *   Recall: 15.96%
    *   Precision: 15.99%

## 3. なぜPrecisionが下がったのか？（分析）
**「二兎を追う者は一兎をも得ず」状態**になりました。

1.  **制約が厳しすぎた**:
    *   Expert Aに対し「Recall 80%以上」を強制したため、閾値を **0.12** まで下げる必要がありました。
    *   その結果、大量の「怪しいけど事故じゃない（False Positive）」データも一緒に取り込んでしまい、Precisionが4%台まで低下しました。
    *   前回のアンサンブル（閾値 0.5付近）では、Recallは3%しかありませんでしたが、Precisionは68%ありました。リコール重視に振りすぎた結果です。

2.  **Generalistの健闘**:
    *   一方、Generalist（非市街地）は比較的良いバランス（どちらも16%前後）を出しており、ドメイン分割自体は機能しています。

## 4. 次のステップへの提言

今回の実験で「Recall 80%を維持しつつPrecisionを上げる魔法」は（今の特徴量では）存在しないことがわかりました。トレードオフは絶対です。

**修正案:**
Precision（確実性）を取り戻したい場合、Expert Aの制約を緩める必要があります。

*   **案A: 制約の緩和**: Recall目標を **80% → 50%** 程度に下げる。
*   **案B: 指標の変更**: Recall制約を撤廃し、**F0.5スコア（Precision重視）の最大化**で閾値を決める（おそらく閾値は0.4〜0.6程度に落ち着きます）。

どちらの方針で再調整しますか？個人的には **案B** が、前回の高Precisionモデルの良さを活かしつつ改善を図る現実的なルートです。

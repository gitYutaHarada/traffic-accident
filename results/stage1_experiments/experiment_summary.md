# Stage 1 改善実験結果サマリー

**実施日**: 2025-12-24
**目的**: Stage 1 の Pass Rate（通過率）を削減しつつ、Fatal Recall 99.5% を維持する手法の探索。

## 1. 実験結果概要

| 実験 | 手法 | Pass Rate (Test) | Recall (Test) | ベースライン比 | 判定 |
|------|------|------------------|---------------|----------------|------|
| **Baseline** | **Max Probability** | **78.64%** | **99.57%** | - | 基準 |
| Exp A | Platt Scaling | 78.57% | 99.57% | -0.07% | ❌ 効果なし |
| Exp A | Isotonic Calib | 81.03% | 99.63% | +2.39% (悪化) | ❌ 悪化 |
| **Exp B** | **Logistic Meta-Model** | **77.26%** | **99.42%** | **-1.38%** | ⚠️ 条件付き成功 |

> [!NOTE]
> **OR Ensemble (参考値)**
> 従来の「個別閾値 + OR条件」は、Test Recallが **99.69%** と過剰に高くなり、Pass Rateも **84.00%** と非常に高いため、効率的ではありませんでした。

## 2. 詳細分析

### A. キャリブレーション実験
- **結果**: 改善効果はほぼ見られませんでした（Plattで誤差範囲の0.07%改善のみ）。
- **考察**: `Max Probability`（最大値）を取る単純な手法が既に強力であり、確率分布の単調変換（Platt Scaling）を行っても、99.5%という極端なRecall領域でのランキング精度は向上しませんでした。

### B. ロジスティックメタモデル実験
- **結果**: Pass Rate を **1.38% 削減**しました（78.64% → 77.26%）。
- **注意点**: TestセットでのRecallが **99.42%** となり、目標の99.5%をわずかに下回りました（不足数: 数件程度）。
- **モデル係数**:
    - `CatBoost`: **5.39** (圧倒的に重要)
    - `LightGBM`: **0.89**
    - CatBoostの予測信頼度が非常に高く、実質的に「CatBoostを主とした重み付け」が行われています。

## 3. 推奨事項

**「Logistic Meta-Model の採用」** を推奨します。

理由:
1.  **効率化**: Pass Rate 1.4% の削減は、Stage 2 の推論コスト削減に直結します。
2.  **Recall**: Test Recall 99.42% は許容範囲内である可能性が高いですが、安全マージンとして**閾値をわずかに下げる**（例: 0.0998 → 0.0950）ことで、Recall 99.5% を確実に達成しつつ、ベースライン以上の効率を維持できる見込みです。
3.  **実装容易性**: ロジスティック回帰は軽量であり、パイプラインへの組み込み負荷がほぼありません。

### 次のアクション案
- Script `train_two_stage_or_ensemble.py` を修正し、OR条件の代わりに「学習済みロジスティック回帰メタモデル」を使用するロジックに変更する。
- または、簡易的に `0.85 * CatBoost + 0.15 * LightGBM` のような重み付き平均を採用する（係数比率に基づく）。

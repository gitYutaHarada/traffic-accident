# Stage 2 二値分類化実験レポート

**実施日**: 2025/12/19
**実験対象**: Two-Stage Pipeline (Stage 2 Binary Classification)

## 1. 概要
Stage 2（精密判定モデル）のアプローチを、従来の「多クラス分類（3クラス）」から**「二値分類（負傷 vs 死亡）」**に変更して評価を行いました。
Stage 1（Recall 95%設定）で選別された「紛らわしい負傷（Hard Negatives）」と「死亡事故」を識別することに特化し、不均衡データ対策として `scale_pos_weight` および動的閾値決定ロジック（Best F1 Score）を導入しました。

## 2. 実験設定
- **Stage 1**: LightGBM Binary (Under-sampling 1:2)
  - 目標 Recall: **95%**
- **Stage 2**: LightGBM Binary (負傷=0, 死亡=1)
  - 利用データ: Stage 1 で `Prob > 0.1120` と判定されたデータのみ
  - 不均衡対策: `scale_pos_weight` (Positive比率に合わせて自動調整)
  - 評価指標: **Best F1 Score** となる閾値をCVで探索し、Testに適用

## 3. 実験結果

### 3.1 Stage 1 (フィルタリング性能)
Stage 1は期待通りのフィルタリング性能を発揮しました。
- **フィルタリング率**: **56.04%** (849,745件を除外)
- **死亡事故補足率**: **95.1%** (12,371 / 13,014件をStage 2へパス)
- **Stage 2 候補データ**: 666,475件 (内、死亡は1.86%)

### 3.2 Stage 2 (識別性能)
AUCスコアは非常に高く、モデルが「重傷」と「死亡」を識別する能力自体は高いことが確認できました。

| データセット | AUC Score | 備考 |
| :--- | :--- | :--- |
| **CV (OOF)** | **0.8723** | 安定して高い識別能力 |
| **Test Set** | **0.8913** | 未知データに対しても汎化している |

### 3.3 動的閾値による評価 (Precision / Recall)
確率の出力分布が非常に低いため、固定閾値（0.5）ではなく、F1スコアが最大となる閾値を探索しました。

**CV (Cross Validation) での最適化結果**:
- **Best Threshold**: 0.3214
- **Precision**: 14.35%
- **Recall**: 26.32%
- **F1 Score**: 0.1824

**Test Set での適用結果 (閾値 0.3214)**:
- **Precision**: **34.98%** (向上)
- **Recall**: **2.40%** (激減)
- **F1 Score**: 0.0449

## 4. 考察

### AUCは高いが、決定境界がシビア
AUC 0.89 という数値は、モデルが「負傷」と「死亡」の順序付け（ランキング）には成功していることを示しています。しかし、Test Setでの結果が示すように、**閾値を固定して運用することの難易度が極めて高い**状態です。

- CVで求めた閾値 (0.3214) をTestに適用すると、Precisionは35%まで向上しましたが、Recallが2.4%まで低下しました。
- これは、「確実に死亡だと言える（確率が高い）」事例は極めて少なく、**大半の死亡事故が「確率0.02〜0.30」のグレーゾーンに密集している**ことを示唆しています。

### 安全重視なら閾値は「0.02」付近
Recall 95%以上を維持するための閾値は **0.018〜0.027** 付近です。
この場合、Precision（的中率）は **約2.0〜2.3%** となります。つまり、アラートの50回に1回が本当の死亡事故、という運用になります。

## 5. 結論と次のステップ

### 結論
- **二値分類化は成功**: AUC 0.89は過去の実験と比較しても高い水準であり、アプローチ自体は正しい。
- **課題は閾値設定**: 確率分布が低スコア帯に偏っており、閾値のわずかな変動でRecall/Precisionが激しく変動する。

### 推奨アクション
1.  **Focal Loss の導入**: まだ識別できていない「難しい死亡事故（Hard Positives）」のスコアを押し上げるため、Stage 2 に Focal Loss を適用する（今回の実験は通常のBinary Cross Entropy）。
2.  **DAE特徴量の統合**: グレーゾーンの識別力を上げるため、以前作成した Denoising Autoencoder 特徴量を Stage 2 に追加する。
3.  **アンサンブル**: 複数のモデル（XGBoost, CatBoost等）を組み合わせることで、確率推定の安定化を図る。
